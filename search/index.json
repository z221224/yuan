[{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1. 获取当前登录用户的id 根据用户的id拼接购物车的key； 2. 获取购物车的数据 2.1 获取 redisTemplate.opsForHash().values(cartKey); 2.2 根据创建时间 排序（新加到购物车的商品应该在最上面） List\u0026lt;CartInfo\u0026gt; cartInfoList = cartInfoList.stream() .sorted((o1, o2) -\u0026gt; o2.getCreateTime().compareTo(o1.getCreateTime())) .toList(); 3. 查询商品的实时价格 3.1 获取skuIdList 3.2 远程调用 根据skuIdList获取最新价格（） 转换为map，key：skuId，value：price Map\u0026lt;Long, BigDecimal\u0026gt; skuIdToPriceMap = SkuPriceListResult.getData() .stream().collect (Collectors.toMap (SkuPrice::getSkuId, SkuPrice::getSalePrice)); 4. 修改购物车数据的最新价格 cartInfoList.forEach(item -\u0026gt; { //设置实时价格 item.setSkuPrice(skuIdToPriceMap.get(item.getSkuId())); }); ","date":"2025-01-16T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E8%B4%AD%E7%89%A9%E8%BD%A6%E5%88%97%E8%A1%A8%E6%9F%A5%E8%AF%A2/","title":"购物车列表查询"},{"content":"缓存穿透: 是指查询一个不存在的数据。\n缓存雪崩: 是指很多key集体失效。\n缓存击穿: 是指一个热点key失效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 try { 1.优先从缓存中获取数据 查询Redis获取业务数据 命中缓存则直接返回 if (redisTemplate.hasKey(dataKey)) { log.info(\u0026#34;命中缓存，直接返回，线程ID：{}，线程名称：{}\u0026#34;, Thread.currentThread().getId(), Thread.currentThread().getName()); return productSku; } 2.尝试获取 分布式锁（set k v ex nx可能获取锁失败） 构建锁key String lockKey = \u0026#34;product:sku:lock:\u0026#34; + skuId; 采用UUID作为线程标识 String lockVal = UUID.randomUUID().toString().replaceAll(\u0026#34;-\u0026#34;, \u0026#34;\u0026#34;); Boolean flag = redisTemplate.opsForValue().setIfAbsent(lockKey, lockVal, 5, TimeUnit.SECONDS); if (flag) { 3.获取锁成功执行业务,将查询业务数据放入缓存Redis log.info(\u0026#34;获取锁成功：{}，线程名称：{}\u0026#34;, Thread.currentThread().getId(), Thread.currentThread().getName()); try { productSku = this.getProductSkuFromDB(skuId); long ttl = productSku == null ? 1 * 60 : 10 * 60; redisTemplate.opsForValue().set(dataKey, productSku, ttl, TimeUnit.SECONDS); return productSku; } finally { 4.业务执行完毕释放锁 String scriptText = \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1]) == ARGV[1]\\n\u0026#34; + \u0026#34;then\\n\u0026#34; + \u0026#34; return redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1])\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34; return 0\\n\u0026#34; + \u0026#34;end\u0026#34;; DefaultRedisScript\u0026lt;Long\u0026gt; redisScript = new DefaultRedisScript\u0026lt;\u0026gt;(); redisScript.setScriptText(scriptText); redisScript.setResultType(Long.class); redisTemplate.execute(redisScript, Arrays.asList(lockKey), lockVal); } } else { try { 5.获取锁失败则自旋（业务要求必须执行） Thread.sleep(200); } catch (InterruptedException e) { throw new RuntimeException(e); } log.error(\u0026#34;获取锁失败，自旋：{}，线程名称：{}\u0026#34;, Thread.currentThread().getId(), Thread.currentThread().getName()); return this.getProductSku(skuId); } } catch (Exception e) { //兜底处理方案：Redis服务有问题，将业务数据获取自动从数据库获取 log.error(\u0026#34;[商品服务]查询商品信息异常：{}\u0026#34;, e); return this.getProductSkuFromDB(skuId); } ","date":"2025-01-16T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E5%95%86%E5%93%81%E8%AF%A6%E6%83%85%E9%A1%B5%E9%9D%A2%E4%BC%98%E5%8C%96/","title":"商品详情页面优化"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0. 获取当前登录用户的id 1. 构建“用户”购物车hash结构key \u0026#34;user:cart:\u0026#34; + userId; 2. 创建Hash结构绑定操作对象（方便对hash进行操作） BoundHashOperations\u0026lt;String, String, CartInfo\u0026gt; hashOps = redisTemplate.boundHashOps(cartKey); 3. 判断用户购物车中是否包含该商品 如果包含：数量进行累加(某件商品数量上限99) 不包含：新增购物车商品 if (hashOps.hasKey(hashKey)) { 3.1 说明该商品在购物车中已有， 对数量进行累加 ，不能超过指定上限99 } else { //4. 判断购物车商品种类（不同SKU）总数大于50件 //4.1 购物车没有该商品，构建购物车对象，存入Redis CartInfo cartInfo = new CartInfo(); //4.2 远程调用商品服务获取商品sku基本信息 //4.3 远程调用商品服务获取商品实时价格 //4.4 将购物车商品存入Redis hashOps.put(key,cartInfo) } ","date":"2025-01-16T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E6%B7%BB%E5%8A%A0%E8%B4%AD%E7%89%A9%E8%BD%A6/","title":"添加购物车"},{"content":"下订单业务逻辑：\n1、验证用户重复提交订单\n1 2 3 redis中有一个订单流水号， 哪个线程先到，就判断并删除流水号key，（使用lua脚本保证原子性） 删除成功，业务逻辑往下走。 2、验证表单参数是否空\n1 判断订单里面的订单项有没有值，没有抛异常 3、校验价格变化\n1 2 3 4 5 6 7 8 9 10 11 12 1.先获取订单项的所有id 2.远程调用，获取所有id的sku的最新价格 3.比较价格 3.1 转换成map，key为skuid，值为价格 3.2 比较订单项的价格和map中的价格 3.3 价格不相等 远程调用更行购物车最新价格。 抛异常。 3.4 价格相等，业务流程继续往下走 4、校验库存锁定库存\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 远程调用 检查并锁定库存 1. 防止重复请求 在redis中setNx一把锁， 如果存在，则已执行过库存锁定 返回空字符串（成功） 不存在，添加成功。业务往下走 2. 遍历所有商品，验库存 满足条件: 商品的available_num \u0026gt; skuNum 不满足的将 skuLockVo.setIsHaveStock(false); 遍历所有商品，锁库存 检查所所有商品的IsHaveStock 只要有一个商品的IsHaveStock是false，抛异常。 //锁定失败，解除 redisTemplate.delete(key); // 响应锁定状态 return result.toString(); 否则，锁库存(也就是修改表里的可用库存和锁定库存)--\u0026gt;available_num-,lock_num+ //锁定库存 挨个遍历，修改数据库 skuLockVoList.forEach(skuLockVo -\u0026gt; { int row = skuStockMapper.lock(skuLockVo.getSkuId(), skuLockVo.getSkuNum()); if(row == 0) {//受影响行数为0，修改失败 //解除去重 redisTemplate.delete(key); throw new ServiceException(\u0026#34;库存锁定失败\u0026#34;); } }); 3. // 如果所有商品都锁定成功的情况下，需要缓存锁定信息到redis。以方便将来解锁库存 或者 减库存 redisTemplate.opsForValue().set(dataKey, skuLockVoList); 5、保存订单（订单表、订单项表、订单日志表）\n1 2 3 4 5 6 7 8 9 Long orderId = null; try { //下单 orderId = this.saveOrder(orderForm); } catch (Exception e) { e.printStackTrace(); //抛出异常 throw new ServiceException(\u0026#34;下单失败\u0026#34;); } 6、删除购物车选中商品 远程调用 删除购物车选中商品信息\n1 2 3 4 5 6 7 8 R\u0026lt;Boolean\u0026gt; booleanR = remoteCartService.deleteCartCheckedList(userId, SecurityConstants.INNER); if (R.FAIL == booleanR.getCode()) { throw new ServiceException(booleanR.getMsg()); } Boolean isDeleteCart = booleanR.getData(); if (!isDeleteCart) { throw new ServiceException(\u0026#34;购物车商品删除失败！！\u0026#34;); } ","date":"2025-01-16T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E4%B8%8B%E8%AE%A2%E5%8D%95/","title":"下订单"},{"content":"缓存常见问题\r缓存最常见的4个问题： 面试\n缓存穿透 缓存雪崩 缓存击穿 数据一致性 缓存穿透\r缓存穿透: 是指查询一个不存在的数据，由于缓存无法命中，将去查询数据库，但是数据库也无此记录，并且出于容错考虑，我们没有将这次查询的null写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。\n解决1 ：空结果也进行缓存，但它的过期时间会很短，最长不超过五分钟，但是不能防止随机穿透。\n解决2 ：使用布隆过滤器或者Redis的Bitmap来解决随机穿透问题\n缓存雪崩\r缓存雪崩:是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。\n解决1：\n原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n解决2：\n如果单节点宕机，可以采用集群部署方式防止雪崩\n缓存击穿\r缓存击穿: 是指对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：如果这个key在大量请求同时进来之前正好失效，那么所有对这个key的数据查询都落到db，我们称为缓存击穿。\n与缓存雪崩的区别：\r击穿是一个热点key失效 雪崩是很多key集体失效 解决：分布式锁\r数据一致性问题\r数据一致性：在当前环境下，通常我们会首选redis缓存来减轻我们数据库访问压力。但是也会遇到以下这种情况：大量用户来访问我们系统，首先会去查询缓存， 如果缓存中没有数据，则去查询数据库，然后更新数据到缓存中，并且如果数据库中的数据发生了改变则需要同步到redis中，同步过程中需要保证 MySQL与redis数据一致性问题\n解决1：使用延时双删策略\r延时双删策略是一种常见的保证MySQL和Redis数据一致性的方法。其主要流程包括：先删除缓存，然后更新数据库。这个过程完成后，大约在数据库从库更新后再次删除缓存。具体的步骤如下：\n第一步，先执行redis.del(key)操作删除缓存；\n第二步，然后执行写数据库的操作；\n第三步，休眠一段时间（例如500毫秒），根据具体的业务时间来定；\n第四步，再次执行redis.del(key)操作删除缓存。\n延时双删策略通过这种方式尝试达到最终的数据一致性，但是这并不是强一致性，因为MySQL和Redis主从节点数据的同步并不是实时的，所以需要等待一段时间以增强它们的数据一致性。同时，由于读写是并发的，可能出现缓存和数据库数据不一致的问题\n解决2：使用canal解决\r分布式锁\r分布式锁主流的实现方案：\n基于数据库实现分布式锁 基于缓存（ Redis等） 基于Zookeeper 每一种分布式锁解决方案都有各自的优缺点：\n高性能：Redis最高 可靠性：zookeeper最高 分布式锁的关键是多进程共享的内存标记(锁)，因此只要我们在Redis中放置一个这样的标记(数据)就可以了。不过在实现过程中，不要忘了我们需要实现下列目标：\n多进程可见：多进程可见，否则就无法实现分布式效果 避免死锁：死锁的情况有很多，我们要思考各种异常导致死锁的情况，保证锁可以被释放 排它：同一时刻，只能有一个进程获得锁 高可用：避免锁服务宕机或处理好宕机的补救措施(redis集群架构：1.主从复制 2.哨兵 3.cluster集群) 小总结：\n为了确保分布式锁可用，至少要确保锁的实现同时满足以下几个条件：\n互斥性。在任意时刻，只有一个客户端能持有锁。\n不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。\n解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。\n加锁和解锁必须具有原子性。\n","date":"2025-01-14T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/redis%E7%BC%93%E5%AD%98%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","title":"redis缓存常见问题"},{"content":"JUC是什么？\r在 Java 5.0 提供了 java.util.concurrent(简称JUC)包，在此包中增加了在并发编程中很常用的工具类。\n并行和并发\r并发（Concurrency）：并发指的是多个任务在同一个时间段内交替执行。在并发场景下，多个任务可以同时存在，但实际上每个任务只能以一种交替的方式执行，即任务之间可能会进行快速的切换或分时执行。\n例子：\n限量抢购 春运抢票 电商秒杀 并行（Parallelism）：并行指的是多个任务在同一时刻同时执行。在并行场景下，多个任务可以同时进行，每个任务拥有自己的处理单元（例如CPU核心）\n例子：\n泡方便面，电水壶烧水，一边撕调料倒入桶中\n同步和异步\r","date":"2025-01-09T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/juc/","title":"juc"},{"content":"JUC概述\r什么是JUC？\rjava.util.concurrent包中提供的并发编程的工具类\n它提供多种工具类：原子类，线程池，并发集合，同步器\n进程与线程：\r进程：具备独立功能的程序软件关于某个数据集合的依次运行活动\n操作系统动态执行的基本单位\n线程：一个进程包含一个或者多个线程\n独立运行和调度的基本单位\n并行和并发：\r并行：多个线程同时跑，干不同的事\n并发：多个线程对同一资源的抢占\n同步和异步：\r同步：任务按顺序依次执行，每一个任务必须等待前一个任务完成\n异步：同时发起请求，不需要等待结果，结果回来后\n线程的状态：\r新建（New）：线程被创建但尚未启动执行。 就绪（Runnable）：线程等待CPU时间片以便执行，也就是处于就绪状态。 阻塞（Blocked）：线程暂停执行，通常是因为等待某些条件满足，例如等待I/O操作完成、等待锁释放等。 无限期等待（Waiting）：线程无限期地等待某个条件的发生，通常需要其他线程来唤醒它。 有限期等待（Timed Waiting）：线程等待一段时间，超过指定时间后会自动唤醒。 终止（Terminated）：线程执行完成或者异常终止，进入终止状态。 枚举没赋值会给它赋初值，从0开始累加\nwait和sleep\r区别：\nwait需要 notify()或notifyAll()方法来唤醒 必须在锁环境下使用\nsleep是当前线程暂停执行指定时间，时间到唤醒\n创建线程：\r创建线程常用的两种方式：\n1 2 3 4 1. 继承Thread：java是单继承，资源宝贵，要用接口方式 extends Thread 2. 实现Runable接口 implements Runnable 3. implements Callable 4. ThreadPoolExecutor *********************************************************************************************视频细节需要补充\n继承Thread抽象类：\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class T1 extends Thread{ @Override public void run() { System.out.println(\u0026#34;Thread....\u0026#34;); super.run(); } } public class ThreadDemo { public static void main(String[] args) { T1 t1 = new T1(); t1.start(); } } 实现Runable接口:\r新建类实现runnable接口：这种方法会新增类，有更好的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 class T2 implements Runnable{ @Override public void run() { System.out.println(Thread.currentThread().getName() +\u0026#34; runnable....\u0026#34;); } } public class ThreadDemo { public static void main(String[] args) { new Thread(new T2(), \u0026#34;线程名\u0026#34;).start(); } } 匿名内部类方式：\n1 2 3 4 5 6 new Thread(new Runnable() { @Override public void run() { // 调用资源方法，完成业务逻辑 } }, \u0026#34;your thread name\u0026#34;).start(); lambda表达式方式：\n1 2 3 new Thread(()-\u0026gt;{ // 调用资源方法，完成业务逻辑 }, \u0026#34;your thread name\u0026#34;).start(); synchronized\r多线程编程模板（上）：\n高内聚 低耦合 （将代码进行一定的封装，进行重复，独立使用） 线程 操作 资源类 实现步骤：\n创建资源类 资源类里创建同步方法、同步代码块 多线程调用 例子：卖票程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 package com.atguigu.demojuc.chap01; //资源类中内聚操作资源的方法，降低线程操作资源的耦合性 class Ticket{ // 定义一个票数 private int number = 20; // 定义一个卖票的方法: 出现了资源抢占； // synchronized: 使用synchronized同步方法解决 public synchronized void sale(){ // 判断 if (number\u0026lt;=0){ System.out.println(Thread.currentThread().getName() + \u0026#34;票已售罄！\u0026#34;); return; } try { System.out.println(Thread.currentThread().getName() + \u0026#34;开始售票，当前票数：\u0026#34; + number); Thread.sleep(200); System.out.println(Thread.currentThread().getName() + \u0026#34;买票售票，剩余票数：\u0026#34; + --number); } catch (InterruptedException e) { e.printStackTrace(); } } } public class SaleTicket { public static void main(String[] args) { // 创建资源类对象 Ticket ticket = new Ticket(); // 创建线程 new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 21; i++) { ticket.sale(); } },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 21; i++) { ticket.sale(); } },\u0026#34;B\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 21; i++) { ticket.sale(); } },\u0026#34;C\u0026#34;).start(); } } synchronized的8锁问题\rsynchronized锁的是什么？\n1 类对象、实例对象 java中的每一个对象都可以作为锁。具体表现为以下3种形式：\n对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步代码块，锁是Synchonized括号里配置的对象 而静态同步方法（Class对象锁）与非静态同步方法（实例对象锁）之间是不会有竞争的(锁都是自己的)。 Lock锁:\rlock锁+三个实现类=JUC里面的锁：\n1 2 3 4 5 6 7 8 ReentrantLock 可重入锁 这两个统一称为读写锁 ReentrantReadWriteLock.ReadLock ReentrantReadWriteLock.WriteLock lock是接口，ReenrantLock、ReadLock、WriteLock三个是lock接口的实现类 ReentrantReadWriteLock实现的是ReadWriteLock ReentrantLock可重入锁\rReentrantLock是可重入的互斥锁，虽然具有与synchronized相同功能，但是会比synchronized有更多的方法，因此更加灵活。\n1 2 3 4 5 6 7 8 9 互斥锁：独占锁、悲观锁 a线程对一个资源加了一把锁，b线程就无法给这个资源加锁 锁可重入： 外层代码块和内层代码块用同一把锁 外层抢到锁后不需要 释放锁再抢内部锁 直接可以进 ReentrantLock和synchronized都具有可重入性 1 2 3 4 5 6 使用： ReentrantLock lock = new ReentrantLock(); 再：lock.lock(); 执行完后 lock.unlock(); 为了避免代码出问题，这个方法最好放到finally(try,catch,finally)里 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class Ticket{ private final ReentrantLock lock = new ReentrantLock(); // 定义一个票数 private int number = 1; // 定义一个卖票的方法: public void sale(){ lock.lock(); // 判断 if (number\u0026lt;=0){ System.out.println(Thread.currentThread().getName() + \u0026#34;票已售罄！\u0026#34;); lock.unlock(); System.out.println(\u0026#34;return\u0026#34;); return; } try { System.out.println(Thread.currentThread().getName() + \u0026#34;开始买票，当前票数：\u0026#34; + number); Thread.sleep(200); System.out.println(Thread.currentThread().getName() + \u0026#34;买票结束，剩余票数：\u0026#34; + --number); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(\u0026#34;finally\u0026#34;); lock.unlock(); } } } 公平锁\r1 2 3 4 5 6 7 8 ReentrantLock可以实现公平锁 公平锁： 也就是在锁上等待时间最长的线程优先获得锁的使用权。 通俗的理解就是谁排队时间最长谁先获取锁。 （公平锁不允许插队，非公平锁允许插队） 实现： private ReentrantLock lock = new ReentrantLock(true); 限时等待\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 通过我们的lock.tryLock()方法来实现 synchronized不具有限时等待的功能 有参表示等待指定的时间 无参则表示立即返回锁申请的结果 true表示获取锁成功，false表示获取锁失败。 这种方法可以用来解决死锁问题。 死锁： 两个线程互相抢被对方拿到的锁，都不释放锁，就出现了死锁 tryLock 能拿到锁就干，拿不到就不干了 ReentrantLock和synchronized区别\r1 2 3 4 5 6 7 8 9 1.两个都是独占锁， 但是synchronized加锁解锁是自动 易于操作，不灵活 ReentarantLock加锁解锁需要手动 不易于操作，但灵活 2.两个都是可重入 但因为synchronized加锁解锁是自动，不担心最后是否释放锁 ReentarantLock加锁解锁需要手动，且加锁一次就需要解锁，否则其他线程无法获得锁 3.synchronized不可响应中断，一个线程获取不到锁就一直等着 ReentrantLock可以响应中断（tryLock方法：获取不到锁则返回false） 4. synchronized不具备设置公平锁的特点，ReentrantLock可以成为公平锁。 ReentrantReadWriteLock读写锁\r1 2 3 读写锁允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。 故：一般用于多读写少情况 特点：\n1 2 3 4 5 6 7 8 1. 写写不可并发 两个线程都拿到写锁，一个写的时候另一个不能写 2. 读写不可并发/写读不可并发 一个读时另一个写不了，一个写时另一个也读不了 3. 读读可以并发 两个线程都拿到读锁，两个线程都能读 1 读写锁保证了写操作的原子性，并且可以进行并发读 锁降级\r1 2 3 4 5 在当前线程拥有写锁的情况下，获取到读锁，随后释放写锁的过程就是锁降级。 为了减少锁的竞争，提高程序的并发性能 锁降级的典型场景是在持有某个写锁时，释放写锁并获取读锁。这样做的好处是在执行读操作期间，其他线程可以同时执行读操作，提高了并发性能。 读写锁总结\r支持公平/非公平策略\n1 支持公平锁和非公平锁切换 支持可重入\n同一读线程在获取了读锁后还可以获取读锁 同一写线程在获取了写锁之后既可以再次获取写锁又可以获取读锁 同一读线程在获取了读锁后不可以获取写锁 1 2 3 4 5 可重入性都是针对同一线程而言 读锁读锁可以 写锁写锁可以 读锁写锁不可以 支持锁降级，不支持锁升级\n读写锁如果使用不当，很容易产生“饥饿”问题：\n在读线程非常多，写线程很少的情况下，很容易导致写线程“饥饿”，虽然使用“公平”策略可以一定程度上缓解这个问题，但是“公平”策略是以牺牲系统吞吐量为代价的。\n锁饥饿（Lock Starvation）是指在多线程编程中的一种情况，其中某些线程可能无法获得所需的锁，而一直等待下去，从而无法继续执行，即线程被\u0026quot;饿死\u0026quot;在等待锁的过程中。这可能会导致应用程序的性能问题和不稳定性。\n线程间通信\r面试题案例\n两个线程，一个线程打印1-52，另一个都要弄字母A-Z，打印顺序为12A34B\u0026hellip;5152Z，要求用线程间通信\n线程间通信模型\n生产者+消费者 通知等待唤醒机制 多线程编程模板(中)\r1.判断\n2.干活\n3.通知\n两个线程操作一个初始值为0的变量，实现一个线程对变量增加1，一个线程对变量减少1，交替10轮。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 package com.atguigu.demojuc.chap03; class ShareDataOne{ private Integer number = 0; /** * 增加1 */ public synchronized void increment() throws InterruptedException { // 1. 判断 if (number != 0) { this.wait(); } // 2. 干活 number++; System.out.println(Thread.currentThread().getName() + \u0026#34;: \u0026#34; + number); // 3. 通知 this.notifyAll(); } /** * 减少1 */ public synchronized void decrement() throws InterruptedException { // 1. 判断 if (number != 1) { this.wait(); } // 2. 干活 number--; System.out.println(Thread.currentThread().getName() + \u0026#34;: \u0026#34; + number); // 3. 通知 this.notifyAll(); } } /** * 现在两个线程， * 可以操作初始值为零的一个变量， * 实现一个线程对该变量加1，一个线程对该变量减1， * 交替，10轮。 * * 笔记：Java里面如何进行工程级别的多线程编写 * 1 多线程编程模板（套路） * 1.1 线程 操作 资源类 * 1.2 高内聚 低耦合 * 2 多线程编程模板（套路） * 2.1 判断 * 2.2 干活 * 2.3 通知 */ public class NotifyWaitDemo { public static void main(String[] args) { ShareDataOne shareDataOne = new ShareDataOne(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 10; i++) { try { shareDataOne.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } }, \u0026#34;AAA\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 10; i++) { try { shareDataOne.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } }, \u0026#34;BBB\u0026#34;).start(); } } 部分打印结果：AAA和BBB交互执行，执行结果是1 0 1 0\u0026hellip; 一共10轮\n1 2 3 4 5 6 7 8 9 AAA: 1 BBB: 0 AAA: 1 BBB: 0 AAA: 1 BBB: 0 AAA: 1 BBB: 0 。。。。 虚假唤醒\r换成4个线程会导致错误，虚假唤醒\n**原因：**在java多线程判断时，不能用if，程序出事出在了判断上面。\n1 进行wait()时判断条件使用if了，导致虚假唤醒 **注意：**消费者被唤醒后是从wait()方法（被阻塞的地方）后面执行，而不是重新从同步块开头。\n解决虚假唤醒：查看API，java.lang.Object的wait方法\n中断和虚假唤醒是可能产生的，所以要用循环，if只判断一次，while是只要唤醒就要重新再判断一次。\n多线程编程模板（下）：\n防止虚假唤醒（使用while，代替if）\n1 2 3 4 5 6 7 8 9 // 1. 判断 while (number != 0) { this.wait(); } // 1. 判断 while (number != 1) { this.wait(); } 线程通信（Condition）\r线程间通信有两套代码开发方式\n1 2 3 4 5 6 1.wait+notify/notifyall+synchronized wait+notify/notifyall必须在有锁的环境下使用，所以必须跟synchronized结合做开发 如果使用JUC中的lock锁， 通过Condition来实现通知唤醒(代替wait+notify/notifyall) 2.lock+condition 上面案例只需要改动ShareDataOne\n并去掉 increment 和 decrement 方法的synchronized\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class ShareDataOne{ private Integer number = 0; final Lock lock = new ReentrantLock(); // 初始化lock锁 final Condition condition = lock.newCondition(); // 初始化condition对象 /** * 增加1 */ public void increment() throws InterruptedException { lock.lock(); // 加锁 try{ // 1. 判断 while (number != 0) { // this.wait(); condition.await(); } // 2. 干活 number++; System.out.println(Thread.currentThread().getName() + \u0026#34;: \u0026#34; + number); // 3. 通知 // this.notifyAll(); condition.signalAll(); //唤醒所有等待的线程 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } /** * 减少1 */ public void decrement() throws InterruptedException { lock.lock(); // 加锁 try{ // 1. 判断 while (number != 1) { // this.wait(); condition.await(); } // 2. 干活 number--; System.out.println(Thread.currentThread().getName() + \u0026#34;: \u0026#34; + number); // 3. 通知 // this.notifyAll(); condition.signalAll(); //唤醒所有等待的线程 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } 1 2 condition.signal(); // 唤醒一个等待的线程 condition.signalAll(); //唤醒所有等待的线程 定制化调用通信\r线程间按顺序通信\n面试题\n1 2 3 4 5 6 7 8 9 多线程之间按顺序调用，实现AA-\u0026gt;BB-\u0026gt;CC。三个线程启动，要求如下： AA打印5次，BB打印10次，CC打印15次 接着 AA打印5次，BB打印10次，CC打印15次 。。。打印10轮 1 2 3 4 5 6 7 分析实现方式： 1. 有一个锁Lock，3把钥匙Condition（a完了唤醒b，b完了唤醒c） 2. 有顺序通知（切换线程），需要有标识位 3. 判断标志位 4. 输出线程名 + 内容 5. 修改标识符，通知下一个 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 package com.atguigu.juc.chap03; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class ThreadOrderAccess { //声明全局锁对象 private static Lock lock = new ReentrantLock(); //为A,B,C线程声明Condition对象负责不同线程等待，唤醒 private static Condition conditionA = lock.newCondition(); private static Condition conditionB = lock.newCondition(); private static Condition conditionC = lock.newCondition(); //声明全局flag标识，作为线程阻塞，执行条件 private static int flag = 1; /** * A线程负责调用打印5次方法 */ public void print5() { //1.先获取锁 lock.lock(); try { //2.判断A线程等待条件（不等于1将当前线程进入等待状态） while (flag != 1) { conditionA.await(); } //3.干活（flag=1则打印5次执行） for (int i = 1; i \u0026lt;= 5; i++) { System.out.println(Thread.currentThread().getName() + \u0026#34;,\u0026#34; + i); } //4.将flag标识修改为2，唤醒B线程干活 flag = 2; conditionB.signalAll(); } catch (InterruptedException e) { throw new RuntimeException(e); } finally { //5.将锁释放 lock.unlock(); } } /** * B线程负责调用打印10次方法 */ public void print10() { //1.先获取锁 lock.lock(); try { //2.判断B线程等待条件（不等于2将当前线程进入等待状态） while (flag != 2) { conditionB.await(); } //3.干活（flag=2则打印10次执行） for (int i = 1; i \u0026lt;= 10; i++) { System.out.println(Thread.currentThread().getName() + \u0026#34;,\u0026#34; + i); } //4.将flag标识修改为3，唤醒C线程干活 flag = 3; conditionC.signalAll(); } catch (InterruptedException e) { throw new RuntimeException(e); } finally { //5.将锁释放 lock.unlock(); } } /** * C线程负责调用打印15次方法 */ public void print15() { //1.先获取锁 lock.lock(); try { //2.判断C线程等待条件（不等于3将当前线程进入等待状态） while (flag != 3) { conditionC.await(); } //3.干活（flag=3则打印15次执行） for (int i = 1; i \u0026lt;= 15; i++) { System.out.println(Thread.currentThread().getName() + \u0026#34;,\u0026#34; + i); } //4.将flag标识修改为1，唤醒A线程干活 flag = 1; conditionA.signalAll(); } catch (InterruptedException e) { throw new RuntimeException(e); } finally { //5.将锁释放 lock.unlock(); } } public static void main(String[] args) { //2.创建资源类对象 ThreadOrderAccess orderAccess = new ThreadOrderAccess(); //1.创建三个线程A,B,C new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 10; i++) { orderAccess.print5(); } }, \u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 10; i++) { orderAccess.print10(); } }, \u0026#34;B\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 10; i++) { orderAccess.print15(); } }, \u0026#34;C\u0026#34;).start(); } } 1 2 3 在Java中，一个ReentrantLock可以与多个Condition对象一起使用 每个Condition对象可以用于不同的线程协调和通信场景 以便更精细地控制多线程之间的执行顺序和互斥访问。 并发容器类\rVector和Synchronized的缺点：\n1 2 3 4 - Vector：内存消耗比较大，适合一次增量比较大的情况（Vector每次扩容是原来容量的一倍，ArrayList是原来的1.5倍） //Vector：读取加锁！ - SynchronizedList：迭代器涉及的代码没有加上线程同步代码 //synchronizedList： 读取数据：读取数据没有加锁！ CopyOnWrite\r什么是CopyOnWrite容器\r1 2 3 4 5 6 7 8 9 10 11 CopyOnWrite容器（简称COW容器）即写时复制的容器。 通俗的理解： 当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。 好处： 可以对CopyOnWrite容器进行并发的读，而不需要加锁 因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 读写分离： 写的时候不影响读，读写是分开的 1 2 3 4 5 6 7 8 从JDK1.5开始 Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器 CopyOnWriteArrayList //是线程安全的 List 实现，它通过复制底层数组的方式保证线程安全，适用于读多写少的场景。 CopyOnWriteArraySet //是CopyOnWriteArrayList 的 Set 版本 应用场景：\r1 2 3 4 CopyOnWrite并发容器用于 读多写少 的并发场景：白名单，黑名单 场景： 假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单一定周期才会更新一次。 缺点\r1 2 3 4 5 6 7 1. 内存占用问题。 //写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存。 //2倍内存空间 2. 数据一致性问题。 //CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。 //所以如果你希望写入的数据，马上能读到，请不要使用CopyOnWrite容器。读的数据可能是就旧数组 ConcurrentHashMap\r特点\n1 2 3 4 5 6 7 8 9 1. 并发性：ConcurrentHashMap //允许多个线程同时访问，读操作不会被阻塞，不需要加锁。 //这意味着多个线程可以并发地读取其中的数据，而不会发生竞争或锁定。 2. 分段锁：ConcurrentHashMap //ConcurrentHashMap是线程安全的Map容器 //JDK8之前，ConcurrentHashMap使用锁分段技术，将数据分成一段段存储，每个数据段配置一把锁，即segment类，这个类继承ReentrantLock来保证线程安全，JKD8的版本取消Segment这个分段锁数据结构，底层也是使用Node数组+链表+红黑树，从而实现对每一段数据就行加锁，也减少了并发冲突的概率。 //这种设计允许多个线程同时进行读操作，只有在写操作时才需要锁定相应的段，以确保线程安全。这提高了并发性能，因为不同段之间的操作不会相互阻塞。 1 2 3 4 5 ConcurrentHashMap是一个用于高并发环境的非常有用的数据结构。 它提供了高效的并发访问支持，允许多个线程同时读取和写入数据，而不需要显式的锁定。 场景：并发编程中需要高效地处理共享数据的情况 并发安全集合类都哪些？\n1 2 3 4 5 6 7 8 9 10 11 ConcurrentHashMap //是线程安全的哈希表实现,它通过分段锁的机制来实现并发访问的高效性。 CopyOnWriteArrayList //是线程安全的 List 实现，它通过复制底层数组的方式保证线程安全，适用于读多写少的场景。 CopyOnWriteArraySet //是 CopyOnWriteArrayList 的 Set 版本 BlockingQueue //是一个用于在多线程间传递数据的队列接口,它包含多个实现类，如 ArrayBlockingQueue、LinkedBlockingQueue JUC强大的辅助类\rCountDownLatch（倒计数器） CyclicBarrier（循环栅栏） Semaphore（信号量 CountDownLatch\r1 2 3 4 5 6 7 8 9 10 11 倒计数器 常用方法： new CountDownLatch(int count) //实例化一个倒计数器，count指定初始计数 countDown() // 每调用一次，计数减一 await() //等待，当计数减到0时，阻塞线程（可以是一个，也可以是多个）并行执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 使用： ex： //6个同学(子线程)陆续离开教室后值班同学（主线程）才可以关门 public static void main(String[] args) throws InterruptedException { //1.创建倒计数器对象 CountDownLatch countDownLatch = new CountDownLatch(6); //2.循环创建6个子线程分别执行各自业务（完成课后作业） for (int i = 1; i \u0026lt;= 6; i++) { new Thread(()-\u0026gt;{ System.out.println(Thread.currentThread().getName()+\u0026#34;，开始学习\u0026#34;); try { TimeUnit.SECONDS.sleep(new Random().nextInt(10)); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(Thread.currentThread().getName()+\u0026#34;，结束学习\u0026#34;); countDownLatch.countDown(); }, \u0026#34;同学\u0026#34;+i).start(); } //3.主线程阻塞等待各个子线程执行结束 countDownLatch.await(10, TimeUnit.SECONDS); System.out.println(Thread.currentThread().getName()+\u0026#34;班长锁门，走人！\u0026#34;); } } 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 同学1，开始学习 同学4，开始学习 同学3，开始学习 同学2，开始学习 同学5，开始学习 同学6，开始学习 同学5，结束学习 同学2，结束学习 同学4，结束学习 同学1，结束学习 同学6，结束学习 同学3，结束学习 main班长锁门，走人！ CountDownLatch 与 join 方法的区别\r1 2 3 4 5 6 7 调用一个子线程join()方法后，该线程会一直被阻塞，直到该线程运行完毕 CountDownLatch则使用计数器 允许子线程运行完毕或者运行中时候递减计数 也就是CountDownLatch 可以在子线程运行任何时候让 await 方法返回而不一定必须等到线程结束； (await类似wait，不过wait配合synchronized关键字，await配合lock接口) countDownLatch 相比 Join 方法让我们对线程同步有更灵活的控制。 CyclicBarrier\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 循环栅栏 大概的意思就是一个可循环利用的屏障 主要作用是: 在多个线程相互等待达到某个共同点之后再一起继续执行 常用方法： 1. CyclicBarrier(int parties, Runnable barrierAction) 创建一个CyclicBarrier实例， parties指定参与相互等待的线程数 barrierAction一个可选的Runnable命令，该参数只在每个屏障点运行一次，可以在执行后续业务之前共享状态。该操作由最后一个进入屏障点的线程执行。 2. CyclicBarrier(int parties) 创建一个CyclicBarrier实例，parties指定参与相互等待的线程数。 3. await() 该方法被调用时表示当前线程已经到达屏障点，当前线程阻塞进入休眠状态，`直到所有线程都到达屏障点`，当前线程才会被唤醒。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 使用： ex：组队打boss过关卡游戏 共计三个线程（玩家），要求所有线程执行完某一关（到达某个屏障点），才能够继续执行下一关 public static void main(String[] args) { //1.声明循环栅栏对象 p1:线程数量 p2:所有线程到达屏障点后执行业务-由最后一个到达屏障点线程执行 CyclicBarrier cyclicBarrier = new CyclicBarrier(3, () -\u0026gt; { System.out.println(Thread.currentThread().getName()+\u0026#34;（裁判）,所有玩家都完成该关卡，继续...\u0026#34;); }); //2.创建三个线程，业务逻辑，线程间互相等待，全部到达屏障点，才继续 for (int i = 1; i \u0026lt;= 3; i++) { new Thread(() -\u0026gt; { try { //2.1 模拟当前线程过游戏所有关卡 System.out.println(Thread.currentThread().getName() + \u0026#34;，开始过第1关\u0026#34;); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName() + \u0026#34;，第1关,已过\u0026#34;); cyclicBarrier.await(); //2.2 如果当前线程先到达屏障点，其他线程还未到达，将当前线程进入阻塞状态，一直到其他所有线程全部到达屏障点 System.out.println(Thread.currentThread().getName() + \u0026#34;，开始过第2关\u0026#34;); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName() + \u0026#34;，第2关,已过\u0026#34;); cyclicBarrier.await(); System.out.println(Thread.currentThread().getName() + \u0026#34;，开始过第3关\u0026#34;); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName() + \u0026#34;，第3关,已过\u0026#34;); cyclicBarrier.await(); } catch (Exception e) { throw new RuntimeException(e); } }, \u0026#34;玩家\u0026#34; + i).start(); } } } 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 玩家1，开始过第1关 玩家3，开始过第1关 玩家2，开始过第1关 玩家3，第1关,已过 玩家1，第1关,已过 玩家2，第1关,已过 玩家2（裁判）,所有玩家都完成该关卡，继续... 玩家2，开始过第2关 玩家1，开始过第2关 玩家3，开始过第2关 玩家3，第2关,已过 玩家2，第2关,已过 玩家1，第2关,已过 玩家1（裁判）,所有玩家都完成该关卡，继续... 玩家1，开始过第3关 玩家3，开始过第3关 玩家2，开始过第3关 玩家1，第3关,已过 玩家2，第3关,已过 玩家3，第3关,已过 玩家3（裁判）,所有玩家都完成该关卡，继续... 注：所有的\u0026quot;过关了\u0026quot;都是由最后到达await方法的线程执行打印的\nCyclicBarrier和CountDownLatch的区别\r1 2 3 4 5 6 7 - CountDownLatch允许一个或多个线程等待一组事件的产生 而CyclicBarrier用于等待其他线程运行到栅栏位置 - CountDownLatch的计数器只能使用一次 而CyclicBarrier的计数器可以使用多次 - 所以CyclicBarrier能够处理更为复杂的场景 Semaphore\r1 2 3 4 5 6 7 8 9 10 11 12 13 信号量 Semaphore可以控制同时访问的线程个数 非常适合需求量大，而资源又很紧张的情况 常用方法： public Semaphore(int permits) // 构造方法，permits指资源数目（信号量） public void acquire() throws InterruptedException // 占用资源，当一个线程调用acquire操作时，它要么通过成功获取信号量（信号量减1），要么一直等下去，直到有线程释放信号量，或超时。 public void release() // （释放）实际上会将信号量的值加1，然后唤醒等待的线程。 两个目的：\n1 2 1. 多个共享资源的互斥使用。 2. 用于并发线程数的控制。保护一个关键部分不要一次输入超过N个线程。（限流） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 使用： ex： //6辆车（线程）要进入到停车场共计有3个车位（信号量） public static void main(String[] args) { //1.构建信号量对象 Semaphore semaphore = new Semaphore(3); //2.循环创建6个线程，拿到信号量才能执行线程业务 for (int i = 1; i \u0026lt;= 6; i++) { new Thread(() -\u0026gt; { try { //2.1 每个车辆只有拿到信号才能停车 当前线程会一直阻塞到获取信号为止 semaphore.acquire(); //2.2 线程业务逻辑 System.out.println(Thread.currentThread().getName()+\u0026#34; 抢到了一个停车位！\u0026#34;); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); //2.3 当前车辆业务执行完毕，释放信号量 System.out.println(Thread.currentThread().getName()+\u0026#34; 离开停车位！！\u0026#34;); semaphore.release(); } catch (Exception e) { throw new RuntimeException(e); } }, \u0026#34;\u0026#34; + i).start(); } } } 打印结果：\n1 2 3 4 5 6 7 8 9 10 11 12 0 抢到了一个停车位！！ 1 抢到了一个停车位！！ 2 抢到了一个停车位！！ 1 离开停车位！！ 3 抢到了一个停车位！！ 2 离开停车位！！ 4 抢到了一个停车位！！ 0 离开停车位！！ 5 抢到了一个停车位！！ 5 离开停车位！！ 3 离开停车位！！ 4 离开停车位！！ Callable接口\r1 Thread类和Runnable接口都`不允许声明检查型异常`，`也不能定义返回值`。 1 2 从java5开始，提供了Callable接口 `用Call()方法作为线程的执行体，增强了之前的run()方法。`因为call方法可以有返回值，也可以声明抛出异常。 Callable和Runnable对比\r1 2 3 runnable：弊端：没有返回结果，不能声明抛异常 来自java.lang callable:优势：有返回值，抛异常 来自java.util.concurrent Callable的使用\rFutureTask其实可以充当了一个中间人的角色\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class MyRunnableThread implements Runnable{ @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; Runnable\u0026#34;); } } /** * 1. 创建Callable的实现类，并重写call()方法，该方法为线程执行体，并且该方法有返回值 */ class MyCallableThread implements Callable\u0026lt;Integer\u0026gt; { @Override public Integer call() throws Exception { int i; for (i = 0; i \u0026lt; 10; i++) { Thread.sleep(300); System.out.println(Thread.currentThread().getName() + \u0026#34; 执行了！\u0026#34; + i); } return i; } } public class CallableDemo { public static void main(String[] args) throws InterruptedException, ExecutionException { // 创建多线程 new Thread(new MyRunnableThread(), \u0026#34;threadName\u0026#34;).start(); //new Thread(new MyCallableThread(), \u0026#34;threadName\u0026#34;).start(); // 2. 创建Callable的实例，并用FutureTask类来包装Callable对象 // 3. 创建FutureTask对象，需要一个Callable类型的参数 FutureTask task = new FutureTask\u0026lt;\u0026gt;(new MyCallableThread()); // 4. 创建多线程，由于FutureTask的本质是Runnable的实现类，所以第一个参数可以直接使用task new Thread(task, \u0026#34;MyCallableThread\u0026#34;).start(); //取消任务 // Thread.sleep(1000); // task.cancel(true); //线程运行时可以被打断吗 // boolean cancelled = task.isCancelled(); // System.out.println(\u0026#34;cancelled \u0026#34; + cancelled); //等待任务执行完毕 // while (!task.isDone()) { //也可以使用task.isDone()判断子线程是否执行完毕 // Thread.sleep(100); // System.out.println(\u0026#34;wait...\u0026#34;); // } //获取结果 System.out.println(task.get());//get方法阻塞主线程，因为需要返回子线程的结果 System.out.println(Thread.currentThread().getName() + \u0026#34; over!\u0026#34;); } } FutureTask\r1 2 3 4 FutureTask是 Java 中的一个类，它实现了Future和Runnable接口，用于表示一个可取消的异步计算任务。 FutureTask 的主要作用是： 一个线程中计算结果，另一个线程中获取计算机的结果，同时还支持任务的取消操作 主要作用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 异步计算: 允许开发者在一个线程中执行耗时的计算任务而不会阻塞主线程 获取计算结果： 调用get()方法，获取计算结果。如果计算尚未完成，get()会阻塞当前线程，直到计算完成 取消任务 调用cancel(boolean mayInterruptIfRunning)方法来取消任务的执行。 可以选择是否允许在任务运行时中断任务。 任务状态查询 FutureTask提供了一些方法来查询任务的状态 isDone()用于检查任务是否已完成 isCancelled()用于检查任务是否已被取消。 异常处理 如果异步任务抛出了异常，FutureTask会捕获异常并在后续调用 get()方法时重新抛出。 获取计算结果时处理可能的一场抢矿 注：为了防止主线程阻塞，建议get方法放到最后\n​ 只计算一次，FutureTask会复用之前计算过的结果\ncallable接口与runnable接口的区别？\r1 2 3 4 5 6 7 - 相同点： 都是接口，都可以编写多线程程序，都采用 Thread.start()启动线程 - 不同点： 1. 具体方法不同：一个是run，一个是call 2. Runnable没有返回值；Callable可以返回执行结果，是个泛型 3. Callable接口的call()方法允许抛出异常；Runnable的run()方法异常只能在内部消化，不能往上继续抛 获取多线程的方法\r1 2 3 4 5 6 传统： 继承thread类 runnable接口 java5以后又有 实现callable接口和java的线程池 阻塞队列（BlockingQueue）\r什么是BlockingQueue\r1 所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤起。 BlockingQueue即阻塞队列，是java.util.concurrent下的一个接口\nBlockingQueue是为了解决多线程中数据高效安全传输而提出的。\n1 2 3 4 5 6 7 8 被阻塞情况主要有如下两种： 1. 当队列满了的时候，依然进行入队列操作 2. 当队列空了的时候，依然进行出队列操作 当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作； 当一个线程试图对一个空队列进行出队列操作时，它将会被阻塞，除非有另一个线程进行了入队列操作。 BlockingQueue接口\r主要有以下7个实现类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 1. ArrayBlockingQueue：由数组结构组成的有界阻塞队列。 2. LinkedBlockingQueue：由链表结构组成的有界阻塞队列。 3. PriorityBlockingQueue：支持优先级排序的无界阻塞队列。 4. DelayQueue：使用优先级队列实现的延迟无界阻塞队列。 5. SynchronousQueue：不存储元素的阻塞队列，也即单个元素的队列。 6. LinkedTransferQueue：由链表组成的无界阻塞队列。 7. LinkedBlockingDeque：由链表组成的双向阻塞队列。 阻塞队列提供以下4种处理方法：\n抛出异常\r1 2 3 4 5 6 7 8 add正常执行返回true element（不删除）和remove（删除）返回阻塞队列中的第一个元素 当阻塞队列满时，再往队列里add插入元素会抛IllegalStateException:Queue full 当阻塞队列空时，再从队列里remove移除元素会抛NoSuchElementException 当阻塞队列空时，再调用element检查元素会抛出NoSuchElementException 特殊值\r1 2 3 插入方法，成功ture失败false 移除方法，成功返回出队列的元素，队列里没有就返回null 检查方法，成功返回队列中的元素，没有返回null 阻塞\r1 2 3 4 5 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 当阻塞队列满时，再往队列里put元素，队列会一直阻塞生产者线程，直到put数据or响应中断退出 当阻塞队列空时，再从队列里take元素，队列会一直阻塞消费者线程，直到队列可用 超时\r1 2 3 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。 返回一个特定值以告知该操作是否成功(典型的是 true / false)。 阻塞队列操作\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class BlockingQueueDemo { public static void main(String[] args) throws InterruptedException { //创建有界阻塞队列 队列长度为3 BlockingQueue\u0026lt;String\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(3); // 第一组方法：add remove element System.out.println(queue.add(\u0026#34;a\u0026#34;)); //入队,正常则返回true System.out.println(queue.add(\u0026#34;b\u0026#34;)); System.out.println(queue.add(\u0026#34;c\u0026#34;)); // System.out.println(queue.add(\u0026#34;d\u0026#34;)); //队列已满仍然入队，报异常 IllegalStateException异常 System.out.println(queue.element()); //获取队列中的第一个元素，并返回 System.out.println(queue.remove()); //出队第一个元素，返回出队元素 System.out.println(queue.remove()); System.out.println(queue.remove()); //System.out.println(queue.remove()); //队列已空仍然出队，报异常 NoSuchElementException 没有这样的元素异常 //System.out.println(queue.element()); //队列已空仍然获取元素，报异常 NoSuchElementException 没有这样的元素异常 ------------------------------------------------------- // 第二组：offer poll peek /*System.out.println(queue.offer(\u0026#34;a\u0026#34;)); //入队,正常则返回true System.out.println(queue.offer(\u0026#34;b\u0026#34;)); System.out.println(queue.offer(\u0026#34;c\u0026#34;)); System.out.println(queue.offer(\u0026#34;d\u0026#34;)); //队列已满仍然入队, 返回false System.out.println(queue.peek()); //获取队列中的第一个元素，并返回 System.out.println(queue.poll()); //出队第一个元素，返回出队元素 System.out.println(queue.poll()); System.out.println(queue.poll()); System.out.println(queue.poll()); //队列已空仍然出队，返回null System.out.println(queue.peek()); //队列已空仍然获取元素，返回null*/ --------------------------------------------------- // 第三组：put take ************ /*queue.put(\u0026#34;a\u0026#34;); //入队 queue.put(\u0026#34;b\u0026#34;); queue.put(\u0026#34;c\u0026#34;); System.out.println(queue.take()); //出队第一个元素，返回出队元素，则后面代码不会阻塞 queue.put(\u0026#34;d\u0026#34;); //队列已满仍然入队, 发生阻塞 System.out.println(queue.take()); //出队第一个元素，返回出队元素 System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); //队列已空仍然出队，发生阻塞*/ 阻塞：程序没终止，卡住不动 ---------------------------------------------------- // 第四组：offer poll /*System.out.println(queue.offer(\u0026#34;a\u0026#34;)); //入队,正常则返回true System.out.println(queue.offer(\u0026#34;b\u0026#34;)); System.out.println(queue.offer(\u0026#34;c\u0026#34;)); System.out.println(queue.offer(\u0026#34;d\u0026#34;, 5, TimeUnit.SECONDS)); //队列已满仍然入队,超时返回false System.out.println(queue.poll()); //出队第一个元素，返回出队元素 System.out.println(queue.poll()); System.out.println(queue.poll()); System.out.println(queue.poll(5, TimeUnit.SECONDS)); //队列已空仍然出队，,超时返回null*/ } } 生产者消费者案例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class BlockingQueueDemo2 { public static void main(String[] args) { //创建无界阻塞队列 //BlockingQueue\u0026lt;Integer\u0026gt; queue = new LinkedBlockingDeque\u0026lt;\u0026gt;(); //创建有界阻塞队列：当消费的进度较慢，生产进度较快，而且队列放不下的时候，生产会被自动阻塞，等待消费 BlockingQueue\u0026lt;Integer\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(3); //生产者 new Thread(()-\u0026gt;{ try { for (int i = 1; i \u0026lt;= 10; i++) { queue.put(i); System.out.println(\u0026#34;生产第\u0026#34; + i + \u0026#34;个馒头，\u0026#34; + \u0026#34;目前还剩\u0026#34; + queue.size() + \u0026#34;个馒头\u0026#34;); TimeUnit.SECONDS.sleep(1); } } catch (InterruptedException e) { throw new RuntimeException(e); } }, \u0026#34;生产者\u0026#34;).start(); //消费者 new Thread(()-\u0026gt;{ try { for (int i = 1; i \u0026lt;= 10; i++) { System.out.println(\u0026#34;消费第\u0026#34; + queue.take() + \u0026#34;个馒头\u0026#34; + \u0026#34;目前还剩\u0026#34; +queue.size() + \u0026#34;个馒头\u0026#34;); TimeUnit.SECONDS.sleep(3); } } catch (InterruptedException e) { throw new RuntimeException(e); } }, \u0026#34;消费者\u0026#34;).start(); } } SynchronousQueue\r作用场景：生产并直接交付\n详情看笔记\n线程池\r1 2 3 4 异步调用：做一些远程调用，微服务调用，这个时候需要创建线程池，通过线程池来执行远程调用。 异步方式进行远程调用： 6个远程接口没有业务上先后顺序的要求，可以6个请求一起发送，6个结果一起回来，然后组装数据，返回前端 ex：1s 但同步：6s 线程池是通过Executor框架实现的\n该框架用了\n1 2 3 4 5 Executor：execute(runnable command)执行任务的方法 ExecutorService：继承Executor submit ThreadPoolExecutor： 线程池框架\r创建一个线程池对象\n1 通常使用Executors工具类 面试题：execute和submit的区别\n1 2 3 4 5 6 7 8 9 10 11 1. execute是Executor接口的方法。 submit是ExecutorService的方法 ExecutorService接口继承了Executor接口。 2. execute只接受Runnable参数 没有返回值 submit可以接受Runnable参数和Callable参数 返回了Future对象，可以进行任务取消、获取任务结果、判断任务是否执行完毕/取消等操作。 3. 通过execute方法提交的任务无法获取具体的异常信息； submit方法可以通过Future对象获取异常信息。 Executors(禁用)\r线程池工作原理\r如何创建线程池？\r​ 使用Executors工厂 ​ 使用ThreadPoolExecutor构造函数\n7个参数\rThreadPoolExecutor的七个参数:\rcorePoolSize（核心池大小）不会被回收\rmaximumPoolSize（最大池大小）会被回收\rkeepAliveTime（线程空闲存活时间）\runit（时间单位）\rworkQueue（工作队列）\rLinkedBlockingQueue大小无限制\rArrayBlockingQueue大小有限，必须指定容量\rSynchronousQueue不存储任务,直接给线程池\rthreadFactory（线程工厂）\rhandler（拒绝策略）\rAbortPolicy: 直接抛出异常\rCallerRunsPolicy：返回给调用者线程执行该任务\rDiscardPolicy：直接丢弃该任务\rDiscardOldestPolicy：丢弃最旧的一个任务\r线程池工作原理\r1 2 3 4 5 工作原理: 提交新任务时,线程池进行判断是否有空闲线程,有就直接执行,没有就查看是否到达核心线程数,没有就创建新的线程执行, 如果达到核心线程数但任务队列有空间,进入任务队列, 如果任务队列也已经满了,查看是否到达最大线程数,没有到达最大线程数就创建新的线程,若到达最大线程数,执行拒绝策略 当队列中的任务执行完,线程空闲时间到达预设时间,销毁超出核心线程数的线程 1 2 3 4 5 6 7 8 9 10 11 虽然也是有请求就创建，但它会判断，如果满了就去判断任务队列，任务队列如果满了会取判断最大线程池，最后还是不够会交给拒绝策略处理 并不是无所节制的创建线程** 最大线程数包括核心线程数 注意，队列若满，最大线程数有空，会直接创建新线程执行，并不会让对头出队 比如13来了，去创建13的 为什么？因为这样比出队相率更高 拒绝策略\r以上内置的策略均实现了RejectedExecutionHandler接口，也可以自己扩展RejectedExecutionHandler接口，定义自己的拒绝策略\n实际业务哪个都基本不用，最常用的是自定义拒绝策略（线程睡一觉等自定义饱和拒绝策略）\n1 2 3 4 5 6 7 存储任务，将来人工处理 发邮件、发短信警告 睡一会，再次将任务提交线程池处理 等等等 自定义线程池\r案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package com.atguigu.demojuc.chap08; class MyRunnable implements Runnable{ private int param; public MyRunnable(int param) { this.param = param; } @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; Runnable......\u0026#34; + param); } } public class CustomizeThreadPoolDemo { public static void main(String[] args) { // 自定义连接池 ExecutorService threadPool = new ThreadPoolExecutor( 2,//核心线程数 5,//最大线程数 2,//等待空闲时间，时间到达会销毁非核心线程数。核心线程不销毁 0就是不销毁 TimeUnit.SECONDS,//时间单位 new ArrayBlockingQueue\u0026lt;\u0026gt;(3),//任务等待队列 Executors.defaultThreadFactory(),//线程工厂 new ThreadPoolExecutor.AbortPolicy() //饱和拒绝策略 //丢弃任务并抛出异常 //new ThreadPoolExecutor.CallerRunsPolicy() //由调用线程处理该任务，谁调用谁处理 //new ThreadPoolExecutor.DiscardOldestPolicy() //丢弃队列中等待最久的任务，添加新任务 //new ThreadPoolExecutor.DiscardPolicy() //也是丢弃任务，但是不抛出异常。 /*new RejectedExecutionHandler() { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { System.out.println(\u0026#34;自定义拒绝策略\u0026#34;); } }*/ ); try { for (int i = 0; i \u0026lt; 9; i++) { //execute()方法只能接收Runnable参数 threadPool.execute(() -\u0026gt; { //submit()方法可以接收Runnable或Callable 推荐 //threadPool.submit(() -\u0026gt; { //这里也可以使用submit System.out.println(Thread.currentThread().getName() + \u0026#34;执行了业务逻辑\u0026#34;); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool.shutdown();//关闭线程池，但实际业务基本不关 } } } 总结\r线程池主要作用：\n1 有效地管理和复用线程，以提高多线程应用程序的性能和资源利用率。 优点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 线程复用：线程池会在池中维护一组可重用的线程，这些线程可以反复执行任务。 线程的复用减少了线程创建和销毁的开销，提高了执行任务的效率。 //--------------------------- 2. 任务队列：线程池通常与任务队列结合使用，将待执行的任务排队等待执行。 这允许任务按顺序执行，控制并发度，防止任务过多导致资源耗尽。 //------------------------- 3. 线程生命周期管理：线程池可以管理线程的生命周期，包括线程的创建、销毁、超时处理等。(线程工厂管线程生命周期管理) 这有助于减少资源泄漏和提高系统的稳定性。 //---------------------------- 4. 可控性：线程池允许您控制线程的数量、最大并发数、线程优先级等参数，以满足不同应用场景的需求。 弹性伸缩，少了--\u0026gt;最小 多了--\u0026gt;最大，再多就拒绝策略处理 多线程高并发底层原理\rJava内存模型(JMM)\r计算机硬件\n1 2 3 4 5 CPU 通过CPU缓存和CPU寄存器来提高数据访问速度，减少对RAM的访问次数，提高对RAM的访问效率，从而提高计算机的性能。 （ROM只读不能写） （RAM随机存取存储器 能读能写） 1 2 JMM屏蔽了屏蔽系统和硬件的差异 故java一次编译到处运行 JMM规定了内存主要划分为主内存和工作内存两种。\n主内存对应的是硬件的物理内存\n工作内存对应的是寄存器和高速缓存。\n共享变量：\n1 2 3 4 5 6 7 8 如果一个变量被多个线程使用，那么这个变量会在每个线程的工作内存中保有一个副本，这种变量就是共享变量。 数据放主内存中，为什么是共享： 因为数据被多个线程共享 但是因为写操作无法并发， 故线程要操作共享变量，会将共享变量拷贝一份，放到当前线程的本地内存当中来进行数据的处理 数据改了后再写回主内存，这叫做数据的同步 主内存：\n1 保存了所有的共享变量。 工作内存：\n1 每个线程都有自己的工作内存，线程独享，保存了线程用到的变量副本（主内存共享变量的一份拷贝）。 JMM对共享内存的操作做出了如下两条规定：\n1 2 3 4 5 6 - 线程对共享内存的所有操作都必须在自己的工作内存中进行，不能直接从主内存中读写； 数据改了后再写回主内存，这叫做数据的同步 - 不同线程无法直接访问其他线程工作内存中的变量，因此共享变量的值传递需要通过主内存完成。 只有将改后数据写回到主内存中，另一个线程将其从主内存中读走才能获得最新数据 ava内存模型的三大特性\n可见性 有序性 原子性 volatile关键字\r可见性\r1 2 3 4 5 6 7 使用volatile关键字可以确保共享变量的可见性 当一个变量被声明为volatile时 每次访问该变量时都会从主内存中读取最新的值 并且对该变量的修改会立即写入主内存，而不是先写入缓存 避免了在多线程环境下出现数据不一致的问题 因为任何对volatile变量的修改都会立即可见于其他线程 有序性\r1 2 3 将变量声明为volatile 可以避免指令重排的优化机制，保证指令的执行顺序与源代码中的顺序一致 以避免多线程环境下的错误 原子性\r从0到1000\n1000个线程执行++number操作，如果++number操作具备原子性，最后的值应该是1000。说明++number不具备原子性。\n给number添加volatile关键字\n测试结果依然不是1000\n尝试给++number方法加同步锁\n结果达成\n说明volatile关键字不能保证原子性。\n1 2 3 volatile关键字只能保证单个变量的可见性，并不能解决原子性问题。 对于原子性需求，需要使用更强大的同步机制，如锁、原子操作等。 保证三大特性\r1 2 3 4 5 6 7 8 可见性： 使用volatile关键字声明变量，确保修改对于所有线程立即可见 有序性： volatile保证对该变量的读写操作是有序的，禁止重排序 原子性： synchronized同步锁确保对共享变量的操作是原子的 atomic提供的原子类AtomicInteger、AtomicLong等 CAS\rAQS\r1 2 3 4 5 6 7 8 9 AbstractQueuedSynchronizer抽象队列同步器简称AQS 是整个java.util.concurrent包的核心 AQS框架提供了一套通用的机制来 管理同步状态（synchronization state）、阻塞/唤醒线程、管理等待队列。 JUC下的Lock（ReentrantLock、ReentrantReadWriteLock等）以及并发工具类（Semaphore、CountDownLatch、CyclicBarrier等）就是通过AQS实现的 什么是AQS\r1 2 3 4 5 6 7 一个状态值+双端队列(FIFO)（左进右出，右进左出） - FIFO：意味着等待时间最长的线程将首先获得锁或资源（公平锁排队）。 - 双向队列：意味着允许多个线程同时从队列的两端进行插入、删除和查找操作（非公平锁插队）。 队列里放等待的线程 1 2 3 4 5 6 7 8 9 10 11 12 请求获取锁-\u0026gt;入队 多线程并发执行任务，加锁 怎么加： 线程去抢AQS类里state属性(资源)，初始为0表示锁没人用，抢到了后0变为1.变为1后其他线程就不能抢，得在队列里排队，直到state变为0(线程任务执行完了 也就是释放锁) 公平锁：排队使用 公平锁指的是按照线程请求的顺序，来分配锁 非公平锁： 一定情况下，可以允许插队 当前线程在请求获取锁的时候，恰巧前一个持有锁的线程释放了这把锁，那么当前申请锁的线程就可以不顾已经等待的线程而选择立刻插队。 但是如果当前线程请求的时候，前一个线程并没有在那一时刻释放锁，那么当前线程还是一样会进入等待队列。 state 属性：表示资源的状态\n1 2 3 - 对于ReentrantLock来说，state=1，表示资源被占用；state=0，表示资源没有被占用。 - 对于CountDownLatch来说，state=0，表示计数器归零，所有线程都可以访问资源；state为N表示计数器未归零，所有线程都需要阻塞。 ReentrantLock\r默认非公平锁\n在ReentrantLock类中包含了3个AQS的实现类：\n抽象类Sync 非公平锁实现类NonfaireSync 公平锁实现类FairSync 上锁，调试公平锁，解锁\r详情看笔记\nAQS的底层原理\r1 2 3 4 5 6 7 AQS使用一个volatile成员变量state来表示锁是否已被持有，通过内置的FIFO队列存储被阻塞的线程。 AQS使用CAS机制对state进行原子操作从而对state的值进行修改。 如果state的值为0，表示锁未被持有，则将当前线程设置为工作线程（即获取到了锁），并将state的值设置为1，返回成功获取到锁。 如果未能成功获取到锁，AQS先自旋获取锁，如果一直获取不到，则将当前获取不到锁的线程加入到FIFO队列中 1 2 3 4 5 6 7 8 9 10 11 12 构成： AQS使用一个volatile成员变量state来表示锁是否已被持有(0/1)，通过内置的FIFO队列存储被阻塞的线程 怎么改state： AQS使用CAS机制对state进行原子操作从而对state的值进行修改 怎么取到锁: 如果state的值为0，表示锁未被持有，则将当前线程设置为工作线程（即获取到了锁），并将state的值设置为1，返回成功获取到锁。 取不到怎么办： 如果未能成功获取到锁，AQS先自旋获取锁 如果一直获取不到，则将当前获取不到锁的线程加入到FIFO队列中 注：FIFO公平锁 双向队列：非公平锁\n自旋锁\r1 2 3 4 5 6 7 8 是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。 这样获取锁的线程一直处于活跃状态 但是并没有执行任何有效的任务 长时间使用这种锁会造成系统负载很大，耗费性能，阻止了其他线程的运行和调度 自旋的线程保持旋转状态(反复尝试获取锁)，而持有该锁的线程并不打算释放锁，这样导致的是结果是无限期推迟，直到持有锁的线程可以完成并释放它为止。 对于ReentrantLock来说，自旋的过程就是不断尝试 调用lock()的过程（使用CAS的方式修改state值） 对于原子操作类来说，自旋的过程就是比较和交换失败后再次尝试比较和交换的过程（CAS） 自旋锁优点\r1 2 3 4 5 1.自旋锁尽可能的减少线程的阻塞 这对于锁的竞争不激烈，且占用锁时间非常短的代码块 来说性能能大幅度的提升 因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗 2.不使用自旋，并且获取不到锁的时候直接进入阻塞状态 自旋锁缺点\r1 2 3 4 5 6 7 如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块 这种情况不适合使用自旋锁 因为自旋锁在获取锁前一直都是占用 cpu 做无用功，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cpu 的线程又不能获取到 cpu，造成 cpu 的浪费。 所以这种情况下我们要关闭自旋锁。 synchronized锁升级过程\r无锁状态：没有线程来申请锁\n偏向锁状态：只有一个线程来申请锁，【没有竞争】，不需要做加锁、解锁的操作\n从无锁状态到当前状态，每次来申请锁的都是这同一个线程，中间没有别的线程来申请过 轻量级锁状态：只有一个线程来申请锁，【没有竞争】，不需要做加锁、解锁的操作\n从上一个状态到现在状态，锁对象被不同线程申请过，只不过每次都是只有一个线程来申请 重量级锁状态：同时有多个线程来申请锁，【有竞争】，需要做加锁、解锁的操作\n","date":"2025-01-09T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/juc_wzt/","title":"juc_wzt"},{"content":"说说线程的状态？\r​\t新建（New）：线程被创建但尚未启动执行。\n​\t就绪（Runnable）：线程等待CPU时间片以便执行，也就是处于就绪状态。\n​\t阻塞（Blocked）：线程暂停执行，通常是因为等待某些条件满足，例如等待I/O操作完成、等待锁释放等。\n​\t无限期等待（Waiting）：线程无限期地等待某个条件的发生，通常需要其他线程来唤醒它。\n​\t有限期等待（Timed Waiting）：线程等待一段时间，超过指定时间后会自动唤醒。\n​\t终止（Terminated）：线程执行完成或者异常终止，进入终止状态。\n线程创建方式有哪些?\r​\t继承Thread抽象类\n​\t实现Runnable接口\n​\t实现Callable接口\n​\t通过ThreadPoolExecutor线程池\n并发安全集合类都哪些？\r​ ConcurrentHashMap 是线程安全的哈希表实现,它通过分段锁的机制来实现并发访问的高效性。 ​ CopyOnWriteArrayList 是线程安全的 List 实现，它通过复制底层数组的方式保证线程安全，适用于读多写少的场景。\n​ CopyOnWriteArraySet 是 CopyOnWriteArrayList 的 Set 版本\n​ BlockingQueue 是一个用于在多线程间传递数据的队列接口,它包含多个实现类，如 ArrayBlockingQueue、LinkedBlockingQueue\n如何创建线程池？说说7个参数和线程池工作原理?\r​ 使用Executors工厂\n​ 使用ThreadPoolExecutor构造函数\nThreadPoolExecutor的七个参数:\rcorePoolSize（核心池大小）不会被回收\rmaximumPoolSize（最大池大小）会被回收\rkeepAliveTime（线程空闲存活时间）\runit（时间单位）\rworkQueue（工作队列）\rLinkedBlockingQueue大小无限制\rArrayBlockingQueue大小有限，必须指定容量\rSynchronousQueue不存储任务,直接给线程池\rthreadFactory（线程工厂）\rhandler（拒绝策略）\rAbortPolicy: 直接抛出异常\rCallerRunsPolicy：返回给调用者线程执行该任务\rDiscardPolicy：直接丢弃该任务\rDiscardOldestPolicy：丢弃最旧的一个任务\r工作原理:\r提交新任务时,线程池进行判断是否有空闲线程,有就直接执行,没有就查看是否到达核心线程数,没有就创建新的线程执行,\r如果达到核心线程数但任务队列有空间,进入任务队列,\r如果任务队列也已经满了,查看是否到达最大线程数,没有到达最大线程数就创建新的线程,若到达最大线程数,执行拒绝策略\r当队列中的任务执行完,线程空闲时间到达预设时间,销毁超出核心线程数的线程\rJMM模型特性有哪些？如何保证这些特性?\r​ 可见性\n​\t使用 volatile关键字声明变量,确保修改对于所有线程立即可见\n有序性\nvolatile 保证对该变量的读写操作是有序的，禁止重排序。\n​ 原子性 ​\nsynchronized同步锁确保对共享变量的操作是原子的。\n​\tatomic提供的原子类AtomicInteger、AtomicLong等\n","date":"2025-01-09T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/juc%E7%9B%B8%E5%85%B3/","title":"juc相关"},{"content":"ReentrantLock和synchronized区别\r1)synchronized是独占锁，加锁和解锁的过程自动进行，易于操作，但不够灵活。ReentrantLock也是独占锁，加锁和解锁的过程需要手动进行，不易操作，但非常灵活。\r2)synchronized可重入，因为加锁和解锁自动进行，不必担心最后是否释放锁；ReentrantLock也可重入，但加锁和解锁需要手动进行，且次数需一样，否则其他线程无法获得锁。\r3)synchronized不可响应中断，一个线程获取不到锁就一直等着；ReentrantLock可以响应中断（tryLock方法：获取不到锁则返回false）。\r4)synchronized不具备设置公平锁的特点，ReentrantLock可以成为公平锁。\rReentrantReadWriteLock适用什么业务场景？有什么特点？\r适用于读多，写少业务场景；\r1). 写写不可并发\r2). 读写不可并发/写读不可并发\r3). 读读可以并发\r读写锁允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。\r支持公平/非公平策略\r支持可重入\r- 同一读线程在获取了读锁后还可以获取读锁\r- 同一写线程在获取了写锁之后既可以再次获取写锁又可以获取读锁\r- 同一读线程在获取了读锁后[不可以]获取写锁\r在读线程非常多，写线程很少的情况下，很容易导致写线程“饥饿”，虽然使用“公平”策略可以一定程度上缓解这个问题，但是“公平”策略是以牺牲系统吞吐量为代价的。\t什么是CAS?说说优缺点？\rCAS，即Compare-And-Swap，是一种用于多线程编程中的同步原语。它的主要作用是在并发环境下保证数据的一致性和线程安全。\rCAS操作包含三个基本步骤：比较、交换和返回结果。\rCAS的优点\r高效性：CAS操作通常比锁机制更轻量级，因为它避免了线程阻塞和上下文切换的开销。在多核处理器上，CAS可以显著提高性能，因为它减少了锁竞争和等待时间。\r非阻塞性：由于CAS是非阻塞的，多个线程可以同时尝试更新同一个变量，而不会导致死锁或活锁的问题。这使得系统能够更好地利用多核处理器的能力，提高了并行度和吞吐量。\r简化代码：使用CAS可以减少显式的锁管理，从而简化代码逻辑，使代码更加简洁易读。开发者不需要担心锁的获取和释放，也不需要处理锁的细粒度控制问题。\r避免死锁：CAS操作不会导致死锁，因为它不会持有任何锁，也不会阻塞其他线程。这降低了系统的复杂性，减少了潜在的错误和风险。\r适用于简单场景：对于简单的数据结构和操作，CAS是一种非常有效的同步机制。它可以快速地检查和更新共享变量的值，而无需额外的同步措施。\rCAS的缺点\rABA问题：当一个线程读取变量的值并准备更新时，另一个线程可能已经修改了该值并重新写回了原值，导致CAS操作误认为没有发生变化。这种情况称为ABA问题（A-B-A），它会引发竞态条件，导致数据不一致。\r循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。因为线程会不断地进行CAS操作，直到成功为止，这可能导致CPU资源的浪费和性能下降。\r只能保证一个共享变量的原子操作：当对多个共享变量进行原子操作时，循环CAS无法保证其原子性。这意味着在复杂的操作中，可能需要额外的同步机制来确保数据的一致性。\r适用场景有限：CAS主要适用于简单的同步场景，对于复杂的操作和数据结构，可能需要使用更高级的同步机制。例如，在涉及多个变量的操作中，CAS可能无法提供足够的原子性和一致性保证。\r可能导致性能下降：在高争用的环境中，大量的线程可能会频繁地进行CAS操作，导致CPU缓存行失效和内存带宽的消耗。这可能会降低系统的性能，尤其是在多核处理器上。\r总的来说，CAS是一种强大的工具，它在适当的场景下可以提供高效的并发控制。然而，开发者需要谨慎使用CAS，以避免潜在的问题和陷阱。在选择是否使用CAS时，应考虑具体的应用场景、性能要求以及系统的复杂性。\rAQS的底层原理？\rAQS使用一个volatile成员变量state来表示锁是否已被持有，通过内置的FIFO队列存储被阻塞的线程。\rAQS使用CAS机制对state进行原子操作从而对state的值进行修改。\r如果state的值为0，表示锁未被持有，则将当前线程设置为工作线程（即获取到了锁），并将state的值设置为1，返回成功获取到锁。\r如果未能成功获取到锁，AQS先自旋获取锁，如果一直获取不到，则将当前获取不到锁的线程加入到FIFO队列中\r说说synchronized锁升级过程？\r- 无锁状态：没有线程来申请锁\r- 偏向锁状态：只有一个线程来申请锁，【没有竞争】，不需要做加锁、解锁的操作\r- 从无锁状态到当前状态，每次来申请锁的都是这同一个线程，中间没有别的线程来申请过\r- 轻量级锁状态：只有一个线程来申请锁，【没有竞争】，不需要做加锁、解锁的操作\r- 从上一个状态到现在状态，锁对象被不同线程申请过，只不过每次都是只有一个线程来申请\r- 重量级锁状态：同时有多个线程来申请锁，【有竞争】，需要做加锁、解锁的操作 ","date":"2025-01-09T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E9%94%81%E7%9B%B8%E5%85%B3/","title":"锁相关"},{"content":"Docker介绍\rDocker作用：\r解决环境差异，引发不兼容问题。\r快速搭建环境，快速水平扩展(集群)\r一次构建，应用到处运行。\rdocker 是一个开源的应用容器引擎，基于 Go 语言开发。\r好处：\r可移植性\r可伸缩\r隔离性\r资源利用率高\r镜像加速器配置：\rsudo mkdir -p /etc/docker\rsudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF'\r{\r\u0026quot;registry-mirrors\u0026quot;: [\r\u0026quot;https://registry.dockermirror.com\u0026quot;,\r\u0026quot;阿里镜像\u0026quot;,\r\u0026quot;https://docker.nju.edu.cn\u0026quot;,\r\u0026quot;https://hub.littlediary.cn\u0026quot;,\r\u0026quot;https://hub.xdark.top\u0026quot;,\r\u0026quot;https://dockerpull.org\u0026quot;,\r\u0026quot;https://hub.crdz.gq\u0026quot;,\r\u0026quot;https://docker.1panel.live\u0026quot;,\r\u0026quot;https://docker.unsee.tech\u0026quot;\r]\r}\rEOF\rsudo systemctl daemon-reload\rsudo systemctl restart docker\r镜像常用命令\r查看镜像：\r中央仓库连接不上。进行 【docker search 镜像名称】 会报超时问题。暂时不管或科学上网。\rdocker search redis\rError response from daemon: Get \u0026quot;https://index.docker.io/v1/search?q=redis\u0026amp;n=25\u0026quot;: net/http: TLS handshake timeout\r拉取镜像(下载)\rdocker pull 镜像名称[:tag] 如果不指定版本号，表示下载最新版本\r删除镜像\r# 删除单个镜像(-f 强制删除)：\rdocker rmi -f 镜像ID\rdocker rmi -f $(docker images -q)\t# 慎用 根据id删除所有镜像\r帮助命令：\r哪里命令不会，就在哪个命令后面增加--help查询帮助文档。\rdocker images --help\rdocker xxx --help\r容器常用命令\r1.查询容器\rdocker ps 只查看正在运行的容器\rdocker ps -a\t正在运行的容器以及停止的容器\tdocker ps -q\t只查看正在运行的容器id\rdocker ps -aq\t查看正在运行的容器以及停止的容器的id\r2.创建容器\r-i：表示运行容器\r-t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。\r--name :为创建的容器命名。\r-d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。\r1.创建交换式容器\rdocker run -it --name=mycentos centos:7 /bin/bash\t交互式容器一旦创建成功(创建+启动)，那么，直接进入容器内部(每一个容器都是一个最小型虚拟机)。\rexit 首次退出会停止容器。重新启动容器后登录，再退出。容器就不会停止。\r2.创建守护式容器\rdocker run -id --name=mycentos centos:7\t3.停止容器、启动容器、重启容器\rdocker stop 容器名称或id\rdocker start 容器名称或id\rdocker restart 容器名称或id\r4.删除容器 （-f force）\rdocker rm -f 容器名称或id\r删除正在运行的容器是不允许的。可以先停止再删除 或 加 -f 强制删除。\rdocker rm spzx_mysql\rError response from daemon: cannot remove container \u0026quot;/spzx_mysql\u0026quot;: container is running: stop the container before removing or force remove\r5.登录容器\rdocker exec -it 容器名称 /bin/bash\r6.其他命令\rdocker logs -f 容器名称/容器的id\t# 查询容器内进程日志，-f参数表示实时监控日志信息 ctrl + c\rdocker inspect 容器名称/容器的id\t# 查看容器的详情信息\rdocker cp # 完成容器和宿主机之间的文件copy 容器即使停止也可以拷贝。\tdocker cp ./nginx.tar mycentos_01:/opt\tdocker cp mycentos_01:/opt/nginx.tar ./\r7.备份与迁移\rdocker commit 容器名称/容器的id 镜像名称\t# 把docker容器保存成一个镜像\rdocker save -o 镜像tar文件名称 镜像名称/镜像id\t# 把镜像保存为tar文件\rdocker load -i 镜像tar文件名称\t# 把tar文件恢复成为一个镜像\r数据卷\r数据卷就是将容器里的目录和宿主机目录进行映射。将容器里的目录数据备份到宿主机目录里。容器删除，容器里的数据没了。\r但是，重新创建容器，将容器里的目录跟宿主机目录进行挂载 ，数据就可以找回。(异地备份)\r关于数据卷的操作：\rdocker volume ls # 查看数据卷列表\rdocker volume create 数据卷名称 # 创建数据卷生成的宿主机上的物理路径： /var/lib/docker/volumes/数据卷名称/_data docker volume inspect 数据卷名称 # 查看数据详情\rdocker volume rm 数据卷名称 # 删除指定的数据卷\r数据卷挂载：案例\rdocker run -d --name=redis01 -p 6380:6379 -v redis-data:/data redis:7.0.10\r目录挂载：案例\tdocker run -d --name redis02 -p 6381:6379 -v /redis-data:/data redis:7.0.10\rdockerfile\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 dockerfile就是一个编写相关指令的文本文件。通过这个文件可以创建想要的镜像。 阿里云公开镜像： 1. 登录阿里云Docker Registry $ docker login --username=yanjingkuang01 registry.cn-hangzhou.aliyuncs.com 用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。 您可以在访问凭证页面修改凭证密码。 2. 将镜像推送到Registry $ docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/docker_xxx/centos7_jdk17:[镜像版本号] $ docker push registry.cn-hangzhou.aliyuncs.com/docker_xxx/centos7_jdk17:[镜像版本号] 3. 从Registry中拉取镜像 $ docker pull registry.cn-hangzhou.aliyuncs.com/docker_xxx/centos7_jdk17:[镜像版本号] docker compose\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Docker Compose作用：批量管理容器。 # 启动容器(如果不存在容器就创建、存在则修改) docker compose -f docker-compose.yml up -d # 删除所有容器 docker compose -f docker-compose.yml down # 停止所有容器 docker compose -f docker-compose.yml stop # 启动所有容器 docker compose -f docker-compose.yml start # 重启所有容器 docker compose -f docker-compose.yml restart ","date":"2025-01-06T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/docker%E5%85%A5%E9%97%A8/","title":"docker入门"},{"content":"知识点一：逻辑删除\r数据库添加字段 , 实体类添加属性 , 配置逻辑删除生效\n知识点二：@JsonIgnore\r: 忽略实体类的某个属性不转成也不接收JSON数据\n@JsonIgnore\n@TableLogic\n@Schema(description = \u0026ldquo;逻辑删除\u0026rdquo;)\n@TableField(\u0026ldquo;is_deleted\u0026rdquo;)\nprivate Byte isDeleted;\n知识点三：自动填充\r指定填充字段和策略 属性上-\u0026gt; @TableFiled(fill = FieldFill.Insert | Update ) 定义填充值实现类 MetaObjectHandler(common模块下 / mybatis-plus\u0026hellip;)\n@Component\npublic class MyMetaObjectHandler implements MetaObjectHandler {\n@Override\npublic void insertFill(MetaObject metaObject) {\nthis.strictInsertFill(metaObject, \u0026ldquo;属性名\u0026rdquo;, 属性类型.class, 填充的值); } 1 2 3 4 5 @Override public void updateFill(MetaObject metaObject) { log.info(\u0026#34;开始更新填充...\u0026#34;); this.strictUpdateFill(metaObject, \u0026#34;属性名\u0026#34;, 属性类型.class, 填充的值); } } 知识点四：自定义转化器\r基础转化器：\n1.1 定义个转化器类 实现 Converter\u0026lt;String,目标类型\u0026gt;接口\n1.2 重写转化方法 目标类型 converter方法(String 原数据值)\n1.3 方法中实现类型转化 if || 枚举.values() + for || 超出值范围抛异常\n1.4 springmvc的配置类中添加自定义转化器 addFormatter() 转化器工厂：\n1.1 定义工厂类 实现 ConverterFactory\u0026lt;String,枚举的接口\u0026gt;\n1.2 重写创建转化器的方法getConverter\n1.3 getConverter方法new Converter对象完成转化逻辑编写（class）\nclass.getEnumContents() == 枚举类型.values() 1.4 注册转化器工厂\nregistry.addConverterFactory(stringToBaseEnumConverterFactory); 2. json类型的转化器jackson\n@JsonValue即可完成json和枚举值的处理\n3. 数据库存储和获取转化器mybatis(typeHandler)\nhttps://www.baomidou.com/guides/auto-convert-enum/ @EnumValue //mybatis-plus 向数据库存储数据的时候，获取code属性进行存储 || 读取数据库数据的时候，将值赋值给code\n转换器工厂：实现implements ConverterFactory\u0026lt;String, BaseEnum\u0026gt;接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Component public class StringToBaseEnumConverterFactory implements ConverterFactory\u0026lt;String, BaseEnum\u0026gt; { @Override public \u0026lt;T extends BaseEnum\u0026gt; Converter\u0026lt;String, T\u0026gt; getConverter(Class\u0026lt;T\u0026gt; targetType) { return new Converter\u0026lt;String, T\u0026gt;() { @Override public T convert(String source) { for (T enumConstant : targetType.getEnumConstants()) { if (enumConstant.getCode() == Integer.parseInt(source)) { return enumConstant; } } throw new RuntimeException(\u0026#34;类型错误\u0026#34;); } }; } } 知识点五：多表查询注意点：\r多表查询，需要自定义查询 方法和结果集映射（外连接 | resultMap） 自定义查询需要处理逻辑删除条件问题 is_deleted = 0 外连接条件 where和on条件的区别\n一旦使用外连接， where后面不能放子表的查询条件。 情况： 主表有数据 子表没数据 条件都不为nul都出现问题 解决： on后面可以添加子表的条件，on在合并之前进行赛选。 on后面的条件不会破坏外连接的特性， 一定保证主表的数据会被查询到。 知识点六：\r知识点七：全局异常处理\r①在common模块写一个类 加注解@RestControllerAdvice ②在这个类的方法上面加注解 @ExceptionHandler\n1 2 3 4 5 6 全局异常处理实现(common | springmvc) common中导入web-starter (springmvc jackson) \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 知识点八：文件上传-minio\r注意事项: 文件上传默认的大小是1MB 修改文件: spring: servlet: multipart: max-file-size: 20MB #单个文件大小 max-request-size: 60MB # 一次请求的大小 ①@ConfigurationProperties(prefix=\u0026ldquo;minio\u0026rdquo;) 必须加入到ioc容器 方式一 ：@Component\n方式二：EnableConfigurationProperties(xxx.class)\n1 2 3 4 5 6 7 8 9 @ConfigurationProperties(prefix = \u0026#34;minio\u0026#34;) @Data public class MinioProperties { //@Value(\u0026#34;${minio.endpoint}\u0026#34;) 单独读取 private String endpoint; private String accessKey; private String secretKey; private String bucketName; } ②web / web-admin /application配置文件声明参数 声明四个参数\n1 2 3 4 5 minio: endpoint: \\http://47.94.86.115:9000 #注意: 不要加 / secret-key: minioadmin access-key: minioadmin bucket-name: lease0923 ③编写minioClient的配置类 (MinioClient加入ioc容器)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @EnableConfigurationProperties(MinioProperties.class) @Configuration public class MinioConfiguration { @Autowired private MinioProperties minioProperties; @Bean public MinioClient minioClient(){ MinioClient minioClient = MinioClient.builder().endpoint(minioProperties.getEndpoint()). credentials(minioProperties.getAccessKey(), minioProperties.getSecretKey()).build(); return minioClient; } } ④编写文件上传的具体业务 FileController | FileService\u0026hellip;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 String url = fileService.uploadFile(file); return Result.ok(url); @Override public String uploadFile(MultipartFile file) throws ServerException, InsufficientDataException, ErrorResponseException, IOException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException { //步骤1: 判断桶是否存在 boolean bucketExists = minioClient.bucketExists(BucketExistsArgs.builder().bucket(minioProperties.getBucketName()).build()); //步骤2: 不存在,创建桶以及设置访问权限 if (!bucketExists) { //创建桶 minioClient.makeBucket(MakeBucketArgs.builder().bucket(minioProperties.getBucketName()).build()); //设置权限 //设置hello-minio桶的访问权限 String policy = \u0026#34;\u0026#34;\u0026#34; { \u0026#34;Statement\u0026#34; : [ { \u0026#34;Action\u0026#34; : \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34; : \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34; : \u0026#34;arn:aws:s3:::%s/*\u0026#34; } ], \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34; }\u0026#34;\u0026#34;\u0026#34;.formatted(minioProperties.getBucketName()); minioClient.setBucketPolicy(SetBucketPolicyArgs.builder(). bucket(minioProperties.getBucketName()) .config(policy).build()); } //步骤3: 向桶中传递文件 //todo: 文件重名的问题 uuid + file.getOriginalFilename() //todo: 文件直接放在桶中太乱的问题 // 20241210/uuid_对象名.png String objectName = new SimpleDateFormat(\u0026#34;yyyyMMdd\u0026#34;).format(new Date()) + \u0026#34;/\u0026#34; + UUID.randomUUID().toString().replaceAll(\u0026#34;-\u0026#34;,\u0026#34;\u0026#34;) + \u0026#34;_\u0026#34; + file.getOriginalFilename(); //minioClient.uploadObject() 传递本地存在的文件 c d f ... filename = 文件的地址 //minioClient.putObject() 传递内存中存在文件数据 流 | 字节数组 minioClient.putObject(PutObjectArgs.builder() .bucket(minioProperties.getBucketName()) .object(objectName) .stream(file.getInputStream(),file.getSize(),-1) //-1 不切割原有文件大小 .contentType(file.getContentType()) .build()); return String.join(\u0026#34;/\u0026#34;,minioProperties.getEndpoint(),minioProperties.getBucketName(),objectName); } 知识点九：mybatis-plus分页插件\r1 2 3 4 5 6 @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return mybatisPlusInterceptor; } 知识点十：controller中方法的参数有多个（Integer current，Integer size，QueryVO queryVO），有实体类，knife4j解析参数时，会误解析成json，这时候要在application.yml里面添加配置：springdoc.default-flat-param-object: true\r知识点十一：异常处理流派\r抛异常：1.快速终止调用 2.快速的捕捉结果，避免多层返回 核心： 1.springmvc全局异常处理 2.自定义异常 知识点十二：mybatis-plus字段更新策略\rMybatis-Plus update strategy 使用Mybatis-Plus提供的更新方法时，若实体中的字段为null，默认情况下，最终生成的update语句中，不会包含该字段。若想改变默认行为，可做以下配置。\n全局配置 在application.yml中配置如下参数 mybatis-plus:\nglobal-config:\ndb-config:\nupdate-strategy: \u0026lt;\\strategy\u0026gt;\n注：上述\u0026lt;strategy\u0026gt;可选值有：ignore、not_null、not_empty、never，默认值为not_null\nignore：忽略空值判断，不管字段是否为空，都会进行更新 not_null：进行非空判断，字段非空才会进行判断 not_empty：进行非空判断，并进行非空串（\u0026quot;\u0026quot;）判断，主要针对字符串类型 never：从不进行更新，不管该字段为何值，都不更新 局部配置 在实体类中的具体字段通过@TableField注解进行配置，如下：\n1 2 3 @Schema(description = \u0026#34;密码\u0026#34;) @TableField(value = \u0026#34;password\u0026#34;, updateStrategy = FieldStrategy.NOT_EMPTY) private String password; 知识点十三：mybatis-plus映射\rfull auto-mapping-behavior: full\n列名不能重复 设置嵌套模式为full，不用全部编写result标签 自定义查询语句都需要思考逻辑删除问题 知识点十四：表查询的on和where\ron是在两张表left join之前过滤一遍子表 where是在两张表left join 之后对整张表进行过滤\n知识点十五：定时任务\r周期性的工作和安排。\nspringboot自带定时任务。\n步骤一：开启定时任务\u0026ndash;@Scheduling【启动类】 步骤二：定义一个方法，编写定时任务逻辑 步骤三：设置方法的执行周期（cron表达式） @Scheduled（crons = “* * * * * *”）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Component public class MyTask { @Autowired private LeaseAgreementService leaseAgreementService; //定期检查租约状态 @Scheduled(cron = \u0026#34;0 0 1 * * *\u0026#34;) public void leaseAgreementCheckStatus() { LambdaUpdateWrapper\u0026lt;LeaseAgreement\u0026gt; updateWrapper = new LambdaUpdateWrapper\u0026lt;\u0026gt;(); updateWrapper.lt(LeaseAgreement::getLeaseEndDate,new Date()); updateWrapper.in(LeaseAgreement::getStatus, LeaseStatus.SIGNED,LeaseStatus.WITHDRAWING,LeaseStatus.RENEWING); updateWrapper.set(LeaseAgreement::getStatus,LeaseStatus.EXPIRED); leaseAgreementService.update(updateWrapper); } } 知识点十六：jackson注解\r@JsonIgnore\u0026ndash;\u0026gt;某个属性要忽略不生成json。 @JsonFormat\u0026ndash;\u0026gt;时间格式和时区设置。【也可以在yml文件全局配置：spring,jackson.date-format】 @JsonProperty\u0026ndash;\u0026gt;后台实体类的名称和接口文档不一致时候。 修改属性生成json的key： User id name name\u0026mdash;\u0026gt;@JsonProperty(\u0026ldquo;username\u0026rdquo;) {id:1,username:\u0026lsquo;xxx\u0026rsquo;} 知识点十七：base64\rbase64是一种转码和解码的工具，可以将任何内容转成字符串。 如：\u0026lt;\\img src=\u0026ldquo;base64字符串\u0026rdquo;\u0026gt; 前端自动解码\n知识点十八：登录流程\r1.获取验证码 \u0026mdash;-\u0026gt; 后台请求\n1、生成验证码图片和正确的验证码 2、生成uuid 3、uuid + 验证码 + 有效时间 \u0026ndash;\u0026gt; 存储到redis 4、将图片和key（uuid）返回给前端 2.登录实现 前端\u0026ndash;\u0026gt;账号 密码 输入的验证码 uuid\n后台\u0026ndash;\u0026gt; 1.校验验证码 2.校验账号 3.校验密码（加密） 4.校验用户是否可用 5.生成token 6.返回token 3.获取用户信息 前端 -\u0026gt; token -\u0026gt;后台 -\u0026gt; 解析token -\u0026gt; 用户 -\u0026gt;查询用户数据 -\u0026gt; 返回\n知识点十九：拦截器\r1.定义拦截器 \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;实现HandlerInterceptor接口，重写方法 2.编写拦截逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component public class LoginInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1.获取request中请求头的token [access_token] String accessToken = request.getHeader(\u0026#34;access_token\u0026#34;); //2.检查token是否为null if (ObjectUtils.isEmpty(accessToken)){ //没有token 没有登录 throw new LeaseException(ResultCodeEnum.ADMIN_LOGIN_AUTH); } //3.检查token是否过期和有效 //内部自动抛异常 JwtUtil.parseToken(accessToken); //true放行 | false拦截 [if(! preHandler()) return ;] return true; } } 3.注册拦截器 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;配置类 实现WebMvcConfigure，addInterceptor 4.设置拦截器,以及指定拦截和放行地址(mvc)\n1 2 3 4 5 6 @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginInterceptor) //匿名资源: 登录 获取验证码 .addPathPatterns(\u0026#34;/admin/**\u0026#34;).excludePathPatterns(\u0026#34;/admin/login/**\u0026#34;); } 知识点二十：application.yml配置文件可以提取\r配置文件，提取出来到其他模块\n知识点二十一：排除\r自动化加载排除： @SpringbootApplication(exclude={MinioConfiguration.class}) componentScan扫描排除： @ComponentScan(excludeFilters = @ComponentScan.Filter(\u0026hellip;\u0026hellip;.))\n知识点二十二：项目部署-虚拟机\r","date":"2025-01-06T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/xm-%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"xm-知识点"},{"content":"Java并发编程（多线程）\r创建多线程的四种方式\rJava中使用Thread类代表线程，所以不管使用什么方式创建多线程本质上都是创建新的Thread对象，然后再调用start()方法启动线程\n所不同的是：打算放在新线程中要执行的任务如何封装\n继承Thread类\r定义一个类继承自 Thread 类，并重写 run() 方法。 创建该类的对象，并调用其 start() 方法启动新线程。 实现Runnable接口\r定义一个类并实现 Runnable 接口的 run() 方法。 创建该类的对象，并将其作为目标传递给一个 Thread 类的实例。 调用 Thread 实例的 start() 方法启动新线程。 实现Callable接口（需借助FutureTask）\r定义一个类并实现 Callable 接口的 call() 方法。 创建一个 FutureTask 对象，将 Callable 实例作为参数传入。 将 FutureTask 对象作为目标传递给一个 Thread 类的实例，并启动线程。 通过 FutureTask 对象的 get() 方法获取异步计算的结果。 使用线程池\r创建一个执行器服务，例如 Executors.newFixedThreadPool(int nThreads) 。 提交实现了 Runnable 或 Callable 接口的任务到执行器服务。 执行器服务会自动分配线程来执行这些任务。 多线程生命周期\r背记\r新建（New）：线程被创建后，尚未启动（未调用start()方法）的状态。 就绪（Runnable）：当线程对象的start()方法被调用后，线程进入就绪状态，此时线程已经准备好执行，等待CPU调度。 运行（Running）：当CPU开始调度处于就绪状态的线程时，线程进入运行状态，开始执行其任务。 阻塞（Blocked）：线程在运行过程中遇到同步锁但申请锁失败，会进入阻塞状态，此时需要获取到锁之后才会继续执行。 等待（Waiting）：线程在执行过程中可能会进入等待状态，例如调用了wait()方法，等待其他线程的通知、唤醒，才能继续执行。 计时等待（Timed Waiting）：与等待状态类似，但在此状态下的线程有一个预定的等待时间，超时后自动返回到就绪状态。 终止（Terminated）：线程完成任务或者因为异常而结束执行，进入终止状态。 线程状态的管理通常是由操作系统和编程语言的运行时环境共同完成的。\n在Java中，可以通过Thread类提供的方法来控制和管理线程的状态，例如使用interrupt()方法来中断线程的阻塞状态，或者使用join()方法等待线程终止等\n理解\r源码中定义的线程状态\rState\n新建（NEW ）\r线程对象刚刚创建，但未启动（start）\n1 2 Thread thread = new Thread();// 只要线程new出来 System.out.println(\u0026#34;线程的名字\u0026#34;+thread.getName()+\u0026#34;线程的状态:\u0026#34;+thread.getState()); 可运行（RUNNABLE ）\r线程已被启动，可以被调度或正在被调度；也可以说此时线程在等待CPU时间片\n1 2 3 4 5 6 Thread thread = new Thread(()-\u0026gt;{ System.out.println(\u0026#34;1111\u0026#34;); System.out.println(\u0026#34;线程的状态\u0026#34;+Thread.currentThread().getState()); }); thread.start(); System.out.println(\u0026#34;线程的状态\u0026#34;+thread.getState()); 锁阻塞（BLOCKED ）\r当前线程要获取的锁对象正在被其他线程占用，此时该线程处于Blocked状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Object o = new Object(); Thread threadA = new Thread(() -\u0026gt; { synchronized (o) { System.out.println(\u0026#34;11111\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } }, \u0026#34;A\u0026#34;); threadA.start(); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } Thread threadB = new Thread(() -\u0026gt; { synchronized (o) { } }, \u0026#34;B\u0026#34;); threadB.start(); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;线程\u0026#34; + threadB.getName() + \u0026#34;状态\u0026#34; + threadB.getState()); 等待阻塞（WAITING ）\r当前线程遇到了wait()，join()等方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Object o = new Object(); Thread thread = new Thread(() -\u0026gt; { synchronized (o) { try { for (int i = 1; i \u0026lt; 10; i++) { System.out.println(\u0026#34;i---\u0026#34; + i); if (i == 5) { o.wait(); // 使用对象的wait方法时 必要要有一个对象和synchronized // 如若不结合synchronized 那么就会出现一个监视器对象状态异常 IllegalMonitorStateException。 // 任何一个对象中都有一个ObjectMonitor对象。监视器锁。管程技术。 } } } catch (InterruptedException e) { e.printStackTrace(); } } }); thread.start(); Thread.sleep(2000); System.out.println(thread.getState()); Thread thread1 = new Thread(() -\u0026gt; { // o.notify();//使用notify或者notifyAll()都要结合synchronized使用，不然就会出现监视器异常IllegalMonitorStateException synchronized (o) { System.out.println(\u0026#34;do some thing\u0026#34;); o.notify(); } }); thread1.start(); System.out.println(\u0026#34;end\u0026#34;); 限时等待（TIMED_WAITING ）\r当前线程调用了sleep(时间)，wait(时间)，join(时间)等方法.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Object o = new Object(); Thread thread = new Thread(() -\u0026gt; { synchronized (o) { try { // 线程调用wait(5000)方法 o.wait(5000); } catch (InterruptedException e) { e.printStackTrace(); } } }); thread.start(); // 线程调用sleep(5000)方法 Thread.sleep(5000); // 线程调用join(5000)方法 thread.join(5000); System.out.println(thread.getState()); 终止（TERMINATED ）\r线程正常结束或异常提前退出.\n什么是线程池，线程池有哪些？\r线程池就是事先将多个线程对象放到一个容器中，当使用的时候就不用 new 线程而是直接去池中拿线程即可，节省了开辟子线程的时间、实现了线程对象的复用，提高的代码执行效率\n在 JDK 的 java.util.concurrent.Executors 中提供了多种生成线程池的静态方法。\nExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(4); ScheduledExecutorService newScheduledThreadPool = Executors.newScheduledThreadPool(4); ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor(); 需要由线程对象执行特定任务时，调用他们的 execute 方法即可。\n注意：实际开发时严格禁止使用上述方法创建线程池！！！因为它们内部设置的各项参数非常不合理，存在OOM等重大风险\nThreadPoolExecutor对象有哪些参数？都有什么作用？怎么设定核心线程数和最大线程数？拒绝策略有哪些？ [重点]\r7个参数的作用\rcorePoolSize\r核心线程数，在ThreadPoolExecutor中有一个与它相关的配置：allowCoreThreadTimeOut（默认为false）\nallowCoreThreadTimeOut为false：核心线程会一直存活，哪怕是一直空闲着 allowCoreThreadTimeOut为true：核心线程空闲时间超过keepAliveTime时会被回收 maximumPoolSize\r最大线程数，线程池能容纳的最大线程数，当线程池中的线程达到最大且等待队列已满时，添加新任务将会触发拒绝策略\nkeepAliveTime\r线程的最大空闲时间\n非核心空闲超过这个时间将被回收 核心线程超过这个时间是否回收受allowCoreThreadTimeOut影响 unit\rkeepAliveTime的时间单位\nworkQueue\r任务队列，常用有三种队列，即SynchronousQueue、LinkedBlockingDeque（无界队列）,ArrayBlockingQueue（有界队列）。\nthreadFactory\r线程工厂，ThreadFactory是一个接口，用来创建worker。通过线程工厂可以对线程的一些属性进行定制，默认直接新建线程。\nRejectedExecutionHandler\r也是一个接口，只有一个方法，当线程池中的资源已经全部使用，添加新线程被拒绝时，会调用RejectedExecutionHandler的rejectedExecution法。默认是抛出一个运行时异常。\n线程池大小设置\r最佳实践\r把corePoolSize和maximumPoolSize设置成相同的数值，避免非核心线程创建又销毁，销毁又创建\n具体数值设置\r首先需要分析项目中线程池负责的任务是哪种类型\nCPU密集型\r主要执行计算任务，响应时间很快，CPU一直在运行。这种任务的CPU利用率很高，那么线程数的配置应该根据CPU核心数来决定。\nCPU核心数等于最大同时执行线程数\n假如CPU核心数为4，那么服务器最多能同时执行4个线程，过多的线程会导致上下文切换反而使得效率降低\n此时线程池的最大线程数可以配置为CPU核心数+1\nI/O密集型\r主要进行I/O操作，执行I/O操作时间长，在I/O过程中CPU处于空闲状态导致CPU利用率不高\n这种情况可以增加线程池中线程数量的大小，具体增加多少可以结合线程的等待时长来判断，等待时间越长，线程数可以相对越多\n一般可以配置CPU核心数的两倍\n补充：其实我们平时写的常规业务都是I/O密集型。前端发送过来一个请求，Java代码需要计算的不多，大部分时间是在等待Redis、MySQL、ElasticSearch通过网络传输返回结果\n常见线程安全的并发容器有哪些？\rSet集合：CopyOnWriteArraySet（写时复制技术） List集合：CopyOnWriteArraySet（写时复制技术） Map集合：ConcurrentHashMap JDK1.7：采用了锁分段（Segment）技术来提高并发性能，每个段（Segment）相当于一个独立的哈希表，并且每个段都有自己的锁，这样可以减少锁的竞争 JDK1.8：设计进行了优化，不再使用分段锁（Segment），而是采用了CAS（Compare and Swap）操作和synchronized关键字相结合的方式来实现线程安全，它使用了更细粒度的锁机制，即在链表或红黑树的节点上使用synchronized锁，同时对于一些非竞争性的操作则采用CAS来保证原子性，从而进一步提高了并发性能 Atomic原子类了解多少？原理是什么？\r概述\rJava中的java.util.concurrent.atomic包提供了一组原子类，用于在多线程环境中执行原子操作，而无需使用显式的锁。\n分别说明\rAtomicInteger、AtomicLong、AtomicReference\r这些类使用compareAndSet（CAS）操作实现原子性。\nCAS是一种乐观锁定机制，它尝试原子地将一个值更新为新值，但只有在当前值等于预期值时才成功；否则，它会重新尝试。\nCAS操作是由处理器提供的原子性操作指令支持的。\nAtomicBoolean\rAtomicBoolean类使用compareAndSet实现。\ncompareAndSet的实现通常依赖于底层处理器的CAS指令。\nAtomicIntegerArray、AtomicLongArray、AtomicReferenceArray\r这些类提供了对数组元素的原子性访问。\n它们也使用CAS操作，但应用于数组的特定位置。\nAtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater\r这些类提供了对对象字段的原子性更新。\n它们使用了反射和CAS操作来实现。\nsynchronized底层实现是什么？Lock底层是什么？有什么区别？\r7.1 synchronized原理\r同步方法\r方法级的同步是隐式的，即无需通过字节码指令来控制，它实现在方法调用和返回操作之中。\nJVM可以从方法常量池中的方法表结构（method_info Structure）中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。\n当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成（无论是正常完成还是非正常完成）时释放monitor。\n同步代码块\r代码块的同步是利用monitorenter和monitorexit这两个字节码指令。它们分别位于同步代码块的开始和结束位置。\n当JVM执行到monitorenter指令时，当前线程试图获取monitor对象的所有权，如果未加锁或者已经被当前线程所持有，就把锁的计数器+1；\n当执行monitorexit指令时，锁计数器-1；\n当锁计数器为0时，该锁就被释放了。\n如果获取monitor对象失败，该线程则会进入阻塞状态，直到其他线程释放锁。\nLock原理\rLock的存储结构：一个int类型状态值（用于锁的状态变更），一个双向链表（用于存储等待中的线程）\nLock获取锁的过程\r本质上是通过CAS来获取状态值修改，如果当场没获取到，会将该线程放在线程等待链表中。\nLock释放锁的过程\r修改状态值，调整等待链表。Lock大量使用CAS+自旋。因此根据CAS特性，Lock建议使用在低锁冲突的情况下。\nLock与synchronized的区别\rLock的加锁和解锁都是由Java代码配合native方法（调用操作系统的相关方法）实现的，而synchronized的加锁和解锁的过程是由JVM管理的。\n阻塞机制\r当一个线程使用synchronized获取锁时，若锁被其他线程占用着，那么当前只能被阻塞，直到成功获取锁。 Lock则提供超时锁和可中断等更加灵活的方式，在未能获取锁的条件下提供一种退出的机制。 锁占有模式\rsynchronized对线程的同步仅提供独占模式， Lock既可以提供独占模式，也可以提供共享模式 条件队列\r一个锁内部可以有多个Condition实例，即有多路条件队列，而synchronized只有一路条件队列\n同样Condition也提供灵活的阻塞方式，在未获得通知之前可以通过中断线程以及设置等待时限等方式退出条件队列。\n总结\rsynchronized Lock 关键字 接口/类 自动加锁和释放锁 需要手动调用unlock()方法释放锁 JVM层面的锁 API层面的锁 非公平锁 可以选择公平或者非公平锁 锁是一个对象，并且锁的信息保存在了对象中 代码中通过int类型的state标识 有一个锁升级的过程 无 ","date":"2025-01-04T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","title":"线程池"},{"content":"什么是Nginx？\rNginx是一款高性能的HTTP服务器和反向代理服务器，具有轻量级、高并发处理能力的特点。以下是对Nginx的具体介绍：\n基本概念\r定义：Nginx是一款由俄罗斯程序员Igor Sysoev开发的开源软件。它主要被用作HTTP服务器和反向代理服务器，同时也支持电子邮件（IMAP/POP3）代理服务。Nginx以其高并发连接处理能力和低资源消耗而闻名，能够在Linux系统上高效运行，并且也有Windows系统的移植版。\n特点：Nginx采用C语言编写，具备高性能和高稳定性。其源代码以类BSD许可证的形式发布，允许广泛的使用和修改。同时，Nginx还拥有丰富的模块库，能够提供包括HTTP负载均衡、缓存、访问控制等多种功能。\n工作原理\r反向代理机制：Nginx作为反向代理服务器，可以接收客户端请求并将其转发给后端服务器，再将从后端服务器获取的响应返回给客户端。这一机制使得Nginx能够隐藏后端服务器的存在，对外表现为一个单一的访问点。\n负载均衡策略：Nginx支持多种负载均衡算法，如轮询和权重分配等，可以根据实际需求将客户端请求分发到不同的后端服务器上，从而提高系统的整体性能和可用性。\n应用场景\r静态内容托管：Nginx在处理静态文件方面表现出色，能够快速响应并返回文件内容。因此，它常被用于托管静态网站或作为动态网站的静态资源服务器。\n反向代理与负载均衡：Nginx可以作为反向代理服务器，将客户端请求分发到多个后端服务器上，实现负载均衡。这有助于提高系统的可扩展性和可靠性。\nAPI网关：Nginx还可以作为API网关，统一管理和调度后端微服务接口，提供认证、限流、监控等功能。\n配置与管理\r配置文件：Nginx的配置文件通常位于安装目录下的conf文件夹中，主配置文件名为nginx.conf。通过修改该文件，可以自定义Nginx的行为和功能。\n命令行工具：Nginx提供了丰富的命令行工具，用于启动、停止、重启Nginx服务以及重新加载配置文件等操作。\n总的来说，Nginx是一个功能强大且灵活的Web服务器和反向代理服务器。无论是在处理静态内容、实现反向代理和负载均衡还是作为API网关等方面，Nginx都展现出了卓越的性能和稳定性。对于需要构建高效、可靠和可扩展的Web应用和服务的组织来说，Nginx是一个值得考虑的选择。\nIT界的AK47：\nNginx的主要功能有哪些？\rNginx的主要功能包括负载均衡、反向代理、动静分离以及配置HTTPS等。以下是对其主要功能的详细阐述：\n负载均衡\r概念和重要性：负载均衡是一种计算机网络基础技术，主要用于优化资源使用，最大化吞吐率，最小化响应时间，同时避免过载。通过引入一个负载均衡器和至少一个额外的web服务器，可以显著提高网站的稳定性和可用性。\n实现方式：Nginx支持多种负载均衡算法，如轮询、IP哈希、最少连接数等，可以根据实际需求将客户端请求分发到不同的后端服务器上，以达到优化资源利用和提高系统性能的目的。\n反向代理\r定义和作用：反向代理是指以代理服务器来接受互联网上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给互联网上请求连接的客户端。这种方式使得真实服务器不能直接被外部网络访问，从而增加了安全性。\n应用场景：反向代理广泛应用于解决浏览器跨域访问问题。当协议、域名、端口号有一项或多项不同时，便违反了同源策略，需要跨域。前端跨域常用的方法之一就是使用Nginx作为反向代理服务器。\n动静分离\r概念：动静分离是指将静态资源（如图片、视频、CSS、JavaScript等）与动态内容（如PHP、Java、Python等生成的内容）分开存储和传输，以提高网站的加载速度和用户体验。\n实现方式：Nginx可以通过配置静态文件路径和缓存策略来实现动静分离。例如，可以将静态文件缓存到内存中，从而减轻后端服务器的负载。\n配置HTTPS\r安全性提升：HTTPS是HTTP的安全版本，通过SSL/TLS协议为数据通信提供加密保护，确保数据传输的安全性。Nginx可以作为SSL/TLS终端代理，对外提供HTTPS服务，负责SSL/TLS握手、证书验证等操作，并将加密的请求转发到后端服务器。\n配置步骤：配置HTTPS通常需要在Nginx的配置文件中指定SSL证书和私钥的路径，并启用SSL模块。具体配置方法可以参考Nginx官方文档或相关教程。\n综上所述，Nginx是一个功能强大且灵活的Web服务器和反向代理服务器，具有负载均衡、反向代理、动静分离以及配置HTTPS等多种主要功能。这些功能使得Nginx在构建高性能、可靠和可扩展的Web应用和服务方面具有显著优势。\nNginx与Apache相比有哪些优势？\rNginx与Apache相比，在性能、资源占用以及配置管理等方面存在区别。以下是具体分析：\n性能\rNginx：Nginx在处理高并发请求时表现出色，能够支持高达50,000个并发连接数。它采用异步非阻塞的事件驱动架构，可以高效地处理大量并发连接，特别适合高流量的网站和应用程序。\nApache：Apache使用多线程模型，每个连接通常使用一个线程。在高并发环境下，Apache可能会出现性能瓶颈，因为每个进程或线程都会消耗较多的系统资。\n资源占用\rNginx：Nginx通常比Apache占用更少的内存和CPU资源，这意味着在相同硬件条件下，Nginx可以支持更多的同时连接。其轻量级特性使得它在资源有限的环境中（如虚拟私有服务器或容器化部署）表现更佳。\nApache：Apache在处理相同数量的并发请求时，会消耗更多的资源，特别是在内存使用方面。\n配置管理\rNginx：Nginx的配置相对简单和直观，配置文件使用一个语法简洁的配置语言，许多高级功能，如负载均衡，可以通过简单的配置实现。它还支持热部署，可以在不间断服务的情况下进行软件版本的升级与回退。\nApache：Apache的配置文件较为复杂，需要较长的学习曲线。修改配置后，只能手工重启服务或者使用第三方插件实现热部署，期间服务会出现短暂的不可用。\n适用场景\rNginx：Nginx适合处理静态内容、反向代理和负载均衡等任务。它的异步事件处理机制使其在高并发场景下表现更为出色。\nApache：Apache更适合处理动态内容和复杂的URL重写等任务。由于其模块化设计，用户可以轻松地通过配置文件启用或关闭各种模块，提供极高的灵活性。\n总的来说，Nginx在处理高并发请求和静态内容方面具有显著优势，而Apache则在处理动态内容和复杂URL重写方面表现更好。选择哪个Web服务器应根据具体的项目需求和技术团队的经验来做出决策。\n如何在Nginx中配置一个虚拟主机？\r在Nginx中配置虚拟主机，可以通过创建配置文件、设置基本信息以及文档根目录等步骤实现。以下是关于如何在Nginx中配置一个虚拟主机的具体分析：\n1\n创建配置文件：在nginx/conf.d目录下（默认路径，可以根据实际情况调整），新建一个.conf文件，例如example.com.conf。\n2\n设置基本信息：在配置文件中，添加以下基础信息，定义监听的端口和虚拟主机的名称：\n1 2 3 4 5 6 nginx server { listen 80; # 或者443（如果启用HTTPS） server_name example.com; } 3\n文档根目录：指定站点的主目录，例如：\nnginx\nroot /var/www/example.com; # 这里替换为你实际的网站文件夹路径\n4\n访问控制和SSL配置（如有必要）：如果需要HTTPS，可以加入SSL证书和密钥：\nnginx\nssl_certificate /path/to/your.crt; ssl_certificate_key /path/to/your.key;\n5\n错误页面和日志设置：设置错误页面和访问日志的位置：\nnginx\nerror_page 404 /404.html; access_log /var/log/nginx/example.access.log main;\n6\n启用虚拟主机：最后，在nginx.conf的http块中包含你新创建的虚拟主机配置，如未包含则添加：\nnginx\ninclude /etc/nginx/conf.d/*.conf\n总的来说，通过上述步骤，可以在Nginx中成功配置一个虚拟主机。配置完成后，不要忘记重启Nginx服务以使更改生效。根据具体需求，还可以进一步优化配置，如设置负载均衡、反向代理等高级功能。\n5\n解释Nginx中的upstream模块及其用途。\nNginx中的upstream模块用于定义后端服务器组，并管理与这些服务器的通信方式。以下是关于upstream模块的具体介绍：\n1\n基本概念\n定义：upstream模块允许用户在Nginx配置文件中定义一组或多组后端服务器。这些服务器可以是不同的物理服务器或同一台服务器的不同应用端口。\n用途：通过upstream模块，可以将客户端请求分发到不同的后端服务器上，从而实现负载均衡和高可用性。\n2\n配置方法\n语法结构：在nginx.conf的http块内定义upstream块，使用server关键字指定后端服务器的IP地址、端口号以及相关参数。例如：\nnginx\nupstream backend { server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; }\n参数说明：常用的参数包括weight（权重）、max_fails（最大失败次数）、fail_timeout（失败超时时间）等。这些参数帮助Nginx更智能地分配请求，提高系统的稳定性和效率。\n3\n调度算法\n静态调度算法：如轮询（rr）、加权轮询（wrr）、ip哈希（ip_hash）等。这些算法根据预定义的规则分配请求，不考虑后端服务器的实时状态。\n动态调度算法：如least_conn（最少连接数）和fair（响应时间）等。这些算法会根据后端服务器的当前负载情况动态调整请求分配，更加智能和高效。\n总的来说，upstream模块是Nginx实现高性能、高可用性和可扩展性的关键组件之一。通过合理配置upstream模块，可以显著提升Web应用的性能和稳定性。\n6\n如何在Nginx中实现负载均衡？\n在Nginx中实现负载均衡，可以通过配置upstream模块和代理设置来实现。以下是具体步骤：\n1\n定义后端服务器组：在Nginx配置文件中（通常是nginx.conf），使用upstream指令定义一个后端服务器组。例如，创建一个名为backend的服务器组，并添加多个后端服务器：\nnginx\nupstream backend { server 192.168.1.101; server 192.168.1.102; server 192.168.1.103; }\n2\n配置负载均衡算法：在upstream块中，可以指定不同的负载均衡算法，如轮询（默认）、加权轮询、最少连接数等。例如，使用加权轮询算法：\nnginx\nupstream backend { server 192.168.1.101 weight=3; server 192.168.1.102 weight=1; server 192.168.1.103 weight=2; }\n3\n设置代理转发：在server块中，使用proxy_pass指令将请求转发到定义的后端服务器组。例如：\nnginx\nserver { listen 80; server_name example.com; location / { proxy_pass http://backend; } }\n4\n高级配置：根据需要，可以进一步优化负载均衡的配置，如设置健康检查、调整超时时间、启用缓存等。例如，启用健康检查：\nnginx\nupstream backend { server 192.168.1.101 max_fails=3 fail_timeout=30s; server 192.168.1.102 max_fails=3 fail_timeout=30s; server 192.168.1.103 max_fails=3 fail_timeout=30s; }\n5\n重启Nginx服务：完成配置后，保存文件并重启Nginx服务以使更改生效：\nBash\nsudo systemctl restart nginx\n总的来说，通过上述步骤，可以在Nginx中实现高效的负载均衡，从而提高Web应用的性能和可靠性。\n7\n在Nginx中如何配置SSL/TLS？\n在Nginx中配置SSL/TLS，可以通过获取SSL证书、修改Nginx配置文件以及重启服务来实现。以下是具体步骤：\n1\n获取SSL证书：首先，需要从可信的证书颁发机构（CA）获取SSL证书。这通常包括一个证书文件（.crt或.pem格式）和一个私钥文件（.key格式）。如果使用的是Let\u0026rsquo;s Encrypt等免费证书，可以使用Certbot等工具自动获取和续订证书。\n2\n修改Nginx配置文件：在Nginx的配置文件中（通常是nginx.conf或位于/etc/nginx/sites-available/目录下的某个文件），为需要启用HTTPS的服务器块添加SSL配置。例如：\nnginx\nserver { listen 443 ssl; server_name example.com; ssl_certificate /path/to/your_domain_name.crt; ssl_certificate_key /path/to/your_private.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root /var/www/html; index index.html index.htm; } }\n3\n配置HTTP到HTTPS的重定向：为了确保所有HTTP请求都被重定向到HTTPS，可以在Nginx配置文件中添加一个新的服务器块来处理HTTP请求：\nnginx\nserver { listen 80; server_name example.com; return 301 https://$host$request_uri; }\n4\n测试配置并重启Nginx：在应用更改之前，使用以下命令测试Nginx配置文件的语法是否正确：\nBash\nsudo nginx -t\n如果测试通过，没有错误信息，则可以安全地重启Nginx以使更改生效：\nBash\nsudo systemctl restart nginx\n5\n自动更新证书：如果使用Let\u0026rsquo;s Encrypt等服务，可以设置定时任务（cron job）来自动更新证书。Certbot提供了自动更新证书的命令，可以添加到crontab中定期执行。\n总的来说，通过上述步骤，可以在Nginx中成功配置SSL/TLS，增强网站的安全性。\n8\n什么是Nginx的反向代理？\nNginx的反向代理是指将客户端请求转发到后端服务器，并将后端服务器的响应返回给客户端的过程。以下是关于Nginx反向代理的具体介绍：\n1\n基本概念\n定义：反向代理是代理服务器的一种，它位于客户端和原始服务器之间，对客户端透明，即客户端认为它直接与原始服务器通信。\n作用：反向代理主要用于负载均衡、缓存静态内容、提高安全性等目的。它可以将请求分发到多个后端服务器上，从而提高应用的可用性和扩展性。\n2\n配置方法\n基本配置：在Nginx配置文件中（通常是nginx.conf），使用proxy_pass指令设置反向代理。例如，将所有以/app开头的请求转发到后端服务器组backend：\nnginx\nserver { listen 80; server_name example.com; location /app { proxy_pass http://backend; } }\n高级配置：可以进一步配置反向代理的行为，如设置超时时间、修改请求头、启用WebSocket支持等。例如，设置代理连接超时时间为60秒：\nnginx\nlocation /app { proxy_pass http://backend; proxy_connect_timeout 60s; proxy_read_timeout 60s; }\n3\n应用场景\n负载均衡：通过反向代理，可以将客户端请求均匀分配到多个后端服务器上，避免单点故障，提高系统的可用性和性能。\n内容缓存：反向代理可以缓存后端服务器的响应，减少对原始服务器的请求压力，加快响应速度。\n安全增强：反向代理可以隐藏后端服务器的真实IP地址，增加一层安全防护，防止直接攻击后端服务器。\n总的来说，Nginx的反向代理功能是构建高性能、可扩展和安全的Web应用的关键组件之一。通过合理配置反向代理，可以显著提升系统的整体性能和可靠性。\n9\n如何在Nginx中设置访问控制（例如：IP白名单和黑名单）？\n在Nginx中设置访问控制，可以通过配置访问规则来实现IP白名单和黑名单。以下是具体步骤：\n1\nIP白名单：允许特定IP地址或IP段访问服务器。\n在Nginx配置文件中（通常是nginx.conf），使用allow指令指定允许的IP地址。例如，只允许IP地址192.168.1.100和192.168.1.101访问：\nnginx\nserver { listen 80; server_name example.com; location / { allow 192.168.1.100; allow 192.168.1.101; deny all; } }\n如果需要允许一个IP段，可以使用CIDR表示法。例如，允许整个192.168.1.0/24网段访问：\nnginx\nlocation / { allow 192.168.1.0/24; deny all; }\n2\nIP黑名单：拒绝特定IP地址或IP段访问服务器。\n在Nginx配置文件中，使用deny指令指定拒绝的IP地址。例如，拒绝IP地址192.168.1.200和192.168.1.201访问：\nnginx\nserver { listen 80; server_name example.com; location / { deny 192.168.1.200; deny 192.168.1.201; allow all; } }\n同样地，可以使用CIDR表示法来拒绝一个IP段。例如，拒绝整个192.168.2.0/24网段访问：\nnginx\nlocation / { deny 192.168.2.0/24; allow all; }\n3\n组合使用白名单和黑名单：可以同时使用allow和deny指令来创建更复杂的访问控制规则。例如，允许特定IP段访问，但拒绝其中的某些IP：\nnginx\nlocation / { allow 192.168.1.0/24; deny 192.168.1.102; deny 192.168.1.103; }\n4\n测试配置并重启Nginx：在应用更改之前，使用以下命令测试Nginx配置文件的语法是否正确：\nBash\nsudo nginx -t\n如果测试通过，没有错误信息，则可以安全地重启Nginx以使更改生效：\nBash\nsudo systemctl restart nginx\n总的来说，通过上述步骤，可以在Nginx中灵活地设置访问控制，包括IP白名单和黑名单，从而增强服务器的安全性。\n10\n如何在Nginx中进行静态资源压缩和缓存？\n在Nginx中进行静态资源压缩和缓存，可以通过配置gzip模块和设置缓存头来实现。以下是具体步骤：\n1\n启用gzip压缩：\n在Nginx配置文件中（通常是nginx.conf），使用gzip指令来启用gzip压缩。可以在http块或server块中进行配置。例如，启用gzip压缩并设置压缩级别为5：\nnginx\nhttp { gzip on; gzip_types text/plain application/xml text/css application/javascript; gzip_vary on; gzip_min_length 256; gzip_comp_level 5; gzip_proxied any; gzip_buffers 16 8k; }\ngzip_types指令指定要压缩的MIME类型。可以根据需要添加或删除类型。\ngzip_vary on指令会在响应头中添加Vary: Accept-Encoding，以便代理服务器正确处理压缩内容。\ngzip_min_length指令设置触发压缩的最小响应体长度。\ngzip_comp_level指令设置压缩级别，范围是1到9，数字越大压缩率越高，但CPU占用也更高。\ngzip_proxied指令指定哪些请求应该被压缩，any表示所有请求都压缩。\ngzip_buffers指令设置用于存储压缩数据的缓冲区数量和大小。\n2\n设置缓存头：\n在Nginx配置文件中，使用expires指令设置静态资源的缓存时间。例如，设置图片、CSS和JavaScript文件的缓存时间为30天：\nnginx\nserver { listen 80; server_name example.com; location ~* .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; } location / { root /var/www/html; index index.html index.htm; } }\nexpires指令设置资源的过期时间，可以使用不同的时间单位，如秒（s）、分钟（m）、小时（h）、天（d）。\nadd_header指令添加HTTP头信息，Cache-Control头可以控制缓存行为，如public表示响应可以被任何缓存存储，no-transform表示中间代理不能改变媒体类型的编码。\n3\n测试配置并重启Nginx：\n在应用更改之前，使用以下命令测试Nginx配置文件的语法是否正确：\nBash\nsudo nginx -t\n如果测试通过，没有错误信息，则可以安全地重启Nginx以使更改生效：\nBash\nsudo systemctl restart nginx\n总的来说，通过上述步骤，可以在Nginx中有效地进行静态资源压缩和缓存，从而提高网站的性能和用户体验。\n11\n解释Nginx中的事件驱动模型。\nNginx中的事件驱动模型是一种高效的网络处理机制，它通过异步非阻塞的方式来处理大量并发连接。以下是对Nginx事件驱动模型的详细解释：\n1\n基本概念\n事件驱动：事件驱动模型的核心思想是程序在等待事件发生时不会阻塞，而是继续执行其他任务。当某个事件发生时，系统会通知应用程序进行处理。这种机制使得程序能够高效地处理大量并发连接。\n异步非阻塞：在事件驱动模型中，I/O操作（如读写数据）通常是异步和非阻塞的。这意味着应用程序可以在等待I/O操作完成的同时继续执行其他任务，而不会被阻塞住。\n2\nNginx的事件驱动架构\n事件循环：Nginx使用一个主事件循环来监听和分发事件。事件循环不断地检查各种事件（如连接、读取、写入等），并根据事件的类型调用相应的回调函数进行处理。\n多路复用：Nginx采用多路复用技术（如epoll、kqueue、select等）来同时监控多个文件描述符。这些技术允许Nginx在一个线程内高效地管理大量的并发连接。\n工作进程：Nginx可以配置多个工作进程，每个工作进程都包含一个独立的事件循环。这种设计使得Nginx能够充分利用多核CPU的优势，提高并发处理能力。\n3\n工作流程\n初始化：Nginx启动时，会初始化事件模块，并创建多个工作进程。每个工作进程都会创建一个事件循环，并开始监听配置文件中定义的端口和地址。\n事件注册：当有新的连接请求到达时，操作系统会将该事件通知给Nginx的事件循环。Nginx会根据事件类型（如新连接、数据可读、数据可写等）将事件添加到事件队列中。\n事件处理：事件循环不断从事件队列中取出事件，并调用相应的回调函数进行处理。例如，当有新的连接请求时，会调用接受连接的回调函数；当有数据可读时，会调用读取数据的回调函数。\n任务调度：Nginx的事件驱动模型还支持任务调度功能，可以将一些耗时的任务（如磁盘I/O操作）交给专门的线程池处理，以避免阻塞事件循环。\n4\n优势\n高并发处理能力：由于采用了异步非阻塞的I/O操作和多路复用技术，Nginx能够高效地处理大量并发连接，适用于高并发场景。\n资源利用率高：通过事件驱动模型，Nginx能够在单线程内处理多个连接，避免了传统多线程模型中的线程切换开销，提高了资源利用率。\n扩展性好：Nginx的事件驱动架构使其具有良好的扩展性，可以通过增加工作进程数量来提升并发处理能力。\n总的来说，Nginx的事件驱动模型通过异步非阻塞的I/O操作和多路复用技术，实现了高效的并发处理能力，适用于高并发的网络应用场景。\n12\n如何在Nginx中配置Gzip压缩？\n在Nginx中配置Gzip压缩，可以通过编辑Nginx配置文件来实现。以下是详细的步骤：\n1\n打开Nginx配置文件：\nNginx的主配置文件通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。你可以使用文本编辑器（如vim、nano）打开该文件。例如：\nBash\nsudo vim /etc/nginx/nginx.conf\n2\n启用gzip模块：\n在http块中添加或修改以下指令来启用gzip压缩：\nnginx\nhttp { # 启用gzip压缩 ​ gzip on;\n# 设置要压缩的MIME类型\r​ gzip_types text/plain application/xml text/css application/javascript;\n# 设置触发压缩的最小响应体长度\r​ gzip_min_length 256;\n# 设置压缩级别，范围是1到9，数字越大压缩率越高，但CPU占用也更高\r​ gzip_comp_level 5;\n# 为所有请求启用gzip压缩\r​ gzip_proxied any;\n# 设置用于存储压缩数据的缓冲区数量和大小\r​ gzip_buffers 16 8k; }\n3\n配置具体的服务器块：\n如果你只想对特定的服务器或位置启用gzip压缩，可以在相应的server块或location块中进行配置。例如，只对静态资源启用gzip压缩：\nnginx\nserver { listen 80; server_name example.com; location ~* .(jpg|jpeg|png|gif|ico|css|js)$ { gzip on; gzip_types text/plain application/xml text/css application/javascript; gzip_min_length 256; gzip_comp_level 5; gzip_proxied any; gzip_buffers 16 8k; } location / { root /var/www/html; index index.html index.htm; } }\n4\n测试配置并重启Nginx：\n在应用更改之前，使用以下命令测试Nginx配置文件的语法是否正确：\nBash\nsudo nginx -t\n如果测试通过，没有错误信息，则可以安全地重启Nginx以使更改生效：\nBash\nsudo systemctl restart nginx\n5\n验证gzip压缩是否生效：\n你可以使用浏览器的开发者工具或命令行工具（如curl）来验证gzip压缩是否生效。例如，使用curl命令查看响应头信息：\nBash\ncurl -I -H \u0026ldquo;Accept-Encoding: gzip\u0026rdquo; http://example.com/path/to/resource\n如果gzip压缩生效，响应头中应该包含Content-Encoding: gzip。\n总的来说，通过上述步骤，你可以在Nginx中配置Gzip压缩，从而提高网站的性能和用户体验。\n13\nNginx如何处理高并发请求？\nNginx处理高并发请求的能力主要得益于其高效的事件驱动架构和多进程/多线程模型。以下是Nginx如何处理高并发请求的详细解释：\n13.1\n\\1. 事件驱动架构\n异步非阻塞I/O：Nginx采用异步非阻塞的I/O操作，这意味着它可以在等待I/O操作完成的同时继续处理其他任务。这种机制避免了传统同步阻塞I/O带来的性能瓶颈。\n事件循环：Nginx使用一个主事件循环来监听和分发事件。事件循环不断地检查各种事件（如连接、读取、写入等），并根据事件的类型调用相应的回调函数进行处理。\n多路复用：Nginx采用多路复用技术（如epoll、kqueue、select等）来同时监控多个文件描述符。这些技术允许Nginx在一个线程内高效地管理大量的并发连接。\n13.2\n\\2. 多进程/多线程模型\n工作进程：Nginx可以配置多个工作进程，每个工作进程都包含一个独立的事件循环。这种设计使得Nginx能够充分利用多核CPU的优势，提高并发处理能力。\n负载均衡：Nginx可以将请求分配到不同的工作进程中，从而实现负载均衡。这有助于避免单个进程过载，提高整体系统的吞吐量。\n13.3\n\\3. 缓存机制\n静态资源缓存：Nginx可以对静态资源进行缓存，减少对后端服务器的请求压力。通过设置适当的缓存头信息，Nginx可以在客户端缓存静态资源，从而减少重复请求。\n反向代理缓存：Nginx作为反向代理时，可以缓存后端服务器的响应数据，提高响应速度并减轻后端服务器的压力。\n13.4\n\\4. 连接池\n长连接：Nginx支持HTTP长连接（Keep-Alive），可以减少TCP连接的建立和关闭开销，提高请求处理效率。\n连接池：Nginx可以维护一个连接池，复用已有的连接，减少频繁创建和销毁连接的开销。\n13.5\n\\5. 优化配置\nworker_processes：配置Nginx的工作进程数量，通常设置为与CPU核心数相同或略高。例如：\nnginx\nworker_processes auto;\nworker_connections：配置每个工作进程的最大连接数。例如：\nnginx\nevents { worker_connections 1024; }\nworker_rlimit_nofile：增加文件描述符的限制，以支持更多的并发连接。例如：\nnginx\nworker_rlimit_nofile 65536;\n13.6\n\\6. 示例配置\n以下是一个示例Nginx配置文件，展示了如何配置Nginx以处理高并发请求：\nnginx\nuser www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/.conf; events { worker_connections 1024; multi_accept on; } http { sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Gzip压缩配置 gzip on; gzip_disable \u0026ldquo;msie6\u0026rdquo;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; server { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; } location ~ .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; } } }\n总的来说，Nginx通过事件驱动架构、多进程/多线程模型、缓存机制、连接池以及优化配置等多种手段，实现了高效的高并发请求处理能力。\n14\n解释Nginx配置文件的结构。\nNginx配置文件的结构是其强大功能和灵活性的基础。Nginx的配置文件通常位于/etc/nginx/nginx.conf，但也可以通过命令行参数指定其他位置。配置文件由多个指令组成，这些指令按照一定的层次结构组织。以下是Nginx配置文件的主要结构和常见指令的解释：\n14.1\n全局块\n全局块包含影响整个Nginx服务器的配置指令。这些指令通常在http块之外。\nnginx\nuser www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf;\n14.2\nevents块\nevents块用于配置与事件处理相关的设置，如工作进程的数量、连接数等。\nnginx\nevents { worker_connections 1024; multi_accept on; }\n14.3\nhttp块\nhttp块包含所有与HTTP协议相关的配置，包括服务器块（server）、位置块（location）等。\nnginx\nhttp { sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Gzip压缩配置 gzip on; gzip_disable \u0026ldquo;msie6\u0026rdquo;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; server { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; } location ~* .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; } } }\n14.4\nserver块\nserver块定义了一个虚拟主机，可以包含多个location块和其他相关配置。\nnginx\nserver { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; } location ~* .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; } }\n14.5\nlocation块\nlocation块用于匹配特定的URL路径，并定义该路径下的处理方式。常见的匹配方式有前缀匹配、正则表达式匹配和精确匹配。\nnginx\nlocation / { root /var/www/html; index index.html index.htm; } location ~* .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; }\n14.6\n常用指令\nuser：指定Nginx运行的用户和组。\nnginx\nuser www-data;\nworker_processes：指定工作进程的数量。通常设置为CPU核心数或auto。\nnginx\nworker_processes auto;\npid：指定存储Nginx主进程PID的文件路径。\nnginx\npid /run/nginx.pid;\ninclude：包含其他配置文件。常用于模块化配置。\nnginx\ninclude /etc/nginx/modules-enabled/*.conf;\nsendfile：启用高效的文件传输模式。\nnginx\nsendfile on;\ntcp_nopush和tcp_nodelay：优化TCP连接性能。\nnginx\ntcp_nopush on; tcp_nodelay on;\nkeepalive_timeout：设置长连接超时时间。\nnginx\nkeepalive_timeout 65;\ntypes_hash_max_size：设置MIME类型哈希表的最大大小。\nnginx\ntypes_hash_max_size 2048;\ninclude：包含其他配置文件，如MIME类型文件。\nnginx\ninclude /etc/nginx/mime.types;\ndefault_type：设置默认的MIME类型。\nnginx\ndefault_type application/octet-stream;\ngzip：启用Gzip压缩。\nnginx\ngzip on;\ngzip_disable：禁用对特定浏览器的Gzip压缩。\nnginx\ngzip_disable \u0026ldquo;msie6\u0026rdquo;;\ngzip_vary：添加Vary: Accept-Encoding头。\nnginx\ngzip_vary on;\ngzip_proxied：设置哪些请求会被代理并压缩。\nnginx\ngzip_proxied any;\ngzip_comp_level：设置Gzip压缩级别。\nnginx\ngzip_comp_level 6;\ngzip_buffers：设置Gzip压缩使用的缓冲区数量和大小。\nnginx\ngzip_buffers 16 8k;\ngzip_http_version：设置支持Gzip压缩的HTTP版本。\nnginx\ngzip_http_version 1.1;\ngzip_types：设置需要压缩的MIME类型。\nnginx\ngzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\nlisten：指定监听的端口和地址。\nnginx\nlisten 80;\nserver_name：指定虚拟主机的域名。\nnginx\nserver_name example.com;\nroot：指定根目录。\nnginx\nroot /var/www/html;\nindex：指定默认的索引文件。\nnginx\nindex index.html index.htm;\nexpires：设置静态资源的过期时间。\nnginx\nexpires 30d;\nadd_header：添加HTTP响应头。\nnginx\nadd_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;;\n14.7\n示例配置文件\n以下是一个简化的Nginx配置文件示例，展示了上述各个部分的基本用法：\nnginx\nuser www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/.conf; events { worker_connections 1024; } http { sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; gzip on; gzip_disable \u0026ldquo;msie6\u0026rdquo;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; server { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; location / { try_files $uri $uri/ =404; } location ~ .(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026ldquo;public, no-transform\u0026rdquo;; } } }\n这个配置文件定义了一个基本的Nginx服务器，能够处理静态资源请求并进行Gzip压缩。通过理解和应用这些配置指令，你可以根据实际需求灵活调整Nginx的行为。\n15\n如何在Nginx中重写URL？\n在Nginx中重写URL通常使用rewrite指令。这个指令允许你根据正则表达式匹配URL，并对其进行重写或重定向。以下是一些常见的用法和示例：\n15.1\n基本语法\nnginx\nrewrite regex replacement [flag];\nregex: 用于匹配的正则表达式。\nreplacement: 替换的内容。\nflag: 可选标志，如last、break、redirect、permanent等。\n15.2\n常见标志\nlast: 停止重写，继续处理请求（常用于重定向）。\nbreak: 停止重写，不再处理后续的重写规则。\nredirect: 返回302临时重定向。\npermanent: 返回301永久重定向。\n15.3\n示例\n15.3.1\n\\1. 简单的URL重写\n假设你想将所有以/old-path开头的URL重写到/new-path：\nnginx\nlocation / { rewrite ^/old-path(/.*)$ /new-path$1 last; }\n在这个例子中，所有匹配/old-path的请求都会被重定向到/new-path，并且保留原始路径中的其余部分。\n15.3.2\n\\2. 重定向到另一个域名\n如果你想将请求重定向到另一个域名，例如将example.com重定向到www.example.com：\nnginx\nserver { listen 80; server_name example.com; location / { rewrite ^(.*)$ http://www.example.com$1 permanent; } }\n这个配置会将所有对example.com的请求永久重定向到www.example.com。\n15.3.3\n\\3. 内部重写（不改变URL）\n如果你希望内部重写URL而不改变客户端看到的URL，可以使用break标志：\nnginx\nlocation / { rewrite ^/old-path(/.*)$ /new-path$1 break; }\n这个配置会将匹配的请求内部重写到/new-path，但客户端浏览器仍然显示原来的URL。\n15.3.4\n\\4. 条件重写\n你可以结合if语句进行更复杂的条件重写：\nnginx\nlocation / { if ($request_uri ~* \u0026ldquo;^/old-path\u0026rdquo;) { rewrite ^/old-path(/.*)$ /new-path$1 last; } }\n这个例子中，只有当请求URI匹配/old-path时，才会进行重写。\n15.3.5\n\\5. 捕获查询参数\n如果你需要捕获查询参数并将其包含在重写后的URL中，可以使用如下配置：\nnginx\nlocation / { rewrite ^/item/([0-9]+) /product?id=$1 last; }\n这个配置会将类似/item/123的URL重写成/product?id=123。\n15.4\n完整示例配置文件\n以下是一个包含多个重写规则的完整Nginx配置文件示例：\nnginx\nuser www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/.conf; events { worker_connections 1024; } http { sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; gzip on; gzip_disable \u0026ldquo;msie6\u0026rdquo;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; server { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; location / { # 重定向不带www的请求到带www的域名 if ($host ~ ^example.com$) { rewrite ^(.)$ http://www.$host$1 permanent; } # 重写旧路径到新路径 rewrite ^/old-path(/.)$ /new-path$1 last; # 内部重写，不改变URL rewrite ^/internal-path(/.*)$ /internal-rewrite$1 break; } } }\n这个配置文件展示了如何结合多种重写规则来实现不同的URL处理需求。通过合理使用这些指令，你可以在Nginx中实现灵活的URL重写和重定向。\n16\n如何在Nginx中配置错误页面？\n在Nginx中配置错误页面（如404、500等）是一个常见的需求，可以通过error_page指令来实现。这个指令允许你指定特定状态码对应的自定义错误页面。以下是详细的步骤和示例：\n16.1\n基本语法\nnginx\nerror_page code [code \u0026hellip;] =uri | @named_location;\ncode: HTTP状态码，例如404、500等。\nuri: 错误页面的路径，可以是相对路径或绝对路径。\n@named_location: 命名位置块，用于更复杂的错误处理逻辑。\n16.2\n示例配置\n16.2.1\n简单的错误页面\n假设你想为404错误配置一个自定义页面，可以这样设置：\nnginx\nserver { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; error_page 404 /custom_404.html; location = /custom_404.html { internal; } }\n在这个例子中，当发生404错误时，Nginx会返回/custom_404.html页面。注意，我们使用internal指令来防止直接访问这个错误页面。\n16.2.2\n多个错误页面\n你可以为不同的错误代码指定不同的错误页面：\nnginx\nserver { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; error_page 404 /custom_404.html; error_page 500 502 503 504 /custom_50x.html; location = /custom_404.html { internal; } location = /custom_50x.html { internal; } }\n在这个配置中，404错误会显示/custom_404.html页面，而500、502、503和504错误会显示/custom_50x.html页面。\n16.2.3\n使用命名位置块处理复杂逻辑\n如果你需要更复杂的错误处理逻辑，可以使用命名位置块：\nnginx\nserver { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; error_page 404 = @custom_404; error_page 500 502 503 504 = @custom_50x; location @custom_404 { # 这里可以添加更多复杂的逻辑，比如日志记录、重定向等 return 404 \u0026ldquo;Custom 404 Page\u0026rdquo;; } location @custom_50x { # 这里可以添加更多复杂的逻辑，比如日志记录、重定向等 return 500 \u0026ldquo;Custom 50x Page\u0026rdquo;; } }\n在这个配置中，404错误会跳转到@custom_404位置块，而500、502、503和504错误会跳转到@custom_50x位置块。你可以在这些位置块中实现更复杂的逻辑。\n16.2.4\n全局错误页面配置\n你也可以在http块中定义全局的错误页面，这样所有服务器块都会继承这些配置：\nnginx\nhttp { include /etc/nginx/mime.types; default_type application/octet-stream; error_page 404 /global_404.html; error_page 500 502 503 504 /global_50x.html; server { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; } server { listen 80; server_name another-example.com; root /var/www/another_html; index index.html index.htm; } }\n在这个配置中，所有服务器块都会使用相同的错误页面配置。\n16.3\n完整示例配置文件\n以下是一个包含多种错误页面配置的完整Nginx配置文件示例：\nnginx\nuser www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 1024; } http { sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; gzip on; gzip_disable \u0026ldquo;msie6\u0026rdquo;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; error_page 404 /global_404.html; error_page 500 502 503 504 /global_50x.html; server { listen 80; server_name example.com; root /var/www/html; index index.html index.htm; location = /global_404.html { internal; } location = /global_50x.html { internal; } } server { listen 80; server_name another-example.com; root /var/www/another_html; index index.html index.htm; location = /global_404.html { internal; } location = /global_50x.html { internal; } } }\n通过合理使用error_page指令，你可以在Nginx中灵活地配置和管理各种错误页面，从而提升用户体验和系统的稳定性。\n17\n解释Nginx中的worker进程和master进程。\n在Nginx的架构中，有两个核心进程：master进程和worker进程。这两个进程共同协作，以高效地处理客户端请求。以下是对这两个进程的详细解释：\n17.1\nMaster 进程\n17.1.1\n功能\n管理：master进程负责启动和管理worker进程。它负责读取配置文件、初始化日志文件、创建worker进程等。\n信号处理：master进程会监听操作系统的信号（如HUP、TERM、USR2等），并根据这些信号执行相应的操作，例如重新加载配置、优雅关闭等。\n健康检查：master进程会定期检查worker进程的健康状态，如果发现某个worker进程异常退出，它会重新启动一个新的worker进程来替代它。\n17.1.2\n特点\n单实例：在一个Nginx实例中，只有一个master进程。\n轻量级：master进程本身不直接处理客户端请求，因此它的资源消耗非常小。\n17.2\nWorker 进程\n17.2.1\n功能\n处理请求：worker进程是实际处理客户端请求的进程。每个worker进程都是独立的，可以并行处理多个连接和请求。\n事件驱动：worker进程使用事件驱动模型（如epoll或kqueue）来高效地处理大量并发连接。\n负载均衡：在多核CPU环境下，Nginx可以通过启动多个worker进程来实现负载均衡，充分利用多核CPU的性能。\n17.2.2\n特点\n多实例：可以根据配置文件中的设置启动多个worker进程。\n高并发：由于每个worker进程都可以独立处理请求，因此Nginx能够高效地处理大量并发连接。\n17.3\n配置文件示例\n以下是一个典型的Nginx配置文件示例，展示了如何配置worker进程的数量：\nnginx\nworker_processes auto; # 自动检测并设置为与CPU核心数相同的数量 events { worker_connections 1024; # 每个worker进程的最大连接数 }\n在这个配置中：\nworker_processes auto;：Nginx会自动检测系统的CPU核心数，并启动相应数量的worker进程。你也可以手动指定一个具体的数字，例如worker_processes 4;。\nworker_connections 1024;：每个worker进程可以同时处理的最大连接数。\n17.4\n工作流程\n1\n启动：当Nginx启动时，首先由master进程读取配置文件并初始化环境。\n2\n创建worker进程：根据配置文件中的设置，master进程会创建指定数量的worker进程。\n3\n监听端口：所有worker进程都会监听指定的端口，等待客户端请求的到来。\n4\n处理请求：当有客户端请求到达时，worker进程会接收请求并进行处理，包括解析请求、访问后端服务器、返回响应等。\n5\n信号处理：如果需要重新加载配置或优雅关闭Nginx，master进程会发送相应的信号给worker进程，让它们执行相应的操作。\n6\n健康检查：master进程会定期检查worker进程的状态，确保它们正常运行。如果某个worker进程异常退出，master进程会立即启动一个新的worker进程来替代它。\n通过这种设计，Nginx能够在高并发环境下高效地处理大量请求，同时保持较高的稳定性和可靠性。\n18\n如何在Nginx中配置健康检查？\n在Nginx中，健康检查通常是指对后端服务器（如应用服务器、数据库服务器等）进行定期的健康状态检查，以确保它们正常运行。如果某个后端服务器出现故障，Nginx可以自动将请求转发到其他健康的服务器上。这种机制可以通过upstream模块和相关指令来实现。\n以下是如何在Nginx中配置健康检查的详细步骤：\n18.1\n定义上游服务器组\n首先，你需要定义一个上游服务器组，并在其中列出所有后端服务器。你可以使用upstream块来定义这个组。\nnginx\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name example.com; location / { proxy_pass http://backend; } } }\n在这个示例中，我们定义了一个名为backend的上游服务器组，其中包含三个后端服务器。\n18.2\n配置健康检查参数\nNginx提供了一些参数来配置健康检查的行为，包括：\nmax_fails：在认为服务器不可用之前允许失败的最大次数。\nfail_timeout：在多长时间内认为服务器是不可用的。\ninterval：健康检查的时间间隔。\n你可以在server指令中添加这些参数。例如：\nnginx\nhttp { upstream backend { server backend1.example.com max_fails=3 fail_timeout=30s; server backend2.example.com max_fails=3 fail_timeout=30s; server backend3.example.com max_fails=3 fail_timeout=30s; } server { listen 80; server_name example.com; location / { proxy_pass http://backend; } } }\n在这个配置中：\nmax_fails=3：如果某个后端服务器连续三次健康检查失败，则认为该服务器不可用。\nfail_timeout=30s：如果某个后端服务器被标记为不可用，它将在30秒内不再接收新的请求。\n18.3\n使用第三方模块（可选）\n如果你需要更复杂的健康检查功能，可以考虑使用第三方模块，如nginx_upstream_check_module。这个模块提供了更多的健康检查选项，如HTTP检查、TCP检查等。\n18.3.1\n安装第三方模块\n首先，你需要下载并编译Nginx，同时包含nginx_upstream_check_module模块。以下是一个基本的安装步骤：\nBash\n# 下载Nginx源码 wget http://nginx.org/download/nginx-1.20.1.tar.gz tar -zxvf nginx-1.20.1.tar.gz cd nginx-1.20.1 # 下载nginx_upstream_check_module模块源码 git clone https://github.com/yaoweibin/nginx_upstream_check_module.git # 编译Nginx并包含模块 ./configure \u0026ndash;add-module=./nginx_upstream_check_module make sudo make install\n18.3.2\n配置第三方模块\n安装完成后，你可以在Nginx配置文件中使用check指令来配置健康检查。例如：\nnginx\nhttp { upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com; check interval=5000 rise=2 fall=5 timeout=2000 type=http; } server { listen 80; server_name example.com; location / { proxy_pass http://backend; } } }\n在这个配置中：\ninterval=5000：每5秒进行一次健康检查。\nrise=2：如果连续两次检查成功，则认为服务器恢复正常。\nfall=5：如果连续五次检查失败，则认为服务器不可用。\ntimeout=2000：每次健康检查的超时时间为2秒。\ntype=http：使用HTTP协议进行健康检查。\n通过以上配置，Nginx能够有效地监控后端服务器的健康状态，并在检测到服务器故障时自动将流量转移到其他健康的服务器上，从而提高系统的稳定性和可靠性。\n19\n如何在Nginx中限制客户端请求速率？\n在Nginx中，限制客户端请求速率可以通过使用limit_req和limit_conn模块来实现。这些模块允许你控制每个IP地址的请求速率和连接数，从而防止滥用和DDoS攻击。\n19.1\n使用 limit_req 模块\nlimit_req模块用于限制每个IP地址的请求速率。你需要定义一个共享内存区域来存储请求计数器，并在服务器或位置块中使用limit_req_zone和limit_req指令。\n19.1.1\n配置示例\nnginx\nhttp { # 定义一个名为 \u0026lsquo;one\u0026rsquo; 的共享内存区域，大小为 10MB，用于存储请求计数器 limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { listen 80; server_name example.com; location / { # 应用请求速率限制 limit_req zone=one burst=5 nodelay; proxy_pass http://backend; } } }\n在这个配置中：\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;：定义了一个名为one的共享内存区域，大小为10MB，用于存储请求计数器。rate=1r/s表示每秒允许1个请求。\nlimit_req zone=one burst=5 nodelay;：对请求速率进行限制。burst=5表示允许突发最多5个请求，nodelay表示不延迟处理突发请求。\n19.2\n使用 limit_conn 模块\nlimit_conn模块用于限制每个IP地址的并发连接数。你需要定义一个共享内存区域来存储连接计数器，并在服务器或位置块中使用limit_conn_zone和limit_conn指令。\n19.2.1\n配置示例\nnginx\nhttp { # 定义一个名为 \u0026lsquo;addr\u0026rsquo; 的共享内存区域，大小为 10MB，用于存储连接计数器 limit_conn_zone $binary_remote_addr zone=addr:10m; server { listen 80; server_name example.com; location / { # 应用连接数限制 limit_conn addr 10; proxy_pass http://backend; } } }\n在这个配置中：\nlimit_conn_zone $binary_remote_addr zone=addr:10m;：定义了一个名为addr的共享内存区域，大小为10MB，用于存储连接计数器。\nlimit_conn addr 10;：对每个IP地址的并发连接数进行限制，最多允许10个并发连接。\n19.3\n综合使用 limit_req 和 limit_conn\n你可以同时使用这两个模块来更全面地限制客户端请求速率和并发连接数。例如：\nnginx\nhttp { # 定义请求速率限制的共享内存区域 ​ limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; # 定义连接数限制的共享内存区域 ​ limit_conn_zone $binary_remote_addr zone=addr:10m;\n​ server { ​ listen 80; ​ server_name example.com;\n​ location / { # 应用请求速率限制 ​ limit_req zone=one burst=5 nodelay; # 应用连接数限制 ​ limit_conn addr 10;\n​ proxy_pass http://backend; ​ } ​ } }\n在这个配置中，每个IP地址的请求速率被限制为每秒1个请求，并且每个IP地址的并发连接数被限制为最多10个。\n通过以上配置，Nginx能够有效地限制客户端请求速率和并发连接数，从而保护后端服务器免受滥用和DDoS攻击的影响。\n20\n如何在Nginx中处理慢请求？\n在Nginx中处理慢请求可以通过配置超时参数来实现。这些参数可以控制客户端连接、读取和发送数据的超时时间，从而防止慢请求占用服务器资源。以下是一些常用的超时参数及其配置方法：\n20.1\nclient_body_timeout\n这个指令用于设置客户端发送请求体的超时时间。如果客户端在指定时间内没有发送完整的请求体，Nginx将关闭连接。\nnginx\nhttp { client_body_timeout 10s; }\n在这个配置中，如果客户端在10秒内没有发送完整的请求体，Nginx将关闭连接。\n20.2\nclient_header_timeout\n这个指令用于设置客户端发送请求头的超时时间。如果客户端在指定时间内没有发送完整的请求头，Nginx将关闭连接。\nnginx\nhttp { client_header_timeout 10s; }\n在这个配置中，如果客户端在10秒内没有发送完整的请求头，Nginx将关闭连接。\n20.3\nkeepalive_timeout\n这个指令用于设置长连接的超时时间。如果客户端在指定时间内没有发送新的请求，Nginx将关闭连接。\nnginx\nhttp { keepalive_timeout 75s; }\n在这个配置中，如果客户端在75秒内没有发送新的请求，Nginx将关闭连接。\n20.4\nsend_timeout\n这个指令用于设置响应数据发送给客户端的超时时间。如果Nginx在指定时间内没有成功发送响应数据，连接将被关闭。\nnginx\nhttp { send_timeout 60s; }\n在这个配置中，如果Nginx在60秒内没有成功发送响应数据，连接将被关闭。\n20.5\nproxy_read_timeout\n这个指令用于设置从后端服务器读取响应数据的超时时间。如果Nginx在指定时间内没有从后端服务器读取到响应数据，连接将被关闭。\nnginx\nhttp { proxy_read_timeout 60s; }\n在这个配置中，如果Nginx在60秒内没有从后端服务器读取到响应数据，连接将被关闭。\n20.6\nproxy_connect_timeout\n这个指令用于设置连接到后端服务器的超时时间。如果Nginx在指定时间内无法连接到后端服务器，连接将被关闭。\nnginx\nhttp { proxy_connect_timeout 30s; }\n在这个配置中，如果Nginx在30秒内无法连接到后端服务器，连接将被关闭。\n20.7\nproxy_send_timeout\n这个指令用于设置向后端服务器发送请求数据的超时时间。如果Nginx在指定时间内没有成功发送请求数据，连接将被关闭。\nnginx\nhttp { proxy_send_timeout 30s; }\n在这个配置中，如果Nginx在30秒内没有成功发送请求数据，连接将被关闭。\n20.8\n综合示例\n以下是一个综合示例，展示了如何在一个Nginx配置文件中同时设置多个超时参数：\nnginx\nhttp { # 设置客户端发送请求体的超时时间为10秒 ​ client_body_timeout 10s; # 设置客户端发送请求头的超时时间为10秒 ​ client_header_timeout 10s; # 设置长连接的超时时间为75秒 ​ keepalive_timeout 75s; # 设置响应数据发送给客户端的超时时间为60秒 ​ send_timeout 60s; # 设置从后端服务器读取响应数据的超时时间为60秒 ​ proxy_read_timeout 60s; # 设置连接到后端服务器的超时时间为30秒 ​ proxy_connect_timeout 30s; # 设置向后端服务器发送请求数据的超时时间为30秒 ​ proxy_send_timeout 30s; }\n通过以上配置，你可以有效地控制Nginx处理慢请求的行为，从而提高服务器的性能和稳定性。\n21\n解释Nginx中的epoll机制。\nNginx中的epoll机制是一种高效的I/O事件通知机制，主要用于处理大量并发连接。它是由Linux内核提供的一种多路复用I/O接口，能够高效地监控多个文件描述符（如套接字）的状态变化，并在这些文件描述符就绪时通知应用程序。\n21.1\nepoll 机制的工作原理\n1\n创建 epoll 实例：\n使用 epoll_create 或 epoll_create1 系统调用创建一个 epoll 实例，返回一个 epoll 文件描述符。\n2\n注册文件描述符：\n使用 epoll_ctl 系统调用将需要监控的文件描述符添加到 epoll 实例中。可以指定要监控的事件类型，如读、写和异常。\n3\n等待事件：\n使用 epoll_wait 系统调用等待事件发生。当有文件描述符就绪时，epoll_wait 会返回并填充一个事件列表，应用程序可以根据这个列表进行相应的处理。\n4\n处理事件：\n应用程序根据 epoll_wait 返回的事件列表，对就绪的文件描述符进行处理，如读取数据、写入数据等。\n5\n修改或删除文件描述符：\n使用 epoll_ctl 系统调用可以修改或删除已经注册的文件描述符。\n21.2\nepoll 的优势\n高效性：epoll 在处理大量并发连接时比传统的 select 和 poll 更加高效，因为它避免了每次调用都需要遍历所有文件描述符的开销。\n可扩展性：epoll 支持动态添加和删除文件描述符，适应高并发场景的需求。\n事件驱动：epoll 采用事件驱动模型，只有在文件描述符状态发生变化时才会通知应用程序，减少了不必要的系统调用。\n21.3\nNginx 中的 epoll 应用\n在 Nginx 中，epoll 被广泛应用于网络事件的处理，特别是在处理大量并发连接时。以下是 Nginx 中使用 epoll 的一些关键点：\n1\n事件循环：\nNginx 使用一个事件循环来管理所有的 I/O 事件。在这个循环中，Nginx 使用 epoll 来监控各种事件，如新连接的到来、数据的读写等。\n2\n异步非阻塞 I/O：\nNginx 采用异步非阻塞 I/O 模型，通过 epoll 实现高效的事件通知。这使得 Nginx 能够在单线程或少量线程的情况下处理大量的并发请求。\n3\n负载均衡和反向代理：\n在负载均衡和反向代理的场景中，Nginx 需要同时处理来自客户端的请求和后端服务器的响应。通过 epoll，Nginx 可以高效地管理这些请求和响应，确保高性能和低延迟。\n21.4\n示例代码\n以下是一个简化的示例代码，展示了如何在 C 语言中使用 epoll：\nC\n#include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt;\n#define MAX_EVENTS 10\nint main() { int epoll_fd = epoll_create1(0); if (epoll_fd == -1) { perror(\u0026ldquo;epoll_create1\u0026rdquo;); exit(EXIT_FAILURE); }\n​ struct epoll_event event; ​ struct epoll_event events[MAX_EVENTS]; ​ int listen_sock = /* \u0026hellip; */; // 假设已经创建了一个监听套接字\n​ event.events = EPOLLIN; ​ event.data.fd = listen_sock; ​ if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, listen_sock, \u0026amp;event) == -1) { ​ perror(\u0026ldquo;epoll_ctl: listen_sock\u0026rdquo;); ​ exit(EXIT_FAILURE); ​ }\n​ while (1) { ​ int nfds = epoll_wait(epoll_fd, events, MAX_EVENTS, -1); ​ if (nfds == -1) { ​ perror(\u0026ldquo;epoll_wait\u0026rdquo;); ​ exit(EXIT_FAILURE); ​ }\n​ for (int n = 0; n \u0026lt; nfds; ++n) { ​ if (events[n].data.fd == listen_sock) { ​ // 处理新的连接 ​ } else { ​ // 处理已存在的连接的数据读写 ​ } ​ } ​ }\n​ close(epoll_fd); ​ return 0; }\n21.5\n总结\nNginx 中的 epoll 机制通过高效的事件通知和处理方式，使得 Nginx 能够在高并发环境下保持高性能和稳定性。epoll 的引入极大地提升了 Nginx 在处理大量并发连接时的效率，是 Nginx 能够成为高性能 Web 服务器的重要原因之一。\n22\n如何在Nginx中实现动静分离？\n在Nginx中实现动静分离（将动态内容和静态内容分别处理）是一种常见的优化策略，可以提高服务器的性能和响应速度。以下是实现动静分离的步骤：\n22.1\n安装 Nginx\n首先，确保你已经安装了 Nginx。如果还没有安装，可以使用以下命令进行安装：\nBash\nsudo apt-get update sudo apt-get install nginx\n22.2\n配置 Nginx\n编辑 Nginx 配置文件，通常位于 /etc/nginx/nginx.conf 或 /etc/nginx/sites-available/default。\n22.2.1\n示例配置\n假设你的静态文件存放在 /var/www/html/static 目录，而动态请求由后端应用服务器（如 PHP-FPM、Node.js 等）处理。\nnginx\nserver { listen 80; server_name your_domain.com; # 定义根目录 root /var/www/html; # 处理静态文件 location /static/ { alias /var/www/html/static/; expires 30d; # 设置缓存时间 access_log off; # 关闭访问日志 } # 处理动态请求 location / { proxy_pass http://backend_server; # 将请求转发到后端服务器 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } }\n在这个配置中：\nlocation /static/ 用于处理静态文件请求，使用 alias 指令将请求映射到实际的文件系统路径。\nexpires 30d; 设置了静态文件的缓存时间为 30 天。\naccess_log off; 关闭了对静态文件的访问日志记录。\nlocation / 用于处理动态请求，通过 proxy_pass 指令将请求转发到后端服务器（例如 PHP-FPM、Node.js 等）。\n22.3\n重启 Nginx\n保存配置文件后，重启 Nginx 以使配置生效：\nBash\nsudo systemctl restart nginx\n22.4\n验证配置\n打开浏览器，访问你的域名或 IP 地址，并检查静态资源是否正确加载。同时，确认动态请求是否被正确转发到后端服务器。\n22.5\n高级配置（可选）\n根据需求，你可以进一步优化配置，例如：\n压缩：启用 Gzip 压缩来减少传输的数据量。\n缓存控制：为静态资源设置更细粒度的缓存控制策略。\n负载均衡：如果有多个后端服务器，可以配置负载均衡策略。\n22.5.1\n示例：启用 Gzip 压缩\nnginx\nhttp { gzip on; gzip_types text/plain application/xml text/css application/javascript; gzip_min_length 1000; gzip_proxied any; gzip_vary on; }\n22.5.2\n示例：负载均衡配置\nnginx\nupstream backend_servers { server backend1.example.com; server backend2.example.com; server backend3.example.com; } server { listen 80; server_name your_domain.com; location / { proxy_pass http://backend_servers; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } }\n22.6\n总结\n通过以上步骤，你可以在 Nginx 中实现动静分离，从而提高服务器的性能和响应速度。这种配置方式适用于大多数 Web 应用场景，能够有效地区分静态和动态内容，从而优化资源的管理和利用。\n23\n解释Nginx中的access log和error log。\n在Nginx中，访问日志（access_log）和错误日志（error_log）是两种重要的日志类型，它们分别记录了不同的信息，用于监控、分析和调试Nginx服务器的运行情况。\n23.1\n访问日志（access_log）\n1\n定义：访问日志主要用于记录客户端对Nginx服务器的每一次请求。它包含了请求的详细信息，如客户端IP地址、请求时间、请求方法、请求URL、响应状态码、返回的数据大小以及用户代理等信息。\n2\n配置：\n路径：可以通过access_log指令指定访问日志的存放位置。例如，access_log /var/logs/nginx-access.log表示将访问日志写入到/var/logs/nginx-access.log文件。\n格式：默认使用预定义的combined格式，但也可以通过log_format指令自定义日志格式。\n其他参数：如buffer=size（指定日志写入时的缓存大小）、gzip=level（日志写入前进行压缩）和flush=time（设置缓存的有效时间）等。\n3\n作用：访问日志对于统计、系统服务排错非常有用。通过分析访问日志，可以了解网站的访问量、用户行为、热门内容等，从而优化网站性能和用户体验。\n23.2\n错误日志（error_log）\n1\n定义：错误日志记录了Nginx服务器在运行过程中产生的错误信息。这些错误可能包括配置文件语法错误、运行时错误、资源不可用等。\n2\n配置：\n路径：通过error_log指令指定错误日志的存放位置。例如，error_log /var/log/nginx/error.log表示将错误日志写入到/var/log/nginx/error.log文件中。\n级别：可以指定日志级别，如error、warn、info、debug等。级别越高，记录的信息越详细，但也可能包含更多的噪音信息。\n3\n作用：错误日志是调试Nginx服务的重要手段。当服务器出现故障或异常时，通过查看错误日志可以快速定位问题原因，并采取相应的解决措施。\n综上所述，Nginx中的访问日志和错误日志分别记录了客户端请求和服务器错误信息，对于监控、分析和调试Nginx服务器至关重要。在实际应用中，应根据需求合理配置这两种日志的参数和格式，以充分发挥其作用。\n24\n如何在Nginx中配置HTTP基本认证？\n在Nginx中配置HTTP基本认证可以通过以下步骤实现：\n1\n创建密码文件：使用htpasswd命令创建一个包含用户名和密码的文件。如果没有htpasswd命令，可以使用openssl passwd命令代替。例如，创建一个名为htpasswd的文件，并添加一个用户名为dongnan，密码为zongming.net的用户：\nBash\nhtpasswd -bdc htpasswd dongnan zongming.net\n或者使用openssl命令：\nBash\necho -n \u0026lsquo;dongnan:\u0026rsquo; \u0026raquo; .htpasswd openssl passwd -apr1 zongming.net \u0026raquo; .htpasswd\n2\n编辑Nginx配置文件：打开你的Nginx配置文件，通常位于/etc/nginx/conf.d/default.conf或/etc/nginx/nginx.conf。在需要启用HTTP基本认证的location块中，添加以下指令：\nnginx\nauth_basic \u0026ldquo;Restricted Area\u0026rdquo;; auth_basic_user_file /path/to/your/htpasswd;\n其中，\u0026ldquo;Restricted Area\u0026quot;是身份验证提示信息，可以根据需要进行修改；/path/to/your/htpasswd是密码文件的路径，请确保路径正确。\n3\n重启Nginx服务：保存配置文件后，重启Nginx服务以使配置生效：\nBash\nsudo systemctl restart nginx\n通过以上步骤，你就可以在Nginx中成功配置HTTP基本认证。当用户访问受保护的资源时，将会看到一个登录窗口，要求输入用户名和密码。只有输入正确的凭据后，才能访问资源。请注意，HTTP基本认证的安全性有限，因为它以明文形式传输凭证，建议在生产环境中结合HTTPS使用以提高安全性。\n25\n如何在Nginx中配置JWT认证？\n在Nginx中配置JWT（JSON Web Token）认证通常涉及以下几个步骤：\n1\n安装必要的模块：\nNginx本身并不直接支持JWT认证，因此你需要使用第三方模块，如ngx_http_auth_request_module或nginx-jwt等。这些模块可以通过包管理器或从源代码编译安装。\n2\n配置JWT认证服务：\n你需要一个服务来验证JWT。这可以是一个专门的认证服务器，或者在你的应用服务器中实现JWT验证逻辑。这个服务应该能够解析JWT并验证其有效性。\n3\n修改Nginx配置文件：\n使用auth_jwt指令或其他相关指令来配置JWT认证。你需要指定JWT密钥、验证服务URL以及其他相关参数。\n示例配置可能如下：\nnginx\nhttp { auth_jwt \u0026ldquo;Your secret key\u0026rdquo; \u0026ldquo;https://auth.example.com/validate\"; \u0026hellip; }\n请注意，具体的配置语法和参数取决于你使用的JWT模块。\n4\n测试配置：\n在完成配置后，重新启动Nginx服务以使配置生效。然后，尝试访问受保护的资源以测试JWT认证是否按预期工作。\n5\n处理错误和日志：\n确保你的Nginx配置中包含适当的错误处理和日志记录，以便在出现问题时能够进行调试和故障排除。\n请注意，由于JWT认证涉及到安全敏感的操作，因此在生产环境中使用时需要格外小心。确保你的JWT密钥保密，并且验证服务是安全的。此外，定期审查和更新你的安全策略也是非常重要的。\n26\n解释Nginx中的location指令及其用法。\n在Nginx中，location指令是用于匹配请求URI并执行相应操作的关键指令。它允许服务器根据请求的URI来决定如何处理这个请求，从而为Web应用提供强大的URL匹配和处理能力。\n26.1\n作用\nURL匹配：location指令的主要作用是根据用户请求的URI来决定如何处理这个请求。它可以将不同的请求映射到文件系统的不同路径，或者将请求转发到其他服务器。\n灵活路由：通过合理配置location，可以实现诸如静态文件服务、反向代理、负载均衡等多种功能。\n26.2\n用法\n基本语法：location [修饰符] 匹配模式 { \u0026hellip; }。其中，“修饰符”是可选的，而“匹配模式”则是必须指定的。大括号内包含了当URL匹配成功时要执行的指令集。\n常见修饰符：\n=：表示精确匹配。如果找到精确匹配，则立即停止搜索。\n^~：表示如果该符号后面的字符是最佳匹配，则采用该规则，不再进行后续的正则表达式匹配。\n~：表示区分大小写的正则匹配。\n~*：表示不区分大小写的正则匹配。\n（无修饰符）：表示前缀匹配。\n匹配模式：可以是一个字符串，也可以是一个正则表达式。Nginx会根据请求的URI与这个匹配模式进行比较，以决定是否应用该location块中的配置。\n示例：\nlocation = / { \u0026hellip; }：使用\u0026rdquo;=\u0026ldquo;修饰符，表示精确匹配根路径\u0026rdquo;/\u0026quot;。\nlocation ^~ /images/ { \u0026hellip; }：使用了\u0026rdquo;^~\u0026ldquo;修饰符，表示如果请求的URI以\u0026rdquo;/images/\u0026ldquo;开头，就会使用这个location块的配置，且不再检查其他正则表达式location。\nlocation ~ .(gif|jpg|png)$ { \u0026hellip; }：使用了\u0026rdquo;~\u0026ldquo;修饰符，表示对URI进行区分大小写的正则匹配。它会匹配所有以\u0026rdquo;.gif\u0026quot;、\u0026quot;.jpg\u0026quot;或\u0026quot;.png\u0026quot;结尾的请求。\nlocation /documents/ { \u0026hellip; }：没有使用修饰符，表示对\u0026quot;/documents/\u0026ldquo;路径进行前缀匹配。\n总之，Nginx的location指令是一个功能强大且灵活的工具，它允许服务器根据请求的URI来执行不同的操作。通过合理配置location，可以实现复杂的Web服务器功能，如静态文件服务、反向代理、负载均衡等。然而，由于其强大的功能也带来了一定的复杂性，因此正确理解和使用location指令对于Nginx管理员和Web开发者来说至关重要。\n27\n如何在Nginx中配置自定义错误页面？\n在Nginx中配置自定义错误页面，可以通过修改Nginx的配置文件来实现。以下是详细的步骤和示例：\n1\n准备自定义错误页面：\n创建或编辑一个HTML文件作为错误页面，例如50x.html，并将其放置在指定的目录中，如/usr/local/nginx/html/myerror/。\n2\n修改Nginx配置文件：\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf）。\n在server块中，添加或修改error_page指令来指定自定义错误页面。例如，对于500、502、503和504错误，可以配置如下：\nnginx\nerror_page 500 502 503 504 /50x.html;\n接着，使用location =指令来定义当发生这些错误时，Nginx应该返回哪个文件。例如：\nnginx\nlocation = /50x.html { root /usr/local/nginx/html/myerror; }\n如果需要为其他类型的错误（如404）也配置自定义页面，可以类似地添加error_page和location =指令。\n3\n重启Nginx服务：\n保存配置文件后，重启Nginx服务以使更改生效。可以使用以下命令：\nBash\nsudo systemctl restart nginx\n或者，如果你使用的是较旧的系统，可能需要使用：\nBash\nsudo service nginx restart\n4\n验证配置：\n访问你的网站，并尝试触发一些错误（如访问不存在的页面或资源），以验证自定义错误页面是否按预期显示。\n需要注意的是，具体的配置路径和命令可能因Nginx的安装方式和操作系统的不同而有所差异。此外，如果你在使用反向代理或其他高级功能，还可能需要配置额外的指令来确保错误页面能够正确显示。\n另外，如果你希望对某些特定的URL路径应用不同的错误页面，也可以在相应的location块中单独配置error_page指令。\n最后，建议在进行任何重大更改之前备份原始的Nginx配置文件，以防万一出现问题可以快速恢复。\n28\n如何在Nginx中配置HTTP到HTTPS的重定向？\n在Nginx中配置HTTP到HTTPS的重定向，可以通过修改Nginx的配置文件来实现。以下是详细的步骤和示例：\n1\n准备SSL证书：\n确保你已经获得了有效的SSL证书，并且已经将证书文件（通常是.crt或.pem文件）和私钥文件（通常是.key文件）放置在服务器上。\n2\n修改Nginx配置文件：\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf）。\n在server块中，添加一个新的server块来处理HTTP请求，并将其重定向到HTTPS。例如：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com; return 301 https://$host$request_uri; }\n这个配置表示当有HTTP请求到达时，Nginx会返回一个301永久重定向响应，将请求重定向到相应的HTTPS URL。\n3\n配置HTTPS服务器块：\n在同一个配置文件中，确保你有一个server块来处理HTTPS请求。例如：\nnginx\nserver { listen 443 ssl; server_name yourdomain.com www.yourdomain.com; ssl_certificate /path/to/your/certificate.crt; ssl_certificate_key /path/to/your/private.key; # 其他SSL配置\u0026hellip; location / { root /usr/share/nginx/html; index index.html index.htm; } }\n这个配置表示当有HTTPS请求到达时，Nginx会使用指定的SSL证书和私钥来处理请求。\n4\n重启Nginx服务：\n保存配置文件后，重启Nginx服务以使更改生效。可以使用以下命令：\nBash\nsudo systemctl restart nginx\n或者，如果你使用的是较旧的系统，可能需要使用：\nBash\nsudo service nginx restart\n5\n验证配置：\n访问你的网站，并尝试通过HTTP访问，以验证是否被正确重定向到HTTPS。\n需要注意的是，具体的配置路径和命令可能因Nginx的安装方式和操作系统的不同而有所差异。此外，如果你在使用反向代理或其他高级功能，还可能需要配置额外的指令来确保重定向能够正确工作。\n另外，建议在进行任何重大更改之前备份原始的Nginx配置文件，以防万一出现问题可以快速恢复。\n29\n如何在Nginx中配置基于域名的路由？\n在Nginx中配置基于域名的路由，可以通过修改Nginx的配置文件来实现。以下是详细的步骤和示例：\n1\n准备服务器块：\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf）。\n在配置文件中，为每个域名添加一个server块。例如，如果你有两个域名example1.com和example2.com，你可以这样配置：\nnginx\nserver { listen 80; server_name example1.com www.example1.com; location / { root /var/www/example1; index index.html index.htm; } } server { listen 80; server_name example2.com www.example2.com; location / { root /var/www/example2; index index.html index.htm; } }\n在这个配置中，每个server块监听相同的端口（80），但使用不同的server_name指令来区分不同的域名。每个server块中的location /指令指定了该域名对应的网站根目录。\n2\n配置SSL（可选）：\n如果你希望为这些域名启用HTTPS，可以在相应的server块中添加SSL配置。例如：\nnginx\nserver { listen 443 ssl; server_name example1.com www.example1.com; ssl_certificate /path/to/your/certificate.crt; ssl_certificate_key /path/to/your/private.key; location / { root /var/www/example1; index index.html index.htm; } }\n确保为每个需要HTTPS的域名都配置了相应的SSL证书和私钥。\n3\n重启Nginx服务：\n保存配置文件后，重启Nginx服务以使更改生效。可以使用以下命令：\nBash\nsudo systemctl restart nginx\n或者，如果你使用的是较旧的系统，可能需要使用：\nBash\nsudo service nginx restart\n4\n验证配置：\n访问你的网站，通过不同的域名来验证是否按预期工作。\n需要注意的是，具体的配置路径和命令可能因Nginx的安装方式和操作系统的不同而有所差异。此外，如果你在使用反向代理或其他高级功能，还可能需要配置额外的指令来确保路由能够正确工作。\n另外，建议在进行任何重大更改之前备份原始的Nginx配置文件，以防万一出现问题可以快速恢复。\n30\n解释Nginx中的limit_req和limit_conn模块。\n在Nginx中，limit_req和limit_conn模块用于限制客户端请求的速率和连接数，以防止服务器过载或滥用。以下是对这两个模块的详细解释：\n30.1\nlimit_req 模块\nlimit_req模块用于限制客户端的请求速率，即在一定时间内允许的最大请求数。这对于防止DDoS攻击、API滥用等场景非常有用。\n30.1.1\n配置示例：\nnginx\nhttp { limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s; server { location / { limit_req zone=mylimit burst=5 nodelay; } } }\nlimit_req_zone指令定义了一个共享内存区域，用于存储每个IP地址的请求计数。参数说明：\n$binary_remote_addr：使用二进制格式的客户端IP地址作为键。\nzone=mylimit:10m：定义一个名为mylimit的区域，大小为10MB。\nrate=1r/s：设置请求速率限制为每秒1个请求。\nlimit_req指令应用到特定的location块，参数说明：\nzone=mylimit：指定要使用的共享内存区域。\nburst=5：允许在短时间内超过速率限制的请求数量（突发请求）。\nnodelay：如果设置了nodelay，超出速率限制的请求会立即返回503错误，而不是排队等待。\n30.2\nlimit_conn 模块\nlimit_conn模块用于限制单个IP地址的并发连接数，以防止过多的并发连接导致服务器资源耗尽。\n30.2.1\n配置示例：\nnginx\nhttp { limit_conn_zone $binary_remote_addr zone=addr:10m; server { location / { limit_conn addr 5; } } }\nlimit_conn_zone指令定义了一个共享内存区域，用于存储每个IP地址的连接计数。参数说明：\n$binary_remote_addr：使用二进制格式的客户端IP地址作为键。\nzone=addr:10m：定义一个名为addr的区域，大小为10MB。\nlimit_conn指令应用到特定的location块，参数说明：\naddr：指定要使用的共享内存区域。\n5：限制每个IP地址的最大并发连接数为5。\n30.3\n总结\nlimit_req：用于限制请求速率，可以设置速率限制和突发请求数。适用于需要控制请求频率的场景。\nlimit_conn：用于限制并发连接数，可以防止过多并发连接导致服务器资源耗尽。适用于需要控制并发连接数的场景。\n通过合理配置这两个模块，可以有效保护Nginx服务器免受恶意请求的影响，提高服务器的稳定性和安全性。\n31\n如何在Nginx中配置跨域资源共享（CORS）？\n在Nginx中配置跨域资源共享（CORS）可以通过添加适当的HTTP头来实现。以下是详细的步骤和示例：\n31.1\n修改Nginx配置文件\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf）。\n31.2\n添加CORS相关的HTTP头\n在需要支持CORS的server块或location块中，添加以下配置：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com;\n​ location / { # 允许所有来源 ​ add_header \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; \u0026lsquo;*\u0026rsquo;;\n# 允许的方法\r​ add_header \u0026lsquo;Access-Control-Allow-Methods\u0026rsquo; \u0026lsquo;GET, POST, OPTIONS\u0026rsquo;;\n# 允许的请求头\r​ add_header \u0026lsquo;Access-Control-Allow-Headers\u0026rsquo; \u0026lsquo;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026rsquo;;\n# 允许携带凭证\r​ add_header \u0026lsquo;Access-Control-Allow-Credentials\u0026rsquo; \u0026rsquo;true\u0026rsquo;;\n# 预检请求的缓存时间\r​ add_header \u0026lsquo;Access-Control-Max-Age\u0026rsquo; 86400;\n# 处理OPTIONS预检请求\r​ if ($request_method = \u0026lsquo;OPTIONS\u0026rsquo;) { ​ add_header \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; \u0026lsquo;*\u0026rsquo;; ​ add_header \u0026lsquo;Access-Control-Allow-Methods\u0026rsquo; \u0026lsquo;GET, POST, OPTIONS\u0026rsquo;; ​ add_header \u0026lsquo;Access-Control-Allow-Headers\u0026rsquo; \u0026lsquo;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026rsquo;; ​ add_header \u0026lsquo;Access-Control-Allow-Credentials\u0026rsquo; \u0026rsquo;true\u0026rsquo;; ​ add_header \u0026lsquo;Access-Control-Max-Age\u0026rsquo; 86400; ​ return 204; ​ } ​ } }\n31.3\n解释配置项\nadd_header \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; \u0026lsquo;\u0026rsquo;: 允许所有来源。如果只想允许特定来源，可以将替换为具体的域名。\nadd_header \u0026lsquo;Access-Control-Allow-Methods\u0026rsquo; \u0026lsquo;GET, POST, OPTIONS\u0026rsquo;: 允许的HTTP方法。可以根据需要调整。\nadd_header \u0026lsquo;Access-Control-Allow-Headers\u0026rsquo; \u0026lsquo;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026rsquo;: 允许的请求头。可以根据需要调整。\nadd_header \u0026lsquo;Access-Control-Allow-Credentials\u0026rsquo; \u0026rsquo;true\u0026rsquo;: 是否允许发送Cookie等凭证信息。如果不需要，可以设置为false。\nadd_header \u0026lsquo;Access-Control-Max-Age\u0026rsquo; 86400: 预检请求的缓存时间，单位是秒。在这个例子中，缓存时间为一天（86400秒）。\nif ($request_method = \u0026lsquo;OPTIONS\u0026rsquo;): 处理OPTIONS预检请求，返回相应的CORS头并返回204状态码。\n31.4\n重启Nginx服务\n保存配置文件后，重启Nginx服务以使更改生效。可以使用以下命令：\nBash\nsudo systemctl restart nginx\n或者，如果你使用的是较旧的系统，可能需要使用：\nBash\nsudo service nginx restart\n31.5\n验证配置\n通过浏览器或工具（如Postman）发送跨域请求，检查响应头中是否包含正确的CORS头信息。\n31.6\n注意事项\n安全性：在生产环境中，不建议将Access-Control-Allow-Origin设置为*，应指定具体的域名以提高安全性。\n复杂配置：对于更复杂的CORS需求，可以考虑使用Nginx的第三方模块或Lua脚本进行更细粒度的控制。\n通过以上步骤，你可以在Nginx中成功配置CORS，从而允许跨域请求访问你的资源。\n32\n如何在Nginx中配置WebSocket支持？\n在Nginx中配置WebSocket支持相对简单，因为Nginx原生支持WebSocket协议。以下是详细的步骤和示例：\n32.1\n修改Nginx配置文件\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf）。\n32.2\n添加WebSocket相关的配置\n在需要支持WebSocket的server块或location块中，添加以下配置：\nnginx\nhttp { server { listen 80; server_name yourdomain.com www.yourdomain.com; location /ws { proxy_pass http://backend_server; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026ldquo;upgrade\u0026rdquo;; proxy_set_header Host $host; } } }\n32.3\n解释配置项\nlisten 80;: 监听80端口。如果你使用HTTPS，可以改为listen 443 ssl;并配置SSL证书。\nserver_name yourdomain.com www.yourdomain.com;: 指定服务器名称。\nlocation /ws { \u0026hellip; }: 定义处理WebSocket请求的位置块。在这个例子中，所有以/ws开头的请求都会被转发到后端服务器。\nproxy_pass http://backend_server;: 将请求转发到后端服务器。你需要将backend_server替换为实际的后端服务器地址。\nproxy_http_version 1.1;: 设置HTTP版本为1.1，这是WebSocket所需的最低版本。\nproxy_set_header Upgrade $http_upgrade;: 设置Upgrade头，用于升级连接。\nproxy_set_header Connection \u0026ldquo;upgrade\u0026rdquo;;: 设置Connection头为upgrade，表示这是一个升级请求。\nproxy_set_header Host $host;: 保留原始主机头信息。\n32.4\n重启Nginx服务\n保存配置文件后，重启Nginx服务以使更改生效。可以使用以下命令：\nBash\nsudo systemctl restart nginx\n或者，如果你使用的是较旧的系统，可能需要使用：\nBash\nsudo service nginx restart\n32.5\n验证配置\n通过浏览器或工具（如Postman）发送WebSocket请求，检查是否能够成功建立连接。你可以使用JavaScript代码来测试WebSocket连接：\nJavaScript\nconst socket = new WebSocket(\u0026lsquo;ws://yourdomain.com/ws\u0026rsquo;); socket.onopen = function(event) { console.log(\u0026lsquo;WebSocket is open now.\u0026rsquo;); }; socket.onmessage = function(event) { console.log(\u0026lsquo;Received message:\u0026rsquo;, event.data); }; socket.onclose = function(event) { console.log(\u0026lsquo;WebSocket is closed now.\u0026rsquo;); }; socket.onerror = function(error) { console.error(\u0026lsquo;WebSocket error:\u0026rsquo;, error); };\n32.6\n注意事项\n安全性：确保你的WebSocket连接是安全的，特别是在生产环境中。建议使用WSS（WebSocket over TLS）而不是WS。\n负载均衡：如果你有多个后端服务器，可以使用Nginx的负载均衡功能来分发WebSocket连接。\n超时设置：根据需要调整超时设置，例如proxy_read_timeout和proxy_send_timeout，以确保连接的稳定性。\n通过以上步骤，你可以在Nginx中成功配置WebSocket支持，从而允许客户端与服务器进行实时通信。\n33\n解释Nginx中的sub_filter模块。\nsub_filter模块是Nginx的一个第三方模块，用于在响应内容中进行字符串替换。它允许你在将响应发送给客户端之前，对响应内容进行动态修改。这个功能对于某些应用场景非常有用，例如：\n替换广告链接或脚本\n修改页面中的特定文本\n添加或删除HTML元素\n33.1\n安装 sub_filter 模块\n首先，你需要确保你的Nginx安装了sub_filter模块。大多数现代的Nginx发行版已经包含了这个模块，但如果你使用的是自定义编译的Nginx，可能需要手动编译该模块。\n33.2\n配置 sub_filter 模块\n以下是如何在Nginx配置文件中使用sub_filter模块的示例：\nnginx\nhttp { server { listen 80; server_name yourdomain.com www.yourdomain.com; location / { proxy_pass http://backend_server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # 启用 sub_filter 模块 sub_filter \u0026lsquo;original_text\u0026rsquo; \u0026lsquo;replacement_text\u0026rsquo;; sub_filter_once off; # 默认情况下，只替换第一次出现的匹配项。设置为off以替换所有匹配项。 } } }\n33.3\n解释配置项\nproxy_pass http://backend_server;: 将请求转发到后端服务器。你需要将backend_server替换为实际的后端服务器地址。\nproxy_set_header Host $host;: 保留原始主机头信息。\nproxy_set_header X-Real-IP $remote_addr;: 设置X-Real-IP头，以便后端服务器知道客户端的真实IP地址。\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;: 设置X-Forwarded-For头，以便后端服务器知道客户端的原始IP地址和代理服务器的IP地址。\nproxy_set_header X-Forwarded-Proto $scheme;: 设置X-Forwarded-Proto头，以便后端服务器知道客户端使用的协议（HTTP或HTTPS）。\nsub_filter \u0026lsquo;original_text\u0026rsquo; \u0026lsquo;replacement_text\u0026rsquo;;: 将响应内容中的original_text替换为replacement_text。你可以根据需要添加多个sub_filter指令来替换不同的文本。\nsub_filter_once off;: 默认情况下，sub_filter只替换第一次出现的匹配项。将sub_filter_once设置为off可以替换所有匹配项。\n33.4\n使用场景示例\n假设你有一个网页，其中包含一个广告链接，你想将其替换为另一个链接。你可以这样配置：\nnginx\nhttp { server { listen 80; server_name yourdomain.com www.yourdomain.com; location / { proxy_pass http://backend_server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # 替换广告链接 sub_filter \u0026lsquo;http://adserver.com/ad123' \u0026lsquo;http://newadserver.com/ad456'; sub_filter_once off; # 替换所有匹配项 } } }\n在这个例子中，所有响应内容中的http://adserver.com/ad123都会被替换为http://newadserver.com/ad456。\n33.5\n注意事项\n性能影响：sub_filter模块会对每个响应进行字符串替换操作，可能会对性能产生一定影响，特别是在高流量环境下。因此，建议仅在必要时使用该模块。\n安全性：确保你替换的内容不会引入安全漏洞，例如跨站脚本攻击（XSS）。\n兼容性：sub_filter模块在某些情况下可能无法正确处理二进制数据或非文本内容，因此在使用时需要谨慎测试。\n通过以上步骤，你可以在Nginx中成功配置sub_filter模块，从而动态修改响应内容。\n34\n如何在Nginx中配置FastCGI？\n在Nginx中配置FastCGI（通常用于处理PHP等动态内容）需要一些特定的设置。以下是详细的步骤和示例：\n34.1\n安装必要的软件包\n首先，确保你已经安装了Nginx和PHP-FPM（FastCGI Process Manager）。你可以使用以下命令来安装它们：\nBash\nsudo apt update sudo apt install nginx php-fpm\n34.2\n修改Nginx配置文件\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/etc/nginx/sites-available/default）。\n34.3\n添加FastCGI相关的配置\n在需要支持FastCGI的server块或location块中，添加以下配置：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com; root /var/www/html; index index.php index.html index.htm; location / { try_files $uri $uri/ =404; } location ~ .php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.4-fpm.sock; # 根据你的PHP版本调整路径 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /.ht { deny all; } }\n34.4\n解释配置项\nlisten 80;: 监听80端口。\nserver_name yourdomain.com www.yourdomain.com;: 定义服务器名称。\nroot /var/www/html;: 设置网站根目录。\nindex index.php index.html index.htm;: 定义默认索引文件。\nlocation / { try_files $uri $uri/ =404; }: 尝试访问请求的文件或目录，如果不存在则返回404错误。\nlocation ~ .php$ { \u0026hellip; }: 匹配所有以.php结尾的请求。\ninclude snippets/fastcgi-php.conf;: 包含FastCGI PHP配置片段。\nfastcgi_pass unix:/run/php/php7.4-fpm.sock;: 指定FastCGI进程管理器的Unix套接字路径。请根据你的PHP版本调整路径。\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;: 设置脚本文件名参数。\ninclude fastcgi_params;: 包含FastCGI参数文件。\nlocation ~ /.ht { deny all; }: 禁止访问以.ht开头的文件和目录。\n34.5\n重启Nginx和PHP-FPM服务\n完成配置后，重启Nginx和PHP-FPM服务以应用更改：\nBash\nsudo systemctl restart nginx sudo systemctl restart php7.4-fpm # 根据你使用的PHP版本调整命令\n34.6\n测试配置\n创建一个PHP文件来测试你的配置，例如在/var/www/html目录下创建一个名为info.php的文件，内容如下：\nPHP\n\u003c?php** phpinfo(); **?\u003e\n然后在浏览器中访问http://yourdomain.com/info.php，你应该能够看到PHP信息页面，这表明FastCGI配置成功。\n34.7\n注意事项\n性能优化：根据需要调整FastCGI缓存和其他性能相关设置。\n安全性：确保你的PHP配置安全，避免暴露敏感信息。\n日志监控：定期检查Nginx和PHP-FPM的日志文件，以便及时发现和解决问题。\n通过以上步骤，你可以在Nginx中成功配置FastCGI，从而处理PHP等动态内容。\n35\n如何在Nginx中配置PHP-FPM？\n在Nginx中配置PHP-FPM（FastCGI Process Manager）是处理PHP动态内容的标准方法。以下是详细的步骤和示例：\n35.1\n安装必要的软件包\n首先，确保你已经安装了Nginx和PHP-FPM。你可以使用以下命令来安装它们：\nBash\nsudo apt update sudo apt install nginx php-fpm\n35.2\n修改Nginx配置文件\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/etc/nginx/sites-available/default）。\n35.3\n添加PHP-FPM相关的配置\n在需要支持PHP-FPM的server块或location块中，添加以下配置：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com; root /var/www/html; index index.php index.html index.htm; location / { try_files $uri $uri/ =404; } location ~ .php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.4-fpm.sock; # 根据你的PHP版本调整路径 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /.ht { deny all; } }\n35.4\n解释配置项\nlisten 80;: 监听80端口。\nserver_name yourdomain.com www.yourdomain.com;: 定义服务器名称。\nroot /var/www/html;: 设置网站根目录。\nindex index.php index.html index.htm;: 定义默认索引文件。\nlocation / { try_files $uri $uri/ =404; }: 尝试访问请求的文件或目录，如果不存在则返回404错误。\nlocation ~ .php$ { \u0026hellip; }: 匹配所有以.php结尾的请求。\ninclude snippets/fastcgi-php.conf;: 包含FastCGI PHP配置片段。\nfastcgi_pass unix:/run/php/php7.4-fpm.sock;: 指定FastCGI进程管理器的Unix套接字路径。请根据你的PHP版本调整路径。例如，对于PHP 7.4，路径通常是/run/php/php7.4-fpm.sock。\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;: 设置脚本文件名参数。\ninclude fastcgi_params;: 包含FastCGI参数文件。\nlocation ~ /.ht { deny all; }: 禁止访问以.ht开头的文件和目录。\n35.5\n重启Nginx和PHP-FPM服务\n完成配置后，重启Nginx和PHP-FPM服务以应用更改：\nBash\nsudo systemctl restart nginx sudo systemctl restart php7.4-fpm # 根据你使用的PHP版本调整命令\n35.6\n测试配置\n创建一个PHP文件来测试你的配置，例如在/var/www/html目录下创建一个名为info.php的文件，内容如下：\nPHP\n\u003c?php** phpinfo(); **?\u003e\n然后在浏览器中访问http://yourdomain.com/info.php，你应该能够看到PHP信息页面，这表明PHP-FPM配置成功。\n35.7\n注意事项\n性能优化：根据需要调整FastCGI缓存和其他性能相关设置。\n安全性：确保你的PHP配置安全，避免暴露敏感信息。\n日志监控：定期检查Nginx和PHP-FPM的日志文件，以便及时发现和解决问题。\nSSL/TLS：如果你的网站需要处理HTTPS请求，请确保配置SSL证书并启用HTTPS。\n通过以上步骤，你可以在Nginx中成功配置PHP-FPM，从而处理PHP等动态内容。\n36\n如何在Nginx中配置uWSGI？\n在Nginx中配置uWSGI（Uniform Web Server Gateway Interface）是处理Python等动态内容的标准方法。以下是详细的步骤和示例：\n36.1\n安装必要的软件包\n首先，确保你已经安装了Nginx和uWSGI。你可以使用以下命令来安装它们：\nBash\nsudo apt update sudo apt install nginx uwsgi uwsgi-plugin-python3\n36.2\n创建uWSGI配置文件\n创建一个uWSGI配置文件，例如/etc/uwsgi/apps-available/yourdomain.ini，内容如下：\nIni\n[uwsgi]\n指定项目目录\rchdir = /var/www/html/yourproject\n指定项目的入口文件\rmodule = wsgi:application\n指定虚拟环境路径（如果有的话）\rhome = /path/to/your/virtualenv\n指定socket文件路径\rsocket = /run/uwsgi/yourdomain.sock\n设置权限\rchmod-socket = 660\n设置进程数和线程数\rprocesses = 4 threads = 2\n设置日志文件路径\rlogto = /var/log/uwsgi/yourdomain.log\n36.3\n启用uWSGI配置\n将uWSGI配置文件链接到apps-enabled目录：\nBash\nsudo ln -s /etc/uwsgi/apps-available/yourdomain.ini /etc/uwsgi/apps-enabled/\n36.4\n修改Nginx配置文件\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/etc/nginx/sites-available/default）。\n在需要支持uWSGI的server块或location块中，添加以下配置：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com; root /var/www/html; index index.html index.htm; location / { try_files $uri $uri/ =404; } location / { include uwsgi_params; uwsgi_pass unix:/run/uwsgi/yourdomain.sock; } location ~ /.ht { deny all; } }\n36.5\n解释配置项\nlisten 80;: 监听80端口。\nserver_name yourdomain.com www.yourdomain.com;: 定义服务器名称。\nroot /var/www/html;: 设置网站根目录。\nindex index.html index.htm;: 定义默认索引文件。\nlocation / { try_files $uri $uri/ =404; }: 尝试访问请求的文件或目录，如果不存在则返回404错误。\nlocation / { \u0026hellip; }: 匹配所有请求。\ninclude uwsgi_params;: 包含uWSGI参数文件。\nuwsgi_pass unix:/run/uwsgi/yourdomain.sock;: 指定uWSGI进程管理器的Unix套接字路径。请根据你的uWSGI配置调整路径。\nlocation ~ /.ht { deny all; }: 禁止访问以.ht开头的文件和目录。\n36.6\n重启Nginx和uWSGI服务\n完成配置后，重启Nginx和uWSGI服务以应用更改：\nBash\nsudo systemctl restart nginx sudo systemctl restart uwsgi\n36.7\n测试配置\n创建一个Python文件来测试你的配置，例如在/var/www/html/yourproject目录下创建一个名为wsgi.py的文件，内容如下：\nPython\ndef application(environ, start_response): status = \u0026lsquo;200 OK\u0026rsquo; output = b\u0026rsquo;Hello World!\u0026rsquo; response_headers = [(\u0026lsquo;Content-type\u0026rsquo;, \u0026rsquo;text/plain\u0026rsquo;), (\u0026lsquo;Content-Length\u0026rsquo;, str(len(output)))] start_response(status, response_headers) return [output]\n然后在浏览器中访问http://yourdomain.com，你应该能够看到“Hello World!”页面，这表明uWSGI配置成功。\n36.8\n注意事项\n性能优化：根据需要调整uWSGI缓存和其他性能相关设置。\n安全性：确保你的uWSGI配置安全，避免暴露敏感信息。\n日志监控：定期检查Nginx和uWSGI的日志文件，以便及时发现和解决问题。\nSSL/TLS：如果你的网站需要处理HTTPS请求，请确保配置SSL证书并启用HTTPS。\n通过以上步骤，你可以在Nginx中成功配置uWSGI，从而处理Python等动态内容。\n37\n解释Nginx中的http2模块。\nNginx中的HTTP/2模块允许Nginx服务器支持HTTP/2协议，这是HTTP协议的第二个主要版本，旨在提高网页加载速度和性能。HTTP/2引入了多项改进，包括多路复用、头部压缩和服务器推送等特性。\n37.1\nHTTP/2的主要特性\n1\n多路复用（Multiplexing）：\n在HTTP/1.x中，每个请求都需要单独的TCP连接，这会导致大量的开销和延迟。HTTP/2允许多个请求和响应在同一个TCP连接上并行进行，从而减少了延迟和提高了效率。\n2\n头部压缩（Header Compression）：\nHTTP/2使用HPACK算法对HTTP头部进行压缩，从而减少了传输的数据量。这对于包含大量重复头部信息的请求特别有用。\n3\n服务器推送（Server Push）：\n服务器可以在客户端请求之前主动发送资源，例如CSS文件、JavaScript文件或图像。这可以减少页面加载时间，因为浏览器不需要等待额外的请求来获取这些资源。\n4\n二进制分帧（Binary Framing）：\nHTTP/2使用二进制格式而不是文本格式，这使得解析更加高效，并且更容易实现多路复用。\n37.2\nNginx中的HTTP/2配置\n要在Nginx中启用HTTP/2，你需要确保你的Nginx版本支持HTTP/2（Nginx 1.9.5及以上版本支持）。然后，你可以在Nginx配置文件中进行相应的设置。\n37.2.1\n基本配置示例\nnginx\nserver { listen 443 ssl http2; server_name yourdomain.com www.yourdomain.com; ssl_certificate /path/to/your/certificate.crt; ssl_certificate_key /path/to/your/private.key; root /var/www/html; index index.html index.htm; location / { try_files $uri $uri/ =404; } }\n37.3\n解释配置项\nlisten 443 ssl http2;: 监听443端口并启用SSL和HTTP/2。\nserver_name yourdomain.com www.yourdomain.com;: 定义服务器名称。\nssl_certificate /path/to/your/certificate.crt;: 指定SSL证书路径。\nssl_certificate_key /path/to/your/private.key;: 指定SSL私钥路径。\nroot /var/www/html;: 设置网站根目录。\nindex index.html index.htm;: 定义默认索引文件。\nlocation / { try_files $uri $uri/ =404; }: 尝试访问请求的文件或目录，如果不存在则返回404错误。\n37.4\n优化HTTP/2性能\n为了进一步优化HTTP/2的性能，你可以调整一些Nginx的配置参数：\nnginx\nhttp { # 启用HTTP/2 ​ http2 on;\n# 设置最大并发流数\r​ http2_max_concurrent_streams 128;\n# 设置初始窗口大小\r​ http2_initial_window_size 65535;\n# 设置最大帧大小\r​ http2_max_frame_size 16384;\n# 设置头部表大小\r​ http2_headers_table_size 4096;\n# 设置服务器推送的最大数量\r​ http2_push_preload on; }\n37.5\n注意事项\n1\nSSL证书：HTTP/2需要SSL/TLS支持，因此你必须配置有效的SSL证书。\n2\n兼容性：虽然大多数现代浏览器都支持HTTP/2，但某些旧版浏览器可能不支持。你可以通过条件语句来处理这种情况。\n3\n性能监控：启用HTTP/2后，建议监控服务器性能，以确保没有出现意外问题。\n4\n安全性：确保你的Nginx和SSL配置是安全的，避免潜在的安全漏洞。\n通过以上步骤，你可以在Nginx中成功启用和配置HTTP/2，从而提升你的网站性能和用户体验。\n38\n如何在Nginx中配置服务器端包含（SSI）？\n在Nginx中配置服务器端包含（SSI，Server Side Include）功能，可以使得网页在发送给客户端之前，通过SSI指令将其他文本、图片或代码信息包含到网页中。这对于管理大型网站、减少冗余内容和提高页面更新效率非常有用。以下是详细的配置步骤：\n38.1\n安装必要的软件包\n确保你已经安装了Nginx。如果没有安装，可以使用以下命令进行安装：\nBash\nsudo apt update sudo apt install nginx-full\n38.2\n配置Nginx以启用SSI\n打开Nginx的配置文件（通常位于/etc/nginx/nginx.conf或/etc/nginx/sites-available/default）。在需要使用SSI的server块或location块中添加以下配置：\nnginx\nserver { listen 80; server_name yourdomain.com www.yourdomain.com; # 开启SSI支持 ssi on; ssi_silent_errors on; ssi_types text/shtml; location / { root /var/www/html; index index.html index.htm; } }\n解释配置项：\nssi on: 开启SSI支持。\nssi_silent_errors on: 在处理SSI文件出错时不输出错误信息。\nssi_types text/shtml: 指定需要支持的SSI文件类型，默认是text/html。\n38.3\n创建测试文件\n为了测试SSI功能，创建一个包含SSI指令的文件。例如，在/var/www/html目录下创建一个名为index.shtml的文件，内容如下：\nHTML\n\u003c!DOCTYPE html\u003e\rSSI Example\rThis is an SSI example\rWelcome to the SSI test page.\n在同一目录下创建一个名为header.html的文件，内容如下：\nHTML\nHome\rAbout\rContact\r38.4\n重启Nginx服务\n完成配置后，重启Nginx服务以应用更改：\nBash\nsudo systemctl restart nginx\n38.5\n访问测试页面\n在浏览器中访问你的域名或IP地址，例如http://yourdomain.com，你应该能够看到包含header.html内容的完整页面，并且显示当前日期和时间。\n38.6\n注意事项\n权限：确保Nginx对包含SSI指令的文件及其包含的文件具有读取权限。\n安全性：避免在包含敏感信息的文件中使用SSI，以防止潜在的安全风险。\n调试：如果SSI指令没有按预期工作，检查Nginx的错误日志（通常位于/var/log/nginx/error.log）以获取更多信息。\n通过以上步骤，你可以在Nginx中成功配置和使用SSI功能，从而简化网页内容的管理和更新。\n39\n解释Nginx中的第三方模块。\nNginx中的第三方模块（Third-party Modules）是扩展Nginx功能的重要工具。这些模块可以增强Nginx的核心功能，使其能够处理更多类型的请求和任务。以下是对Nginx中第三方模块的详细解释：\n39.1\n什么是第三方模块？\n第三方模块是由社区开发者或公司开发的，用于扩展Nginx功能的插件。它们通常以动态链接库（.so文件）的形式存在，可以在编译时或运行时加载到Nginx中。\n39.2\n为什么使用第三方模块？\n扩展功能：Nginx本身是一个高性能的HTTP服务器和反向代理服务器，但通过第三方模块，你可以添加更多的功能，如负载均衡、缓存、安全认证等。\n性能优化：一些第三方模块经过优化，可以显著提高Nginx的性能和稳定性。\n简化配置：某些复杂的功能可以通过第三方模块实现，从而简化Nginx的配置。\n39.3\n如何安装和使用第三方模块？\n39.3.1\n安装第三方模块\n1\n下载源码：首先，从官方仓库或第三方网站下载所需的模块源码。例如，可以从GitHub上获取开源的Nginx模块。\nBash\ngit clone https://github.com/openresty/headers-more-nginx-module.git\n2\n编译Nginx：在编译Nginx时，将第三方模块包含进去。假设你下载了一个名为headers-more-nginx-module的模块，可以使用以下命令进行编译：\nBash\n./configure \u0026ndash;add-module=/path/to/headers-more-nginx-module make sudo make install\n3\n加载模块：有些模块需要在Nginx配置文件中显式加载。例如，对于OpenResty的模块，可能需要在nginx.conf中添加如下配置：\nnginx\nload_module modules/ngx_http_headers_more_filter_module.so;\n39.3.2\n使用第三方模块\n一旦安装并加载了第三方模块，就可以在Nginx配置文件中使用该模块提供的功能。例如，使用headers-more-nginx-module模块来设置响应头：\nnginx\nhttp { server { listen 80; server_name example.com; location / { more_set_headers \u0026lsquo;Server: MyCustomServer\u0026rsquo;; proxy_pass http://backend; } } }\n39.4\n常见的第三方模块\nOpenResty：一个基于Nginx的高性能Web平台，集成了许多有用的第三方模块，如LuaJIT、Redis、Memcached等。\nngx_pagespeed：Google开发的Nginx模块，用于自动优化网页内容，包括图像压缩、CSS和JavaScript最小化等。\nngx_cache_purge：用于清除Nginx缓存的模块，常用于CDN缓存管理。\nngx_brotli：用于启用Brotli压缩的模块，减少传输数据量，提高加载速度。\nngx_http_auth_request_module：用于外部认证的模块，可以将认证请求转发给后端服务。\n39.5\n注意事项\n兼容性：确保第三方模块与当前使用的Nginx版本兼容。\n安全性：选择知名且维护良好的第三方模块，避免使用来源不明的模块，以防止安全漏洞。\n性能影响：第三方模块可能会增加Nginx的内存和CPU使用率，需要监控其性能表现。\n39.6\n示例：安装和使用ngx_pagespeed模块\n1\n下载源码：\nBash\nwget https://dl.google.com/dl/page-speed/psol/1.13.35.2-x64.tar.gz tar -zxvf 1.13.35.2-x64.tar.gz\n2\n编译Nginx：\nBash\n./configure \u0026ndash;add-module=/path/to/ngx_pagespeed-release--beta \u0026ndash;with-compression=gzip \u0026ndash;with-http_ssl_module \u0026ndash;with-pcre \u0026ndash;with-file-aio \u0026ndash;with-http_realip_module \u0026ndash;with-http_addition_module \u0026ndash;with-http_sub_module \u0026ndash;with-http_dav_module \u0026ndash;with-http_flv_module \u0026ndash;with-http_mp4_module \u0026ndash;with-http_gunzip_module \u0026ndash;with-http_gzip_static_module \u0026ndash;with-http_auth_request_module \u0026ndash;with-http_random_index_module \u0026ndash;with-http_secure_link_module \u0026ndash;with-http_stub_status_module \u0026ndash;with-threads \u0026ndash;with-stream \u0026ndash;with-stream_ssl_module \u0026ndash;with-stream_ssl_preread_module \u0026ndash;with-http_slice_module \u0026ndash;with-mail \u0026ndash;with-mail_ssl_module \u0026ndash;add-module=/path/to/headers-more-nginx-module \u0026ndash;add-module=/path/to/ngx_brotli \u0026ndash;add-module=/path/to/ngx_cache_purge \u0026ndash;add-module=/path/to/ngx_http_auth_request_module \u0026ndash;with-ld-opt=\u0026quot;-Wl,-rpath,/usr/local/lib\u0026rdquo; \u0026ndash;prefix=/etc/nginx \u0026ndash;sbin-path=/usr/sbin/nginx \u0026ndash;conf-path=/etc/nginx/nginx.conf \u0026ndash;error-log-path=/var/log/nginx/error.log \u0026ndash;http-log-path=/var/log/nginx/access.log \u0026ndash;pid-path=/var/run/nginx.pid \u0026ndash;lock-path=/var/run/nginx.lock \u0026ndash;http-client-body-temp-path=/var/cache/nginx/client_temp \u0026ndash;http-proxy-temp-path=/var/cache/nginx/proxy_temp \u0026ndash;http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \u0026ndash;http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \u0026ndash;http-scgi-temp-path=/var/cache/nginx/scgi_temp \u0026ndash;user=www-data \u0026ndash;group=www-data \u0026ndash;with-debug \u0026ndash;with-pcre-jit \u0026ndash;with-file-aio \u0026ndash;with-http_ssl_module \u0026ndash;with-http_v2_module \u0026ndash;with-http_realip_module \u0026ndash;with-http_addition_module \u0026ndash;with-http_sub_module \u0026ndash;with-http_dav_module \u0026ndash;with-http_flv_module \u0026ndash;with-http_mp4_module \u0026ndash;with-http_gunzip_module \u0026ndash;with-http_gzip_static_module \u0026ndash;with-http_auth_request_module \u0026ndash;with-http_random_index_module \u0026ndash;with-http_secure_link_module \u0026ndash;with-http_stub_status_module \u0026ndash;with-threads \u0026ndash;with-stream \u0026ndash;with-stream_ssl_module \u0026ndash;with-stream_ssl_preread_module \u0026ndash;with-http_slice_module \u0026ndash;with-mail \u0026ndash;with-mail_ssl_module \u0026ndash;with-cc-opt=\u0026rsquo;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector \u0026ndash;param=ssp-buffer-size=4 -m64 -mtune=generic\u0026rsquo; \u0026ndash;with-ld-opt=\u0026rsquo;-Wl,-rpath,/usr/local/lib -L/usr/local/lib\u0026rsquo; make sudo make install\n3\n配置Nginx：\nnginx\nhttp { pagespeed on; pagespeed FileCachePath /var/ngx_pagespeed_cache; pagespeed RewriteLevel CoreFilters; pagespeed EnableFilters combine_css,extend_cache,collapse_whitespace; server { listen 80; server_name example.com; location / { root /usr/share/nginx/html; index index.html index.htm; } } }\n总结来说，Nginx中的第三方模块极大地扩展了Nginx的功能，使其能够处理更复杂和多样化的任务。通过合理地选择和使用这些模块，可以显著提升Nginx的性能和灵活性。\n40\n如何在Nginx中配置图片和视频的自动优化？\n在Nginx中配置图片和视频的自动优化，可以通过多种方法实现。以下是一些关键步骤和建议：\n40.1\n理解Nginx与图片处理的基础\nNginx是一个高性能的Web服务器和反向代理服务器，负责指挥和管理网络请求的流量。当用户请求访问包含图片或视频的网页时，Nginx接收并决定如何快速、高效地将资源传递给用户。\n40.2\n优化服务器硬件和网络环境\n1\n升级服务器硬件：确保服务器具有足够的CPU核心和内存，以应对多个并发的图片请求。\n2\n优化网络带宽：拥有高带宽的网络连接，可以加速图片和视频的传输。\n40.3\nNginx配置优化\n1\n启用HTTP/2协议：HTTP/2相较于HTTP/1.1具有多路复用、头部压缩等特性，可以显著提高图片加载效率。在Nginx配置中添加listen 443 ssl http2;即可启用HTTP/2。\n2\n调整缓冲区大小：适当增大缓冲区大小，可以减少与客户端的交互次数，提高传输效率。例如，设置client_header_buffer_size为1k，large_client_header_buffers为4个8k，proxy_buffer_size为128k，proxy_buffers为4个256k，proxy_busy_buffers_size为256k。\n3\n开启Gzip压缩：虽然Gzip压缩对于图片本身效果有限（因为图片通常已经过压缩），但对于文本类型的元数据（如HTML、CSS、JavaScript）仍然有效。在Nginx配置中添加gzip on;以及相应的gzip_types。\n40.4\n图片缓存策略\n1\n浏览器缓存：通过设置正确的HTTP头信息，让浏览器缓存图片资源。当用户再次访问相同的页面时，如果图片没有更新，浏览器将直接使用本地缓存的图片。例如，设置图片的缓存有效期为30天，并指示浏览器可以缓存。\n2\nNginx本地缓存：Nginx自身也可以设置缓存，将经常访问的图片资源暂存在内存中，提高响应速度。创建缓存空间并设置不同状态码的缓存有效期。\n40.5\n图片压缩与格式转换\n1\n图片压缩：使用专业的图片压缩工具，在不明显影响图片质量的前提下，减小图片的文件大小。\n2\n格式转换：根据图片的特点和使用场景，选择合适的图片格式。例如，对于色彩简单的图片，使用PNG格式可能更节省空间；对于有大量连续色调的图片，JPEG可能是更好的选择。\n40.6\n负载均衡与集群部署\n当流量巨大时，单台Nginx服务器可能不堪重负，这时需要多台服务器协同工作。通过Nginx实现负载均衡，将请求分发到多台后端服务器上。\n40.7\n实际案例分析\n在实际应用中，可以根据具体需求调整上述配置。例如，对于大型网站，可能需要结合CDN（内容分发网络）来加速图片和视频的分发。同时，定期监控服务器的性能和资源使用情况，确保配置调整是有效的。\n综上所述，通过合理配置Nginx服务器、优化硬件和网络环境、采用合适的缓存策略和图片压缩技术，可以显著提升图片和视频在Nginx中的加载速度和用户体验。\n41\n解释Nginx中的切片模块（slice）。\nNginx中的切片模块（slice）是一个用于处理大文件和并发请求的模块。下面详细解释其功能、背景、配置指令以及运行流程：\n1\n基本解读\n引入时间：nginx在2015年的1.9.8版本中引入了ngx_http_slice_module模块。\n编译选项：默认情况下，slice模块没有编译进nginx，需要在编译时使用\u0026ndash;with-http_slice_module参数来启用。\n核心功能：slice模块通过支持Range回源请求，将大响应分解为多个小片段，从而提高服务性能，特别是在处理大文件并发请求时。\n2\n背景介绍\n大文件处理问题：当上游响应的文件特别大时，nginx处理效率较低，特别是多个请求同时并发请求一个大文件时，性能成为瓶颈。\n缓存策略问题：大文件不利于CDN缓存，因为CDN服务器通常需要等文件下载完全后才能缓存，如果用户下载一半或与上游服务器连接中断，会导致文件不能完整被缓存，引起反复下载，降低命中率。\n负载均衡问题：大文件在CDN架构中不容易平衡cache节点的负载，可能导致负载不平衡而影响用户体验。\n3\n配置指令\n基本语法：slice size;，其中size是切片的大小，单位可以是K(千字节)、M(兆字节)、G(吉字节)。\n配置位置：可以在http、server、location块中定义。\n启用条件：要真正启用slice功能，还需要设置以下两条指令：\nproxy_cache_key $uri$is_args$args$slice_range;：表示如果使用nginx的自带缓存功能，那么nginx会以切片为单位进行缓存，需要对同一个文件的不同分片进行区分。\nproxy_set_header Range $slice_range;：表示如果向上游服务器进行请求时，需要增加HTTP Range头，该头的内容就是$slice_range变量的值。\n4\n运行流程\n客户端请求：假定客户端发送一个GET请求，不携带Range头，默认读取所有内容。\n子请求生成：nginx会根据配置的slice大小（例如2M），先发起一个2M的range请求，这个请求返回的Content-Range响应头会给出文件总长度，这样nginx就知道一共需要发几个range请求来取完所有内容。\n范围请求：nginx会构造多个range请求（例如0-2M, 2-4M, 4-6M），每个请求都会返回一定范围的响应。\n数据整合：nginx接收到多个片段后，会重新整合出原始客户需要的Range请求头的内容发送给客户端。\n总的来说，Nginx的slice模块通过将大文件分解为多个小片段来提高处理效率和缓存命中率，解决了大文件在CDN架构中的缓存和负载均衡问题。\n42\n如何在Nginx中配置文件下载限速？\n在Nginx中配置文件下载限速可以通过设置带宽限制来实现。这有助于控制服务器的带宽使用，防止某些用户或应用程序占用过多的带宽资源。以下是详细的步骤和示例：\n42.1\n理解带宽限制的基本概念\n1\n带宽限制：通过限制每个连接的最大传输速率来控制带宽使用。例如，可以设置每个连接的最大传输速率为10KB/s。\n2\n应用场景：适用于需要控制带宽使用的场景，如视频流媒体服务、文件下载服务等。\n3\n实现方式：通过Nginx的limit_rate指令来实现带宽限制。\n42.2\n配置带宽限制的步骤\n1\n打开Nginx配置文件：通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。\n2\n定位到需要限制带宽的server块或location块：根据实际需求，选择在全局、虚拟主机或特定路径下进行配置。\n3\n添加limit_rate指令：在相应的块中添加limit_rate指令，并指定带宽限制值。\n42.3\n具体配置示例\n42.3.1\n全局配置\nnginx\nhttp { \u0026hellip; limit_rate 10k; # 设置全局带宽限制为10KB/s \u0026hellip; }\n42.3.2\n虚拟主机配置\nnginx\nserver { listen 80; server_name example.com; \u0026hellip; location /downloads/ { limit_rate 50k; # 设置/downloads/路径下的带宽限制为50KB/s \u0026hellip; } \u0026hellip; }\n42.3.3\n特定路径配置\nnginx\nserver { listen 80; server_name example.com; \u0026hellip; location /largefile { limit_rate 1m; # 设置/largefile路径下的带宽限制为1MB/s \u0026hellip; } \u0026hellip; }\n42.4\n验证配置\n1\n测试配置文件：在修改完配置文件后，使用以下命令测试配置文件是否正确：\nBash\nsudo nginx -t\n如果输出显示“syntax is ok”和“test is successful”，则表示配置文件无误。\n2\n重新加载Nginx：在确认配置文件无误后，使用以下命令重新加载Nginx：\nBash\nsudo systemctl reload nginx\n或者\nBash\nsudo service nginx reload\n3\n验证效果：通过浏览器或其他工具访问被限制的路径，观察下载速度是否符合预期。\n42.5\n注意事项\n1\n单位：limit_rate指令支持多种单位，包括k（千字节）、m（兆字节）等。\n2\n优先级：如果同时在全局和局部设置了limit_rate，局部设置会覆盖全局设置。\n3\n性能影响：虽然带宽限制可以有效控制带宽使用，但过高的限制可能会影响用户体验，因此需要根据实际情况进行调整。\n综上所述，通过合理配置Nginx的limit_rate指令，可以有效地控制文件下载的带宽使用，确保服务器资源的合理分配。\n在Nginx中配置文件下载限速可以通过设置带宽限制来实现。这有助于控制服务器的带宽使用，防止某些用户或应用程序占用过多的带宽资源。以下是详细的步骤和示例：\n42.6\n一、理解带宽限制的基本概念\n1\n带宽限制：通过限制每个连接的最大传输速率来控制带宽使用。例如，可以设置每个连接的最大传输速率为10KB/s。\n2\n应用场景：适用于需要控制带宽使用的场景，如视频流媒体服务、文件下载服务等。\n3\n实现方式：通过Nginx的limit_rate指令来实现带宽限制。\n42.7\n二、配置带宽限制的步骤\n1\n打开Nginx配置文件：通常位于/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。\n2\n定位到需要限制带宽的server块或location块：根据实际需求，选择在全局、虚拟主机或特定路径下进行配置。\n3\n添加limit_rate指令：在相应的块中添加limit_rate指令，并指定带宽限制值。\n42.8\n三、具体配置示例\n42.8.1\n\\1. 全局配置\nnginx\nhttp { \u0026hellip; limit_rate 10k; # 设置全局带宽限制为10KB/s \u0026hellip; }\n42.8.2\n\\2. 虚拟主机配置\nnginx\nserver { listen 80; server_name example.com; \u0026hellip; location /downloads/ { limit_rate 50k; # 设置/downloads/路径下的带宽限制为50KB/s \u0026hellip; } \u0026hellip; }\n42.8.3\n\\3. 特定路径配置\nnginx\nserver { listen 80; server_name example.com; \u0026hellip; location /largefile { limit_rate 1m; # 设置/largefile路径下的带宽限制为1MB/s \u0026hellip; } \u0026hellip; }\n42.9\n四、验证配置\n1\n测试配置文件：在修改完配置文件后，使用以下命令测试配置文件是否正确：\nBash\nsudo nginx -t\n如果输出显示“syntax is ok”和“test is successful”，则表示配置文件无误。\n2\n重新加载Nginx：在确认配置文件无误后，使用以下命令重新加载Nginx：\nBash\nsudo systemctl reload nginx\n或者\nBash\nsudo service nginx reload\n3\n验证效果：通过浏览器或其他工具访问被限制的路径，观察下载速度是否符合预期。\n42.10\n五、注意事项\n1\n单位：limit_rate指令支持多种单位，包括k（千字节）、m（兆字节）等。\n2\n优先级：如果同时在全局和局部设置了limit_rate，局部设置会覆盖全局设置。\n3\n性能影响：虽然带宽限制可以有效控制带宽使用，但过高的限制可能会影响用户体验，因此需要根据实际情况进行调整。\n综上所述，通过合理配置Nginx的limit_rate指令，可以有效地控制文件下载的带宽使用，确保服务器资源的合理分配。\n43\n如何在Nginx中配置防火墙规则？\n在Nginx中配置防火墙规则，通常涉及到使用Nginx的访问控制模块和第三方模块，如ModSecurity。这些规则可以帮助你限制特定IP地址的访问、防止某些类型的攻击等。以下是如何在Nginx中配置防火墙规则的具体步骤：\n1\n安装Nginx：确保你已经安装了Nginx服务器。如果尚未安装，可以通过以下命令进行安装：\nBash\nsudo apt update sudo apt install nginx\n2\n创建黑名单或白名单配置文件：在Nginx的conf目录（通常是/etc/nginx）下创建一个名为blockip.conf的文件。在这个文件中，你可以定义要屏蔽或允许的IP地址或IP段。例如：\n纯文本\ndeny 195.91.122.67; allow 192.168.0.0/24;\n3\n修改Nginx主配置文件：打开Nginx的主配置文件（通常是/etc/nginx/nginx.conf），并在适当的位置（如http块、server块或location块）添加以下配置以包含blockip.conf文件：\n纯文本\ninclude /etc/nginx/blockip.conf;\n4\n测试并重启Nginx：在修改完配置文件后，使用以下命令测试Nginx配置文件是否正确：\nBash\nsudo nginx -t\n如果测试通过，则重启Nginx以使配置生效：\nBash\nsudo systemctl restart nginx\n5\n高级配置：除了基本的黑白名单功能外，你还可以使用Nginx的其他模块和第三方模块来实现更复杂的防火墙规则。例如，使用ngx_http_limit_req模块来限制每个IP的请求频率，或者使用ModSecurity来增强Web应用的安全性。\n总的来说，通过上述步骤，你可以在Nginx中配置基本的防火墙规则来保护你的网站免受恶意攻击。然而，对于更复杂的安全需求，建议结合使用其他安全工具和最佳实践来构建一个多层次的安全防护体系。\n44\n解释Nginx中的stream模块。\nNginx中的stream模块用于处理四层协议（如TCP和UDP）的流量转发、代理以及负载均衡。以下是对stream模块的详细解释：\n1\n基本功能\n流量转发与代理：stream模块能够代理和转发TCP或UDP流量，使得只有特定IP地址能访问的服务可以通过Nginx进行中转，从而允许其他IP地址的客户端访问这些服务。\n负载均衡：对于多个TCP或UDP端口服务，stream模块支持多种负载均衡算法（如轮询、最小连接数、ip_hash等），以实现数据流的负载均衡，提高系统的可用性和性能。\n2\n工作原理\n监听与接收请求：stream模块通过监听指定的TCP或UDP端口来接收客户端的请求。\n选择上游服务器并建立连接：当请求到来时，stream模块会根据配置选择一个合适的上游服务器，并与其建立socket连接。\n数据转发：stream模块将客户端的数据转发给选定的上游服务器，并将上游服务器的响应数据转发回客户端，从而实现了数据的代理转发。\n3\n配置示例\n以下是一个使用Nginx stream模块实现TCP流量代理转发和负载均衡的简单配置示例：\nnginx\nstream { upstream backend { server 192.168.1.100:3306; # 上游服务器1 server 192.168.1.101:3306; # 上游服务器2 } server { listen 3306; # 监听本地3306端口 proxy_pass backend; # 将请求转发给upstream定义的上游服务器组 } }\n在这个配置中，Nginx的stream模块监听了本地的3306端口，并将接收到的TCP请求转发给名为backend的上游服务器组。上游服务器组包含两个MySQL服务器（192.168.1.100:3306和192.168.1.101:3306），Nginx会根据负载均衡算法（默认是轮询）选择一个服务器来处理请求。\n总的来说，Nginx的stream模块是一个功能强大的工具，适用于需要处理四层协议流量的场景。通过合理配置和使用stream模块，可以实现高效的流量转发、代理和负载均衡功能。\n45\n如何在Nginx中配置邮件代理（mail proxy）？\n在Nginx中配置邮件代理（mail proxy）可以通过使用第三方模块如nginx-mail-module来实现。以下是详细的步骤和示例：\n45.1\n安装必要的软件包\n1\n安装Nginx：确保你已经安装了Nginx服务器。如果尚未安装，可以通过以下命令进行安装：\nBash\nsudo apt update sudo apt install nginx\n2\n安装第三方邮件代理模块：目前，Nginx官方并不直接支持邮件代理功能，但有一些第三方模块可以实现这一功能。例如，可以使用nginx-mail-module。\n45.2\n配置邮件代理\n1\n下载并编译nginx-mail-module：首先，你需要下载并编译nginx-mail-module。可以从GitHub上获取源码并进行编译安装。\nBash\ngit clone https://github.com/vozlt/nginx-module-mail.git cd nginx-module-mail ./configure \u0026ndash;add-module=/path/to/nginx-module-mail make sudo make install\n2\n修改Nginx配置文件：打开Nginx的主配置文件（通常是/etc/nginx/nginx.conf），并在适当的位置添加邮件代理的配置。以下是一个基本的邮件代理配置示例：\n纯文本\nmail { server_name mail.example.com; auth_http localhost:9000/auth; proxy_pass_error_message on; smtp_capabilities \u0026ldquo;PIPELINING\u0026rdquo; \u0026ldquo;8BITMIME\u0026rdquo;; smtp_auth login plain cram-md5; server { listen 143 ssl; protocol imap; imap_capabilities IMAP4rev1; imap_client_buffer 16K; imap_login_attempts 5; imap_timeout 300s; imap_auth = login plain; imap_user = user@domain.com; imap_pass = password; } server { listen 587 ssl; protocol smtp; smtp_auth login plain cram-md5; smtp_capabilities \u0026ldquo;PIPELINING\u0026rdquo; \u0026ldquo;8BITMIME\u0026rdquo;; smtp_timeout 300s; smtp_user = user@domain.com; smtp_pass = password; } }\n3\n测试并重启Nginx：在修改完配置文件后，使用以下命令测试Nginx配置文件是否正确：\nBash\nsudo nginx -t\n如果测试通过，则重启Nginx以使配置生效：\nBash\nsudo systemctl restart nginx\n45.3\n验证配置\n1\n发送和接收邮件：配置完成后，你可以尝试使用邮件客户端（如Outlook、Thunderbird等）连接到你的Nginx邮件代理服务器，并发送和接收邮件以验证配置是否成功。\n2\n检查日志：如果遇到问题，可以查看Nginx的错误日志（通常位于/var/log/nginx/error.log）以获取更多调试信息。\n总的来说，通过上述步骤，你可以在Nginx中配置邮件代理功能。需要注意的是，邮件代理的配置可能会因具体需求而有所不同，因此建议根据实际情况进行调整和优化。\n46\n如何在Nginx中配置缓存控制头（Cache-Control）？\n在Nginx中配置缓存控制头（Cache-Control）可以通过使用add_header指令来实现。以下是详细的步骤和示例：\n46.1\n基本配置\n1\n打开Nginx配置文件：通常，Nginx的主配置文件位于/etc/nginx/nginx.conf。你可以使用文本编辑器打开这个文件，例如：\nBash\nsudo nano /etc/nginx/nginx.conf\n2\n添加缓存控制头：在适当的位置（如http块、server块或location块）添加add_header指令来设置Cache-Control头。以下是一个基本的示例：\n纯文本\nhttp { \u0026hellip; server { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; # 添加Cache-Control头 add_header Cache-Control \u0026ldquo;public, max-age=3600\u0026rdquo;; } } }\n46.2\n高级配置\n1\n根据条件设置Cache-Control头：你可以根据请求的URL或其他条件来动态设置Cache-Control头。例如，对于静态资源可以设置较长的缓存时间，而对于动态内容则设置较短的缓存时间。\n纯文本\nserver { listen 80; server_name example.com; location /static/ { root /var/www/html; add_header Cache-Control \u0026ldquo;public, max-age=31536000\u0026rdquo;; # 静态资源缓存一年 } location /dynamic/ { proxy_pass http://backend; add_header Cache-Control \u0026ldquo;no-cache, no-store, must-revalidate\u0026rdquo;; # 动态内容不缓存 } }\n2\n使用变量设置Cache-Control头：你还可以使用Nginx内置的变量来动态设置Cache-Control头。例如，根据请求的文件类型设置不同的缓存策略：\n纯文本\nserver { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; # 根据文件扩展名设置Cache-Control头 if ($request_uri ~* .(jpg|jpeg|png|gif|ico|css|js)$) { add_header Cache-Control \u0026ldquo;public, max-age=31536000\u0026rdquo;; # 图片和静态资源缓存一年 } if ($request_uri ~* .(html|htm)$) { add_header Cache-Control \u0026ldquo;no-cache, no-store, must-revalidate\u0026rdquo;; # HTML页面不缓存 } } }\n46.3\n测试和验证\n1\n重启Nginx：在修改完配置文件后，使用以下命令测试Nginx配置文件是否正确，并重启Nginx以使配置生效：\nBash\nsudo nginx -t sudo systemctl restart nginx\n2\n检查响应头：使用浏览器开发者工具或curl命令检查HTTP响应头，确认Cache-Control头是否按预期设置。例如，使用curl命令：\nBash\ncurl -I http://example.com/static/image.jpg\n你应该能看到类似以下的输出：\n纯文本\nHTTP/1.1 200 OK Server: nginx/1.18.0 (Ubuntu) Date: Wed, 14 Oct 2021 12:00:00 GMT Content-Type: image/jpeg Content-Length: 12345 Connection: keep-alive Cache-Control: public, max-age=31536000\n总的来说，通过上述步骤，你可以在Nginx中配置缓存控制头（Cache-Control）。这些配置可以帮助你更好地控制客户端缓存行为，提高网站性能和用户体验。\n47\n解释Nginx中的变量系统。\nNginx中的变量系统是其配置灵活性和功能性的重要组成部分。以下是对Nginx变量系统的详细解释：\n47.1\n变量定义与表示\n变量前缀：Nginx使用“”符号作为变量的前缀，如‘﻿variable_name`。\n变量名：变量名由字母、数字、下划线组成，且必须以字母或下划线开头，不能包含特殊字符（如空格、连字符等）。\n变量值：变量的值可以是字符串类型，并且可以通过配置文件进行动态设置和获取。\n47.2\n变量种类\n内置变量：这些变量在Nginx启动时就已经被预设好了，不需要用户在配置文件中显式声明。它们通常代表客户端请求或响应的某些部分，如请求头、响应头、客户端地址等。例如，$http_user_agent代表HTTP请求头中的User-Agent字段，$remote_addr代表客户端的IP地址。\n自定义变量：用户可以在配置文件中使用set指令来声明和初始化自定义变量。这些变量可以在后续的配置指令中引用。例如，set $my_var \u0026ldquo;some_value\u0026rdquo;;定义了一个名为$my_var的自定义变量，并将其值设置为\u0026quot;some_value\u0026quot;。\n47.3\n变量作用域\nNginx变量的作用域可以是全局的，也可以是局部的。全局变量在整个配置文件中都可以访问，而局部变量只在声明它的上下文块（如server、location等）中可见。\n47.4\n变量解析与插值\n当Nginx处理请求时，它会解析并替换配置文件中的变量为实际的值。这种替换过程称为变量插值或变量解析。\n变量插值可以发生在多个地方，包括日志记录、重定向、代理传递等场景。\n47.5\n变量缓存\n为了提高性能，Nginx会对某些变量进行缓存。这意味着一旦变量被解析过一次，其结果就会被存储起来，以便后续请求快速访问。然而，这也可能导致在某些情况下变量值无法实时更新的问题。\n47.6\n变量使用示例\n重定向：使用变量可以实现基于URL参数或其他条件的动态重定向。\n负载均衡：通过变量可以动态选择不同的上游服务器。\n条件判断：结合if指令和变量，可以实现复杂的条件逻辑。\n日志记录：使用变量可以定制日志格式，记录更多有用的信息。\n综上所述，Nginx的变量系统为其提供了强大的配置灵活性和功能性。通过合理使用内置变量和自定义变量，用户可以构建出满足各种需求的Web服务器配置。然而，在使用变量时也需要注意其作用域、解析时机以及可能的缓存问题。\n48\n如何在Nginx中配置多视图（multi-view）支持？\n在Nginx中配置多视图（即多页面）支持，主要是通过配置多个location块来实现的。以下是详细的步骤和示例：\n1\n安装Nginx：确保已安装Nginx。如果尚未安装，可以使用以下命令进行安装（以Ubuntu为例）：\nBash\nsudo apt update sudo apt install nginx\n2\n配置Nginx：打开Nginx的主配置文件（通常位于/etc/nginx/nginx.conf），并在其中添加或修改相应的配置。\n3\n定义服务器块：在nginx.conf文件中，使用server块来定义一个虚拟服务器。在这个块内，可以定义多个location块来处理不同的URL路径。\n4\n配置多视图：对于多页面应用，每个页面（或视图）都可以对应一个location块。例如，假设有一个项目包含两个页面：index.html和project.html，它们分别位于/root/libs/landing-page/html目录下。可以按照以下方式配置：\nnginx\nserver { listen 80; server_name your_domain.com; location / { root /root/libs/landing-page; index index.html project.html; # 设置默认文档 } location /project { root /root/libs/landing-page; index project.html; # 当访问/project时，返回project.html } }\n在这个配置中，当用户访问http://your_domain.com/时，将返回index.html；当用户访问http://your_domain.com/project时，将返回project.html。\n5\n测试并重启Nginx：保存配置文件后，使用以下命令测试Nginx配置是否正确：\nBash\nsudo nginx -t\n如果配置正确，将显示“syntax is ok”和“test is successful”。然后，重启Nginx以使配置生效：\nBash\nsudo systemctl restart nginx\n6\n访问多视图：现在，您应该能够通过浏览器访问配置的多视图了。例如，访问http://your_domain.com/将显示index.html的内容，而访问http://your_domain.com/project将显示project.html的内容。\n需要注意的是，以上配置是一个基本的示例。在实际项目中，可能需要根据具体需求进行调整。例如，您可能需要为每个视图配置不同的访问权限、缓存策略等。此外，如果您使用的是反向代理或负载均衡等高级功能，还需要进行相应的配置。\n最后，建议在生产环境中使用前充分测试Nginx配置，以确保其稳定性和安全性。\n49\n解释Nginx中的X-Accelerator模块。\nNginx中的X-Accelerator模块是一个功能模块，它允许由后台（如Apache、Tomcat、FastCGI等）通过返回的头来决定投递静态文件。这一机制在处理需要登录认证、权限核查、积分扣除或增加等细粒度控制的场景时非常有用。以下是对X-Accelerator模块的详细解释：\n49.1\n工作原理\n1\n客户端请求：用户通过浏览器向Nginx发送一个请求，这个请求可能是下载某个资源。\n2\nNginx转发请求：Nginx作为反向代理服务器，将这个请求转发给后台服务器（如Apache、Tomcat等）。\n3\n后台服务器处理：后台服务器接收到请求后，进行必要的验证和处理（如登录认证、权限核查等）。如果条件满足，后台服务器会设置一个特殊的HTTP头（如X-Accel-Redirect），并将这个头返回给Nginx。\n4\nNginx接管下载任务：Nginx收到带有X-Accel-Redirect头的响应后，会根据该头中指定的URI进行location匹配，然后是请求文件的匹配。最终，Nginx会从匹配到的位置提供文件下载服务给终端用户。\n49.2\n配置示例\n假设有一个文件下载的场景，其中/dd/filename是客户端请求的路径，而实际的文件位于/var/www/files目录下。可以在Nginx配置文件中添加以下内容来实现X-Accelerator模块的功能：\nnginx\n# 定义受保护的文件位置 location /protected_files { internal; alias /var/www/files; } # 客户端请求的路径 location /dd/ { proxy_pass http://backend_server; # 这里的backend_server是后台服务器的地址 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }\n在后台服务器（如PHP程序）中，可以这样设置X-Accel-Redirect头来指定下载的文件：\nPHP\nheader(\u0026ldquo;X-Accel-Redirect: /protected_files/\u0026rdquo;.$path);\n49.3\n功能特点\n减轻后端服务器压力：由于Nginx在打开静态文件时使用了sendfile(2)，其IO效率非常高，因此将静态资源的下载任务交给Nginx可以大大减轻后端服务器的压力。\n灵活性高：X-Accelerator模块允许在后端服务器上进行各种验证和处理，然后由Nginx负责提供高效的文件下载服务，这种分工合作的方式提高了系统的整体性能和可扩展性。\n49.4\n注意事项\nNginx服务器只认识从后端服务器发来的X-Accel-Redirect头，而从客户端发来的这种头，Nginx并不会理睬。\n使用X-Accelerator模块时，必须确保Nginx作为后端服务的代理，并且访问的是Nginx的代理地址，直接访问后端服务Nginx会报404。\n综上所述，Nginx中的X-Accelerator模块是一个强大的工具，它在处理需要细粒度控制的静态文件下载场景时非常有用。通过合理配置和使用这一模块，可以提高系统的性能和可扩展性。\n50\n如何在Nginx中配置安全头部（Security Headers）？\n在Nginx中配置安全头部（Security Headers）是增强Web应用安全性的重要步骤。这些头部可以帮助防止各种类型的攻击，如跨站脚本攻击（XSS）、点击劫持、内容类型嗅探等。以下是详细的步骤和示例：\n50.1\n安装Nginx\n确保已安装Nginx。如果尚未安装，可以使用以下命令进行安装（以Ubuntu为例）：\nBash\nsudo apt update sudo apt install nginx\n50.2\n配置Nginx\n打开Nginx的主配置文件（通常位于/etc/nginx/nginx.conf），并在其中添加或修改相应的配置。\n50.3\n添加安全头部\n在http块或特定的server块中添加安全头部配置。以下是一些常见的安全头部及其配置示例：\n50.3.1\n基本安全头部\nnginx\nhttp { # 其他配置\u0026hellip; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options DENY; add_header X-XSS-Protection \u0026ldquo;1; mode=block\u0026rdquo;; add_header Referrer-Policy no-referrer-when-downgrade; add_header Content-Security-Policy \u0026ldquo;default-src \u0026lsquo;self\u0026rsquo;; script-src \u0026lsquo;self\u0026rsquo; \u0026lsquo;unsafe-inline\u0026rsquo; \u0026lsquo;unsafe-eval\u0026rsquo;; style-src \u0026lsquo;self\u0026rsquo; \u0026lsquo;unsafe-inline\u0026rsquo;;\u0026rdquo;; }\n50.3.2\nHSTS（HTTP Strict Transport Security）\nHSTS可以强制客户端使用HTTPS连接，从而防止中间人攻击。\nnginx\nhttp { # 其他配置\u0026hellip; add_header Strict-Transport-Security \u0026ldquo;max-age=31536000; includeSubDomains\u0026rdquo; always; }\n50.3.3\nFeature-Policy（功能策略）\nFeature-Policy头用于控制浏览器中某些功能的启用情况。\nnginx\nhttp { # 其他配置\u0026hellip; add_header Feature-Policy \u0026ldquo;geolocation \u0026rsquo;none\u0026rsquo;; midi \u0026rsquo;none\u0026rsquo;; notifications \u0026rsquo;none\u0026rsquo;; push \u0026rsquo;none\u0026rsquo;; sync-xhr \u0026rsquo;none\u0026rsquo;; microphone \u0026rsquo;none\u0026rsquo;; camera \u0026rsquo;none\u0026rsquo;; magnetometer \u0026rsquo;none\u0026rsquo;; gyroscope \u0026rsquo;none\u0026rsquo;; speaker \u0026rsquo;none\u0026rsquo;; vibrate \u0026rsquo;none\u0026rsquo;; fullscreen \u0026rsquo;none\u0026rsquo;; payment \u0026rsquo;none\u0026rsquo;\u0026rdquo;; }\n50.4\n测试并重启Nginx\n保存配置文件后，使用以下命令测试Nginx配置是否正确：\nBash\nsudo nginx -t\n如果配置正确，将显示“syntax is ok”和“test is successful”。然后，重启Nginx以使配置生效：\nBash\nsudo systemctl restart nginx\n50.5\n验证安全头部\n可以使用浏览器的开发者工具或在线工具（如SecurityHeaders.io）来检查响应头是否包含预期的安全头部。\n50.6\n注意事项\n逐步实施：在生产环境中逐步实施这些安全头部，以确保不会对现有功能造成影响。\n定期更新：随着新的安全威胁的出现，应定期审查和更新安全头部配置。\n结合其他安全措施：仅靠安全头部是不够的，还应结合其他安全措施，如输入验证、输出编码、使用HTTPS等。\n通过以上步骤，您可以在Nginx中配置安全头部，从而提高Web应用的安全性。\n在Nginx中配置缓存控制头（Cache-Control）可以通过使用add_header指令来实现。以下是详细的步骤和示例：\n50.7\n一、基本配置\n1\n打开Nginx配置文件：通常，Nginx的主配置文件位于/etc/nginx/nginx.conf。你可以使用文本编辑器打开这个文件，例如：\nBash\nsudo nano /etc/nginx/nginx.conf\n2\n添加缓存控制头：在适当的位置（如http块、server块或location块）添加add_header指令来设置Cache-Control头。以下是一个基本的示例：\n纯文本\nhttp { \u0026hellip; server { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; # 添加Cache-Control头 add_header Cache-Control \u0026ldquo;public, max-age=3600\u0026rdquo;; } } }\n50.8\n二、高级配置\n1\n根据条件设置Cache-Control头：你可以根据请求的URL或其他条件来动态设置Cache-Control头。例如，对于静态资源可以设置较长的缓存时间，而对于动态内容则设置较短的缓存时间。\n纯文本\nserver { listen 80; server_name example.com; location /static/ { root /var/www/html; add_header Cache-Control \u0026ldquo;public, max-age=31536000\u0026rdquo;; # 静态资源缓存一年 } location /dynamic/ { proxy_pass http://backend; add_header Cache-Control \u0026ldquo;no-cache, no-store, must-revalidate\u0026rdquo;; # 动态内容不缓存 } }\n2\n使用变量设置Cache-Control头：你还可以使用Nginx内置的变量来动态设置Cache-Control头。例如，根据请求的文件类型设置不同的缓存策略：\n纯文本\nserver { listen 80; server_name example.com; location / { root /var/www/html; index index.html index.htm; # 根据文件扩展名设置Cache-Control头 if ($request_uri ~* .(jpg|jpeg|png|gif|ico|css|js)$) { add_header Cache-Control \u0026ldquo;public, max-age=31536000\u0026rdquo;; # 图片和静态资源缓存一年 } if ($request_uri ~* .(html|htm)$) { add_header Cache-Control \u0026ldquo;no-cache, no-store, must-revalidate\u0026rdquo;; # HTML页面不缓存 } } }\n50.9\n三、测试和验证\n1\n重启Nginx：在修改完配置文件后，使用以下命令测试Nginx配置文件是否正确，并重启Nginx以使配置生效：\nBash\nsudo nginx -t sudo systemctl restart nginx\n2\n检查响应头：使用浏览器开发者工具或curl命令检查HTTP响应头，确认Cache-Control头是否按预期设置。例如，使用curl命令：\nBash\ncurl -I http://example.com/static/image.jpg\n你应该能看到类似以下的输出：\n纯文本\nHTTP/1.1 200 OK Server: nginx/1.18.0 (Ubuntu) Date: Wed, 14 Oct 2021 12:00:00 GMT Content-Type: image/jpeg Content-Length: 12345 Connection: keep-alive Cache-Control: public, max-age=31536000\n总的来说，通过上述步骤，你可以在Nginx中配置缓存控制头（Cache-Control）。这些配置可以帮助你更好地控制客户端缓存行为，提高网站性能和用户体验。\n标题目录\n1 什么是Nginx？\n2 Nginx的主要功能有哪些？\n3 Nginx与Apache相比有哪些优势？\n4 如何在Nginx中配置一个虚拟主机？\n5 解释Nginx中的upstream模块及其用途。\n6 如何在Nginx中实现负载均衡？\n7 在Nginx中如何配置SSL/TLS？\n8 什么是Nginx的反向代理？\n9 如何在Nginx中设置访问控制（例如：IP白名单和黑名单）？\n10 如何在Nginx中进行静态资源压缩和缓存？\n11 解释Nginx中的事件驱动模型。\n12 如何在Nginx中配置Gzip压缩？\n13 Nginx如何处理高并发请求？\n14 解释Nginx配置文件的结构。\n15 如何在Nginx中重写URL？\n16 如何在Nginx中配置错误页面？\n17 解释Nginx中的worker进程和master进程。\n18 如何在Nginx中配置健康检查？\n19 如何在Nginx中限制客户端请求速率？\n20 如何在Nginx中处理慢请求？\n21 解释Nginx中的epoll机制。\n22 如何在Nginx中实现动静分离？\n23 解释Nginx中的access log和error log。\n24 如何在Nginx中配置HTTP基本认证？\n25 如何在Nginx中配置JWT认证？\n26 解释Nginx中的location指令及其用法。\n27 如何在Nginx中配置自定义错误页面？\n28 如何在Nginx中配置HTTP到HTTPS的重定向？\n29 如何在Nginx中配置基于域名的路由？\n30 解释Nginx中的limit_req和limit_conn模块。\n31 如何在Nginx中配置跨域资源共享（CORS）？\n32 如何在Nginx中配置WebSocket支持？\n33 解释Nginx中的sub_filter模块。\n34 如何在Nginx中配置FastCGI？\n35 如何在Nginx中配置PHP-FPM？\n36 如何在Nginx中配置uWSGI？\n37 解释Nginx中的http2模块。\n38 如何在Nginx中配置服务器端包含（SSI）？\n39 解释Nginx中的第三方模块。\n40 如何在Nginx中配置图片和视频的自动优化？\n41 解释Nginx中的切片模块（slice）。\n42 如何在Nginx中配置文件下载限速？\n43 如何在Nginx中配置防火墙规则？\n44 解释Nginx中的stream模块。\n45 如何在Nginx中配置邮件代理（mail proxy）？\n46 如何在Nginx中配置缓存控制头（Cache-Control）？\n47 解释Nginx中的变量系统。\n48 如何在Nginx中配置多视图（multi-view）支持？\n49 解释Nginx中的X-Accelerator模块。\n50 如何在Nginx中配置安全头部（Security Headers）？\n本页内容由用户通过 wolai 发布，并不代表 wolai 立场，如有违规侵权，请\n投诉/举报 或提交 侵权通知\n","date":"2024-12-30T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/nginx/","title":"Nginx"},{"content":"JVM快速入门\r从面试开始：\n1.JVM是什么? JVM的内存区域分为哪些?\n2.什么是OOM? 什么是StackoverflowError? 有哪些方法分析?\n3.JVM 的常用参数调优你知道哪些?\n4.GC是什么? 为什么需要GC?\n5.什么是类加载器?\n什么是JVM\rJVM：Java Virtual Machine，Java虚拟机\n**位置：**JVM是运行在操作 系统之上的，它与硬件没有直接的交互。\n为什么要在程序和操作系统中间添加一个JVM？\nJava 是一门抽象程度特别高的语言，提供了自动内存管理等一系列的特性。这些特性直接在操作系统上实现是不太可能的，所以就需要 JVM 进行一番转换。有了 JVM 这个抽象层之后，Java 就可以实现跨平台了。JVM 只需要保证能够正确执行 .class 文件，就可以运行在诸如 Linux、Windows、MacOS 等平台上了。而 Java 跨平台的意义在于一次编译，处处运行，能够做到这一点 JVM 功不可没。\n主流虚拟机有哪些？\rJCP组织（Java Community Process 开放的国际组织 ）：Hotspot虚拟机（Open JDK版），sun2006年开源 Oracle：Hotspot虚拟机（Oracle JDK版），闭源，允许个人使用，商用收费 BEA：JRockit虚拟机 IBM：J9虚拟机 阿里巴巴：Dragonwell JDK（龙井虚拟机），电商物流金融等领域，高性能要求。 结构图\rJVM的作用：加载并执行Java字节码文件(.class) - 加载字节码文件、分配内存（运行时数据区）、运行程序\nJVM的特点：一次编译到处运行、自动内存管理、自动垃圾回收\n类加载器子系统：将字节码文件（.class）加载到内存中的方法区\n运行时数据区：\n方法区：存储已被虚拟机加载的类的元数据信息(元空间)。也就是存储字节码信息。 堆：存放对象实例，几乎所有的对象实例都在这里分配内存。 虚拟机栈(java栈)：虚拟机栈描述的是Java方法执行的内存模型**。每个方法被执行的时候都会创建一个**栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息 本地方法栈：本地方法栈则是记录虚拟机当前使用到的native方法。 程序计数器：当前线程所执行的字节码的行号指示器。 本地方法接口：虚拟机使用到的native类型的方法，负责调用操作系统类库。（例如Thread类中有很多Native方法的调用）\n执行引擎：包含解释器、即时编译器和垃圾收集器 ，负责执行加载到JVM中的字节码指令。\n注意：\n多线程共享方法区和堆； Java栈、本地方法栈、程序计数器是每个线程私有的。 执行引擎Execution Engine\rExecution Engine执行引擎负责解释命令(将字节码指令解释编译为机器码指令)，提交操作系统执行。\nJVM执行引擎通常由两个主要组成部分构成：解释器和即时编译器（Just-In-Time Compiler，JIT Compiler）。\n解释器：当Java字节码被加载到内存中时，解释器逐条解析和执行字节码指令。解释器逐条执行字节码，将每条指令转换为对应平台上的本地机器指令。由于解释器逐条解析执行，因此执行速度相对较慢。但解释器具有优点，即可立即执行字节码，无需等待编译过程。 即时编译器（JIT Compiler）：为了提高执行速度，JVM还使用即时编译器。即时编译器将字节码动态地编译为本地机器码，以便直接在底层硬件上执行。即时编译器根据运行时的性能数据和优化技术，对经常执行的热点代码进行优化，从而提高程序的性能。即时编译器可以将经过优化的代码缓存起来，以便下次再次执行时直接使用。 JVM执行引擎还包括其他一些重要的组件，如即时编译器后端、垃圾回收器、线程管理器等。这些组件共同协作，使得Java程序能够在不同的操作系统和硬件平台上运行，并且具备良好的性能。\n本地方法接口Native Interface\r本地接口的作用是融合不同的编程语言为 Java 所用，于是就在内存中专门开辟了一块区域处理标记为native的代码，它的具体做法是 Native Method Stack中登记 native方法，在Execution Engine 执行时加载native libraies。\n例如Thread类中有一些标记为native的方法：\nNative Method Stack\r本地方法栈存储了从Java代码中调用本地方法时所需的信息。是线程私有的。\nPC寄存器(程序计数器)\r每个线程都有一个程序计数器，是线程私有的，就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址，即 将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。\n类加载器ClassLoader\r负责加载class文件，class文件在文件开头有特定的文件标识(cafe babe)。 ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。 加载的类信息存放到方法区的内存空间。 类的加载过程\r类加载过程主要分为三个步骤：加载、链接、初始化，而其中链接过程又分为三个步骤：验证、准备、解析，加上使用、卸载两个步骤统称为为类的生命周期。\n阶段一：加载\n通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流代表的静态存储结构转为方法区运行时数据结构 在内存中生成一个代码这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 结论：类加载为懒加载\n阶段二：链接\n验证：验证阶段主要是为了为了确保Class文件的字节流中包含的信息符合虚拟机要求，并且不会危害虚拟机 准备： 为类的静态变量分配内存并且设置该类变量的默认初始值，即赋初值【赋的默认值】 实例变量是在创建对象的时候完成赋值，且实例变量随着对象一起分配到Java堆中 final修饰的常量在编译的时候会分配，准备阶段直接完成赋值，即没有赋初值这一步。被所有线程所有对象共享 解析：将符号引用替换为直接引用 符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可 直接引用：可以直接指向目标的指针，而直接引用必须引用的目标已经在内存中存在 阶段三：初始化\n​\t初始化阶段是执行类构造器 的过程。这一步主要的目的是：根据程序员程序编码制定的主观计划去初始化类变量和其他资源。\n类加载器的作用\r负责加载class文件，class文件在文件开头有的文件标识**（CA FE BA BE）**，并且ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。\n类加载器分类\r分为四种，前三种为虚拟机自带的加载器。\n启动类加载器（BootstrapClassLoader）：由C++实现。\n扩展类加载器（ExtClassLoader/PlatformClassLoader）：由Java实现，派生自ClassLoader类。\n应用程序类加载器（AppClassLoader）：也叫系统类加载器。由Java实现，派生自ClassLoader类。\n自定义加载器 ：程序员可以定制类的加载方式，派生自ClassLoader类。\nJava 9之前的ClassLoader\nBootstrap ClassLoader加载$JAVA_HOME中【jre/lib/rt.jar】，加载JDK中的核心类库 ExtClassLoader加载相对次要、但又通用的类，主要包括$JAVA_HOME中【jre/lib/ext/*.jar】或-Djava.ext.dirs指定目录下的jar包 AppClassLoader加载-cp指定的类，加载用户类路径中指定的jar包及目录中class Java 9及之后的ClassLoader\nBootstrap ClassLoader，使用了模块化设计，加载【lib/modules】启动时的基础模块类，java.base、java.management、java.xml ExtClassLoader更名为PlatformClassLoader，使用了模块化设计，加载【lib/modules】中平台相关模块，如java.scripting、java.compiler。 AppClassLoader加载-cp，-mp指定的类，加载用户类路径中指定的jar包及目录中class 双亲委派模型\r如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上：\n1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器PlatformClassLoader去完成。 2、当PlatformClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器BootStrapClassLoader去完成。 3、如果BootStrapClassLoader加载失败，会用PlatformClassLoader来尝试加载； 4、若PlatformClassLoader也加载失败，则会使用AppClassLoader来加载 5、如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException 其实这就是所谓的双亲委派模型。简单来说：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上。\n目的：\n一，性能，避免重复加载；\n二，安全性，避免核心类被修改。\n方法区Method Area\r方法区存储什么\r方法区是被所有线程共享。《深入理解Java虚拟机》书中对方法区存储内容的经典描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等：\n方法区演进细节\rHotspot中方法区的变化：\n方法区(永久代（JDK7及以前）、元空间（JDK8以后）)\n方法区是 JVM 规范中定义的一块内存区域，用来存储类元数据、方法字节码、即时编译器需要的信息等 永久代是 Hotspot 虚拟机对 JVM 规范的实现（1.8 之前） 元空间是 Hotspot 虚拟机对 JVM 规范的另一种实现（1.8 以后），使用本地内存作为这些信息的存储空间 虚拟机栈stack\rStack 栈是什么？\r栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，每个线程都有自己的栈，它的生命周期是跟随线程的生命周期，线程结束栈内存也就释放，是线程私有的。 线程上正在执行的每个方法都各自对应一个栈帧（Stack Frame）。 栈运行原理\rJVM对Java栈的操作只有两个，就是对栈帧的压栈和出栈，遵循“先进后出”或者“后进先出”原则。 一个线程中只能有一个正在执行的方法（当前方法），因此对应只会有一个活动的当前栈帧。 当一个方法1（main方法）被调用时就产生了一个栈帧1 并被压入到栈中，栈帧1位于栈底位置\n方法1又调用了方法2，于是产生栈帧2 也被压入栈，\n方法2又调用了方法3，于是产生栈帧3 也被压入栈，\n……\n执行完毕后，先弹出栈帧4，再弹出栈帧3，再弹出栈帧2，再弹出栈帧1，线程结束，栈释放。\n栈存储什么?\r局部变量表（Local Variables）\r也叫本地变量表。\n作用：存储方法参数和方法体内的局部变量：8种基本类型变量、对象引用（reference）。\n可以用如下方式查看字节码中一个方法内定义的的局部变量，当程序运行时，这些局部变量会被加载到局部变量表中。\n查看局部变量：\n可以使用javap - .class* 命令，或者idea中的jclasslib插件。\n注意：以下方式看到的是加载到方法区中的字节码中的局部变量表，当程序运行时，局部变量表会被动态的加载到栈帧中的局部变量表中\n操作数栈（Operand Stack）\r**作用：**也是一个栈，在方法执行过程中根据字节码指令记录当前操作的数据，将它们入栈或出栈。用于保存计算过程的中间结果，同时作为计算过程中变量的临时存储空间。\n动态链接（Dynamic Linking）\r**作用：**可以知道当前帧执行的是哪个方法。**指向运行时常量池中方法的符号引用。**程序真正执行时，类加载到内存中后，符号引用会换成直接引用。\n1 2 3 4 5 6 7 8 9 10 public class DynamicLinkingDemo { public void methodA(){ methodB(); //方法A引用方法B } public void methodB(){ } } 方法返回地址（Return Address）\r**作用：**可以知道调用完当前方法后，上一层方法接着做什么，即“return”到什么位置去。存储当前方法调用完毕\n完整的内存结构图如下\r栈溢出\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 未设置栈大小默认：11416次 * 设置VM参数：-Xss256k 2475次 */ public class StackOOMDemo { public static int count = 1; public static void main(String[] args) { System.out.println(count); count++; main(args); } } 常见问题栈溢出：Exception in thread \u0026ldquo;main\u0026rdquo; java.lang.StackOverflowError通常出现在递归调用时。\n问题辨析：\n垃圾回收是否涉及栈内存？\n不涉及，因为栈内存在方法调用结束后都会自动弹出栈。\n方法内的局部变量是线程安全的吗？\n当方法内局部变量没有逃离方法的作用范围时线程安全，因为一个线程对应一个栈，每调用一个方法就会新产生一个栈桢，都是线程私有的局部变量，当变量是static时则不安全，因为是线程共享的。\n设置栈的大小\r// 使用配置，设置栈为1MB，下面可以3选一 -Xss1m\n-Xss1024k -Xss1048576 完整的写法是： -XX:ThreadStackSize=1m\n堆heap\r堆体系概述\r堆、栈、方法区的关系\rHotSpot是使用指针的方式来访问对象：\nJava堆中会存放指向类元数据的地址\nJava栈中的reference存储的是指向堆中的对象的地址\n堆空间概述\r一个Java程序运行起来对应一个进程，一个进程对应一个JVM实例，一个JVM实例中有一个运行时数据区。 堆是Java内存管理的核心区域，在JVM启动的时候被创建，堆内存的大小是可以调节的。 分代空间\r堆空间划分\r堆内存逻辑上分为三部分：\nYoung Generation Space 新生代/年轻代 Young/New Tenured generation space 养老代/老年代 Old/Tenured Permanent Space/Meta Space 永久代/元空间 Permanent/Meta 新生代又划分为：\n新生代又分为两部分： 伊甸园区（Eden space）和幸存者区（Survivor pace） 。\n幸存者区有两个： 0区（Survivor 0 space）和1区（Survivor 1 space）。\nJDK1.7及之前堆空间\rJDK1.8及之后堆空间\r**注意：**方法区（具体的实现是永久代和元空间）逻辑上是堆空间的一部分，但是虚拟机的实现中将方法区和堆分开了，如下图：\n","date":"2024-12-28T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/jvm/","title":"JVM"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings\rThe following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1\rH2\rH3\rH4\rH5\rH6\rParagraph\rXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes\rThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution\rTiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution\rDon\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables\rTables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables\rItalics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks\rCode block with backticks\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces\r\u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block\r1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types\rOrdered List\rFirst item Second item Third item Unordered List\rList item Another item And another item Nested list\rFruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark\rGIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image\rThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-26T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E6%88%91%E6%98%AF%E6%A0%87%E9%A2%98/","title":"我是标题"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings\rThe following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1\rH2\rH3\rH4\rH5\rH6\rParagraph\rXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes\rThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution\rTiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution\rDon\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables\rTables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables\rItalics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks\rCode block with backticks\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces\r\u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block\r1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types\rOrdered List\rFirst item Second item Third item Unordered List\rList item Another item And another item Nested list\rFruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark\rGIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image\rThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-26T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E6%88%91%E6%98%AF%E6%A0%87%E9%A2%982/","title":"我是标题2"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings\rThe following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1\rH2\rH3\rH4\rH5\rH6\rParagraph\rXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes\rThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution\rTiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution\rDon\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables\rTables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables\rItalics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks\rCode block with backticks\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces\r\u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block\r1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types\rOrdered List\rFirst item Second item Third item Unordered List\rList item Another item And another item Nested list\rFruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark\rGIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image\rThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-26T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/%E6%88%91%E6%98%AF%E6%A0%87%E9%A2%983/","title":"我是标题3"},{"content":"正文测试\r而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用\r思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n","date":"2024-09-09T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/test-a/","title":"A"},{"content":"JavaWEB部分\r请描述转发和重定向的区别？\r1、请求次数： 转发一次，重定向两次\n2、浏览器地址：转发不变，重定向改变\n3、使用request域共享数据：转发是一次请求可以共享数据，重定向浏览器发起两次请求，不能共享数据\n4、相对路径： 转发地址不变会造成转发后的页面中的相对位置发生改变引起相对路径失效，重定向不会\n5、效率：转发浏览器一次请求效率高，重定向效率低\n6、WEB-INF下资源：转发可以访问，重定向不可以\n==和===的区别？\r1、== 只判断值是否相等，不考虑其数据类型是否相等\n2、===既判断值相等，又判断数据类型相等\nHttp 常见的状态码有哪些？\r200 OK //客户端请求成功\n301 Moved Permanently（永久移除)，请求的 URL 已移走。Response 中应该包含一个 Location URL, 说明资源现在所处的位置\n302 found 重定向\n400 Bad Request //客户端请求有语法错误，不能被服务器所理解\n401 Unauthorized //请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用\n403 Forbidden //服务器收到请求，但是拒绝提供服务\n404 Not Found //请求资源不存在，eg：输入了错误的 URL\n500 Internal Server Error //服务器发生不可预期的错误\n503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常\nServlet生命周期\rServlet 加载—\u0026gt;实例化—\u0026gt;服务—\u0026gt;销毁。\n生命周期详解：\ninit（）：\n在Servlet的生命周期中，仅执行一次init()方法。它是在服务器装入Servlet时执行的，负责初始化Servlet对象。可以配置服务器，以在启动服务器或客户机首次访问Servlet时装入Servlet。无论有多少客户机访问Servlet，都不会重复执行init（）。\nservice（）：\n它是Servlet的核心，负责响应客户的请求。每当一个客户请求一个HttpServlet对象，该对象的Service()方法就要调用，而且传递给这个方法一个“请求”（ServletRequest）对象和一个“响应”（ServletResponse）对象作为参数。在HttpServlet中已存在Service()方法。默认的服务功能是调用与HTTP请求的方法相应的do功能。\ndestroy（）：\n仅执行一次，在服务器端停止且卸载Servlet时执行该方法。当Servlet对象退出生命周期时，负责释放占用的资源。一个Servlet在运行service()方法时可能会产生其他的线程，因此需要确认在调用destroy()方法时，这些线程已经终止或完成。\n如何与Tomcat 结合工作步骤：\n（1）Web Client 向Servlet容器（Tomcat）发出Http请求\n（2）Servlet容器接收Web Client的请求\n（3）Servlet容器创建一个HttpRequest对象，将Web Client请求的信息封装到这个对象中。\n（4）Servlet容器创建一个HttpResponse对象\n（5）Servlet容器调用HttpServlet对象的service方法，把HttpRequest对象与HttpResponse对象作为参数传给HttpServlet 对象。\n（6）HttpServlet调用HttpRequest对象的有关方法，获取Http请求信息。\n（7）HttpServlet调用HttpResponse对象的有关方法，生成响应数据。\nServlet是单实例的吗？\rservlet是单实例的[单例多线程]\nservice是多线程方法\nServlet是线程安全的吗？为什么？\rServlet对象并不是一个线程安全的对象。\nServlet第一次被调用的时候，init()方法会被调用，然后调用service() 方法，从第二次被请求开始，就直接调用service()方法。\n因为servlet是单实例的，所以后面再次请求同一个Servlet的时候都不会创建Servlet实例，\n而且web容器会针对每个请求创建一个独立的线程，这样多个并发请求会导致多个线程同时调用 service() 方法，这样就会存在线程不安全的问题。\n如何解决Servlet线程不安全的问题？\r（1）不要在servlet中使用成员变量。\n（2）可以给servlet中的方法添加同步锁，Synchronized，但是不提倡，数据并发访问会造成阻塞等待。\n（3）可以实现 SingleThreadModel 接口，如下。这样可以避免使用成员变量的问题，但是也不提倡，原因同上。\nPublic class Servlet1 extends HttpServlet implements SingleThreadModel{\n……\n}\n谈谈过滤器的作用？\r过滤器，是在java web中，你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，\n然后再传入servlet或者struts的 action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，\n如果用户没有登陆都过滤掉）,或者在传入servlet或者 struts的action前统一设置字符集，或者去除掉一些非法字符\nRequest对象的主要方法有哪些？\rRequest对象的主要方法：\nsetAttribute(String name,Object)：设置名字为name的request 的参数值\ngetAttribute(String name)：返回由name指定的属性值\ngetAttributeNames()：返回request 对象所有属性的名字集合，结果是一个枚举的实例\ngetCookies()：返回客户端的所有 Cookie 对象，结果是一个Cookie 数组\ngetCharacterEncoding() ：返回请求中的字符编码方式\ngetContentLength() ：返回请求的 Body的长度\ngetHeader(String name) ：获得HTTP协议定义的文件头信息\ngetHeaders(String name) ：返回指定名字的request Header 的所有值，结果是一个枚举的实例\ngetHeaderNames() ：返回所以request Header 的名字，结果是一个枚举的实例\ngetInputStream() ：返回请求的输入流，用于获得请求中的数据\ngetMethod() ：获得客户端向服务器端传送数据的方法\ngetParameter(String name) ：获得客户端传送给服务器端的有 name指定的参数值\ngetParameterNames() ：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实\nrequest.getAttribute()和 request.getParameter()有何区别？\rgetParameter 得到的都是 String 类型的。或者是 http://a.jsp?id=123 中的 123，或者是某个表单提交过去的数据。\ngetAttribute 则可以是对象。\ngetParameter()是获取 POST/GET 传递的参数值；\ngetAttribute()是获取对象容器中的数据值；\ngetParameter：用于客户端重定向时，即点击了链接或提交按扭时传值用，即用于在用表单或 url 重定向传值时接收数据用。\ngetAttribute：用于服务器端重定向时，即在 sevlet 中使用了 forward 函数,或 struts 中使用了\nmapping.findForward。 getAttribute 只能收到程序用 setAttribute 传过来的值。\ngetParameter()是获取 POST/GET 传递的参数值；\ngetAttribute()是获取 SESSION 的值；\n另外，可以用 setAttribute,getAttribute 发送接收对象.而 getParameter 显然只能传字符串。\nsetAttribute 是应用服务器把这个对象放在该页面所对应的一块内存中去，当你的页面服务器\n重定向到另一个页面时，应用服务器会把这块内存拷贝另一个页面所对应的内存中。这样\ngetAttribute 就能取得你所设下的值，当然这种方法可以传对象。 session 也一样，只是对象在内存中的生命周期不一样而已。 getParameter 只是应用服务器在分析你送上来的 request页面的文本时，取得你设在表单或 url 重定向时的值。\ngetParameter 返回的是 String, 用于读取提交的表单中的值;\ngetAttribute 返回的是 Object，需进行转换,可用 setAttribute 设置成任意对象，使用很灵活，可随时用；\n什么是Tomcat？\rTomcat简单的说就是一个运行JAVA的网络服务器，底层是Socket的一个程序，它也是JSP和Serlvet的一个容器。\n详细描述MVC！\r基于java的web应用系统采用MVC设计模型，即用Model（模型）、View（视图）和Controller（控制）分离设计，这是目前web应用服务系统的主流设置方向。\nModel：处理业务逻辑的模块。\nView：负责页面显示，显示Model的处理结果给用户，主要实现数据到页面的转换过程。\nController：负责每个请求的分发，把Form数据传递给Model进行处理，处理完成后，把处理结果返回给相应的View显示给用户。\nHttp请求由哪三部分组成?\rhttp协议报文\n1.请求报文(请求行/请求头/请求数据/空行)\n​ 请求行\n​ 求方法字段、URL字段和HTTP协议版本\n​ 例如：GET /index.html HTTP/1.1\n​ get方法将数据拼接在url后面，传递参数受限\n​ 请求方法：\n​ GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT\n​ 请求头(key value形式)\n​ User-Agent：产生请求的浏览器类型。\n​ Accept：客户端可识别的内容类型列表。\n​ Host：主机地址\n​ 请求数据\n​ post方法中，会把数据以key value形式发送请求\n​ 空行\n​ 发送回车符和换行符，通知服务器以下不再有请求头\n2.响应报文(状态行、消息报头、响应正文)\n​ 状态行\n​ 消息报头\n​ 响应正文\n请说下在后台Servlet代码中如何获取前端form表单提交的属性？\r可以使用request.getParameter(); 也可以使用request.getParameterMap(),在使用beanutils.populate()方法\n说说Promise有什么特别？\r（1）对象的状态不受外界影响。Promise对象代表一个异步操作，有三种状态：pending（进行中）、fulfilled（已成功）和rejected（已失败）。只有异步操作的结果，可以决定当前是哪一种状态，任何其他操作都无法改变这个状态。\n（2）一旦状态改变，就不会再变，任何时候都可以得到这个结果。Promise对象的状态改变，只有两种可能：从pending变为fulfilled和从pending变为rejected。\n只要这两种情况发生，状态就凝固了，不会再变了，会一直保持这个结果，这时就称为 resolved（已定型）。如果改变已经发生了，你再对Promise对象添加回调函数，也会立即得到这个结果。\nnpm常用命令？\r1.项目初始化 npm init\n2.安装依赖 npm install 包名 或者 npm install 包名@版本号/npm install -g 包名/npm install\n3.升级依赖 npm update 包名\n4.卸载依赖 npm uninstall 包名\n5.查看依赖 npm ls查看项目依赖 npm list -g查看全局依赖\nES6模块化有几种暴露方式，分别作出解释？\r1.分别暴露 // 模块想对外导出,添加export关键字即可!\n2.统一暴露 // 模块想对外导出,export统一暴露想暴露的内容!\n3.默认暴露 // 默认暴露语法 export default sum默认暴露相当于是在暴露的对象中增加了一个名字为default的属性\n请描述get请求 和 post请求的区别？\r① 浏览器和表单的默认提交方式是get，get请求效率比post高\n② get请求参数在url地址后拼接，所以有以下特点：\n请求报文没有请求体 少了和请求体相关的请求头参数 参数在url地址中拼接，上传参数大小有限制，不能用来上传文件，相对post请求不安全 ③ post请求参数在请求报文的请求体中携带，有以下特点：\n请求报文有请求体，相对安全 请求头多了和请求体相关的参数 请求体数据没有大小限制可以用来上传文件 async await的基本使用\rasync 表示这是一个async函数， await只能用在async函数里面，不能单独使用 async 返回的是一个Promise对象，await就是等待这个promise的返回结果后，再继续执行 await 如果右边的是一个Promise对象，后面必须跟一个Promise对象，但是不必写then()，直接就可以得到返回值，如果await右边是一个普通数据 返回的就是普通数据\nsession 和 cookie 有什么区别？\rCookie:主要用在保存客户端，其值在客户端与服务端之间传送，不安全，存储的数据量有限。 Session:保存在服务端，每一个session在服务端有一个sessionID作一个标识。存储的数据量大，安全性高。占用服务端的内存资源 cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，相当重要的数据，应该使用session保存到服务端。 session会在一定时间内保持在服务器上，但是会占用内存资源，当访问的用户过多，会加重服务器的负载，考虑到减轻服务器的压力，可以将不重要的数据放在cookie中持久的保存。 单个cookie保存的数据不能超过4k，很多浏览器都限制站点最多保存20个cookie。 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。 这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。 集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。 这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。\n简述响应式数据和非响应式数据？\r响应式: 1. 当Vue组件的实例初始化的时候已有的数据就是响应式数据 2. 响应式属性的值发生改变会触发视图更新 非响应式: 1. 当Vue组件的实例初始化的时候没有，后期添加的属性 2. 非响应式属性的值发生改变不会触发视图更新\n请说下Vue 有哪些指令，并简述其作用（5个以上）？\rv-html：用于渲染HTML标签 v-show：用于类似双大括号语法渲染数据 v-if：渲染数据的时候，也可以用于条件判断 v-for：遍历集合或者数组，用于页面渲染数据 v-bind:绑定属性，注意冒号后面跟标签的属性，属性后面的等号指向数据，它可以简写为 :class, :href。 V-model：数据双向绑定\n简述JS中var let const声明变量的区别？\rLet 和 var的区别 1、let 不能重复声明 2、let有块级作用域，非函数的花括号遇见let会有块级作用域，也就是只能在花括号里面访问。 3、let不会预解析进行变量提升 4、let 定义的全局变量不会作为window的属性 const和var的差异 1、新增const和let类似，只是const定义的变量不能修改 2、并不是变量的值不得改动，而是变量指向的那个内存地址所保存的数据不得改动。\n框架部分\rMaven 构建工具\rMaven项目依赖中作用范围scope?\r当一个Maven工程添加了对某个jar包的依赖后，这个被依赖的jar包可以对应下面几个可选的范围，默认是compile。\n​\nMaven项目之间的三种关系及其特征？\r- 依赖关系（兄弟关系、朋友关系）：\n- 项目A依赖项目B，项目A可以访问项目B中某些依赖，避免重复提供\n- 缺点：但是只有范围为compile时可以访问\n- 继承关系（父子关系，并列关系）：\n- 使用继承时，需要定义父项目和子项目\n- 继承关系是单向关系：子项目指定父项目，父项目不用指定子项目\n- 父项目的所有的依赖（compile、test、provided等）子项目都可以自动使用\n- 父项目中可以通过dependencyManagement来管理依赖，子项目如果需要必须手动声明\n- 缺点：彼此间是并列关系，父项目、子项目需要分别逐个手动进行clean、compile操作\n- 聚合关系（父子关系，包含关系）：\n- 首先是继承关系，并且比继承关系更进一步\n- 在聚合关系中, 子项目明确父项目, 但是父项目明确子项目，是双向关系\n- 其实是一个大项目包含多个子项目，对父项目进行clear、compile等命令，\n是对所有子项目进行clear、compile命令。但是如果对一个子项目进行maven操作，不影响其他子项目\nMaven中A依赖B，B依赖C，那么A可以使用C中的类吗？\r此时要看B依赖C时的范围，如果是compile范围则A可以使用C，如果是test或provided范围则A不能使用C。\n通过Maven下载jar包，下载失败了怎么办？（提示：分*.lastUpdated和内部损坏两种情况说明）\r.lastUpdated情况：将.lastUpdated文件删除，重新下载。如果*.lastUpdated这样的文件很多，则使用专门的批处理脚本统一清理。\n内部损坏情况：删除损坏的jar包重新下载。\n下面依赖信息对应的jar包在Maven仓库根目录下的路径是什么？\rorg.apache.commons\ncommons-lang3\n3.1\n答案：Maven本地库根目录/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar\nMaven仓库之间的关系以及优先级？（须简单介绍三个仓库）\rMaven仓库是用来存储和管理Maven项目所需依赖和插件的地方。通常情况下，Maven仓库可以分为三个层次：本地仓库、中央仓库和远程仓库。\n本地仓库：是位于本地计算机上的一个目录，用于存储Maven项目构建所需的依赖和插件。当第一次构建项目时，Maven会自动从中央仓库下载所需的依赖到本地仓库。本地仓库具有最高的优先级，即当构建项目时，Maven会首先在本地仓库中查找依赖，如果找到则直接使用，否则才会去中央仓库或远程仓库下载。\n中央仓库：是Maven官方维护的仓库，包含了大量的开源Java项目依赖和插件。当Maven构建项目时，如果本地仓库没有找到所需的依赖，就会去中央仓库下载。中央仓库具有较高的优先级，因为它包含了许多常用的依赖和插件。\n远程仓库：是自定义的仓库，用于存放特定的依赖和插件。远程仓库可以是私有的，也可以是公共的。当本地仓库和中央仓库都没有找到所需的依赖时，Maven会去远程仓库下载。远程仓库具有较低的优先级，因为它是在本地仓库和中央仓库之后才被搜索的。\n总之，Maven仓库之间的关系是本地仓库优先于中央仓库和远程仓库，中央仓库优先于远程仓库。这样的优先级规则保证了Maven能够高效地查找和下载所需的依赖和插件。\n如何解决Mavan 环境依赖jar包冲突\r版本排除 com.example example-artifact 1.0.0 conflicting-group conflicting-artifact 2. 引入更具体的依赖版本 3. 使用Dependency Management 在父级pom.xml 中明确指定依赖的版本，可以确保所有模块使用相同的版本 4. 调整依赖顺序 案例： 假设存在两个依赖A和B，它们都依赖同一个第三方库C，但是使用了不同的版本。如果你希望使用A依赖中的C版本，而不是B依赖中的C版本，可以将A的依赖声明放在B之前，这样Maven在解析依赖时会优先选择A的C版本。 5. 使用插件分析依赖冲突 如maven-dependency-plugin和maven-enforcer-plugin,这些插件可以帮助你检查和解决依赖冲突问题。 6. 升级或降级依赖版本 如果允许的话，你可以尝试升级或降级冲突的依赖版本，以解决冲突问题。但需要注意，这可能会引入其他问题，因此需要谨慎操作。 Ssm框架\r如何理解框架framework？\r- 生活案例：不需要自己盖房，直接购买毛坯房即可，自己来装修，质量户型有保证，还节省了建房的时间。\n在开发过程中使用的框架就好比毛坯房。\n- 框架= jar（大量最佳实践基础上的对特定问题的固定解决方案进行封装并提供相应的API）\n+ 配置文件（个性化定制，配置变化的内容，比如数据库连接参数、端口号、接口的具体实现类等）\n- 作用1：可以保证减少开发时间、降低开发难度，并且还保证设计质量。好比和世界上最优秀的软件工程师是\n​ 一个项目的，并且他们完成的还是基础、全局的工作。想想是不是很嗨的一件事情。\n- 作用2：框架还有一个作用是约束，统一了代码流程和风格。同样的技术解决同样的问题会产生不同流程和\n​ 风格的解决方案，而采用一种框架其实就是限制用户必须使用其规定的方案来实现，可降低程序员\n​ 之间沟通以及日后维护的成本。\n- 常用的基于JavaEE的三大开源框架，已经从SSH、SSH2过渡到了SSM：SpringMVC、Spring、MyBatis。\n- 总之，框架是一个半成品，已经对基础的代码进行了封装并提供相应的API，开发者在使用框架是直接调用\n封装好的API可以省去很多代码编写，从而提高工作效率和开发速度，并统一了风格（这一点不要忽略掉）。\n如何理解ORM\r- JDBC的缺点：需要手动的完成面向对象的Java语言、面向关系的数据库之间数据的转换，代码繁琐无技术含量，\n影响了开发效率（查询时需要手动的将结果集ResultSet的列数据转换为Java对象的属性；\n而添加操作时需要手动将Java对象的属性转换为数据库表的列字段）。\n- 关于面向对象的Java语言、面向关系的数据库之间数据的转换必须要做，问题在于这个转换是否可以不由开\n发者来做。可以的。ORM框架就是专门来做这个问题的，相当于在面向对象语言和关系数据库之间搭建一个桥梁。\n- ORM，Object-Relationl Mapping，对象关系映射，它的作用是在关系型数据库和对象之间作一个映射，\n这样我们在具体的操作数据库的时候，只要像平时操作对象一样操作它就可以了，\nORM框架会根据映射完成对数据库的操作，就不需要再去和复杂的SQL语句打交道了。\nHibernate是一个全自动的ORM框架。因为Hibernate创建了Java对象和数据库表之间的完整映射，\n可以完全以面向对象的思想来操作数据库，程序员不需要手写SQL语句。MyBatis中还需要手写SQL语句，\n所以是半自动化的。但是最终MyBatis却战胜了Hibernate，主要还是因为MyBatis可以更加精确的定义SQL，\n更加灵活，也便于优化性能。\nMybatis 结果集的映射方式有几种，并分别解释每种映射方式如何使用？\r自动映射 ，通过resultType来指定要映射的类型即可。 自定义映射 通过resultMap来完成具体的映射规则，指定将结果集中的哪个列映射到对象的哪个属性。\nMybatis中#{}和${}的区别是什么？\r#{}是预编译处理，${}是字符串替换。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。\nMybatis中当实体类中的属性名和表中的字段名不一样 ，怎么办 ？\r第1种： 通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。 select order_id id, order_no orderno ,order_price price form orders where order_id=#{id}; 第2种： 通过来映射字段名和实体类属性名的一一对应的关系 select * from orders where order_id=#{id} \u0026lt;!–用id属性来映射主键字段–\u0026gt; \u0026lt;!–用result属性来映射非主键字段，property为实体类属性名，column为数据表中的属性–\u0026gt; MyBatis如何获取自动生成的(主)键值？如何完成MySQL的批量操作\r在标签中使用 useGeneratedKeys 和 keyProperty 两个属性来获取自动生成的主键值。 例如: insert into names (name) values (#{name}) MyBatis完成MySQL的批量操作主要是通过标签来拼装相应的SQL语句。 例如: insert into tbl_employee(last_name,email,gender,d_id) values (#{curr_emp.lastName},#{curr_emp.email},#{curr_emp.gender},#{curr_emp.dept.id}) 简述MyBatis的单个参数、多个参数如何传递及如何取值\r1、MyBatis传递单个参数，如果是普通类型(String+8个基本)的，取值时在#{}中可以任意指定，如果是对象类型的，则在#{}中使用对象的属性名来取值\n2、MyBatis传递多个参数，默认情况下，MyBatis会对多个参数进行封装Map. 取值时 在#{}可以使用012 .. 或者是param1 param2.. 3、MyBatis传递多个参数，建议使用命名参数，在Mapper接口的方法的形参前面使用 @Param() 来指定封装Map时用的key. 取值时在#{}中使用@Param指定的key.\n方法一：顺序传参\n1 2 3 4 public User select(String name,int id); \u0026lt;select id=\u0026#34;select\u0026#34; resultMap=\u0026#34;UserResultMap\u0026#34;\u0026gt; select * from user where name=#{0} and id=#{1} \u0026lt;/select\u0026gt; #{}里面的数字代表你传入参数的顺序。 这种方法不建议使用，sql层表达不直观，且一旦顺序调整容易出错。\n方法二：@Param注解传参\n1 2 3 public User select(@Param(\u0026#34;paramName\u0026#34;) String name,@Param(\u0026#34;paramId\u0026#34;) int id); \u0026lt;select id=\u0026#34;select\u0026#34; resultMap=\u0026#34;UserResultMap\u0026#34;\u0026gt; select * from user where name=#{paramName} and id=#{paramId} \u0026lt;/select\u0026gt; #{}里面的名称对应的是注解 @Param括号里面修饰的名称。 这种方法在参数不多的情况还是比较直观的，推荐使用。\n方法三：Map传参\n1 2 3 4 5 Map\u0026lt;String,Object\u0026gt; map = new HashMap\u0026lt;String, Object\u0026gt;(); map.put(\u0026#34;mapName\u0026#34;,\u0026#34;zhangsan\u0026#34;); map.put(\u0026#34;mapId\u0026#34;,2); public User select(Map\u0026lt;String,Object\u0026gt; map); \u0026lt;select id=\u0026#34;select\u0026#34; parameterType=\u0026#34;java.util.Map\u0026#34; resultMap=\u0026#34;UserResultMap\u0026#34;\u0026gt; select * from user where name=#{mapName} and id=#{mapId} \u0026lt;/select\u0026gt; #{}里面的名称对应的是 Map里面的key名称。 这种方法适合传递多个参数，且参数易变能灵活传递的情况。\n讲述下MyBatis多表映射中association与collection区别\r在MyBatis多表映射中，association和collection是两种不同的映射类型，用于处理关联关系和一对多的关系。\nassociation： association用于描述两个表之间的一对一关系。它表示一个复杂类型（Java对象）在另一个表中的外键关联。在映射文件中，我们可以使用association来定义关联关系，指定外键列和关联的结果映射。 例如，假设我们有两个表：Order（订单）和User（用户），一个订单只对应一个用户。我们可以在Order的映射文件中使用association来描述订单和用户之间的关联关系： 这里，association指定了外键列order_id以及关联的结果映射User。 collection： collection用于处理一对多的关系，表示一个表中的一条记录关联多个另一个表的记录。在映射文件中，我们可以使用collection来定义一对多的映射关系。 例如，假设我们有两个表：Department（部门）和Employee（员工），一个部门拥有多个员工。我们可以在Department的映射文件中使用collection来描述部门和员工之间的关系： 这里，collection指定了关联的结果集类型（Employee）以及关联的结果映射。 区别： association用于一对一的关系，而collection用于一对多的关系。 association关联的结果类型是复杂类型（Java对象），而collection关联的结果类型是集合类型（List、Set等）。 在association中，外键列必须在当前表中存在；而在collection中，外键列可以在当前表或关联表中存在。 association使用的是association标签，而collection使用的是collection标签。\n请写出Mybatis中常用的动态标签，并简单介绍其作用？\rif 标签 if 标签通常用于 WHERE 语句、UPDATE 语句、INSERT 语句中，通过判断参数值来决定是否使用某个查询条件、判断是否更新某一个字段、判断是否插入某个字段的值。\nforeach 标签 foreach 标签主要用于构建 in 条件，可在 sql 中对集合进行迭代。也常用到批量删除、添加等操作中。\nchoose 标签 有时候我们并不想应用所有的条件，而只是想从多个选项中选择一个。MyBatis 提供了 choose 元素，按顺序判断 when 中的条件出否成立，如果有一个成立，则 choose 结束。当 choose 中所有 when的条件都不满则时，则执行 otherwise 中的 sql。类似于 Java 的 switch 语句，choose 为 switch，when 为 case，otherwise 则为 default。\nwhere 标签 当 if 标签较多时,如果标签返回的内容是以 AND 或 OR 开头的，则它会剔除掉. set 标签 使用 set 标签可以将动态的配置 set关键字，和剔除追加到条件末尾的任何不相关的逗号。\ntrim 标签 格式化输出，也可以通过 trim 标签设定或忽略前后缀来实现. 配置关联关系 collection 标签 配置一对多 association 标签 配置一对一 sql 标签 当多种类型的查询语句的查询字段或者查询条件相同时，可以将其定义为常量，方便调用。为求 结构清晰也可将 sql 语句分解。\n描述下Spring Ioc依赖注入，有哪些方式？(IOC和DI)\r构造器依赖注入：构造器依赖注入在容器触发构造器的时候完成，该构造器有一系列的参数，每个参数代表注入的对象。\nSetter方法依赖注入：首先容器会触发一个无参构造函数或无参静态工厂方法实例化对象，之后容器调用bean中的setter方法完成Setter方法依赖注入。 全局属性注入：\n说下对Spring面向切面编程(AOP)的理解？以及常用术语\r面向切面编程AOP可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。 可以和过滤器进行类比来理解AOP，有很多相似点。 - OOP解决纵向的业务问题，AOP解决横向的问题，比如日志、安全验证、事务、异常等。 相同的代码重复的出现在项目的不同位置，不利于维护。可以将这些功能分别提取出来，由多份变成一份， 然后在编译或者运行时织入到指定的多个位置。 - Spring底层使用了动态代理模式实现AOP。若目标对象实现了若干接口，Spring 使用JDK的动态代理。 若目标没有实现任何接口，Spring 使用 CGLIB 库生成目标类的子类。还可以配置不管是否实现接口， 都是要CGLIB。 面向切面编程（AOP）：允许程序员模块化横向业务逻辑，或定义核心部分的功能，例如日志管理和事务管理。 切面(Aspect) ：AOP的核心就是切面，它将多个类的通用行为封装为可重用的模块。该模块含有一组API提供 cross-cutting功能。例如,日志模块称为日志的AOP切面。根据需求的不同，一个应用程序可以有若干切面。在Spring AOP中，切面通过带有@Aspect注解的类实现。 通知(Advice)：通知表示在方法执行前后需要执行的动作。实际上它是Spring AOP框架在程序执行过程中触发的一些代码。Spring切面可以执行一下五种类型的通知: before(前置通知)：在一个方法之前执行的通知。 after(最终通知)：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。 after-returning(后置通知)：在某连接点正常完成后执行的通知。 after-throwing(异常通知)：在方法抛出异常退出时执行的通知。 around(环绕通知)：在方法调用前后触发的通知。 切入点(Pointcut)：切入点是一个或一组连接点，通知将在这些位置执行。可以通过表达式或匹配的方式指明切入点。 引入：引入允许我们在已有的类上添加新的方法或属性。 目标对象：被一个或者多个切面所通知的对象。它通常是一个代理对象。也被称做被通知（advised）对象。 代理：代理是将通知应用到目标对象后创建的对象。从客户端的角度看，代理对象和目标对象是一样的。有以下几种代理： BeanNameAutoProxyCreator：bean名称自动代理创建器 DefaultAdvisorAutoProxyCreator：默认通知者自动代理创建器 Metadata autoproxying：元数据自动代理织入：将切面和其他应用类型或对象连接起来创建一个通知对象的过程。织入可以在编译、加载或运行时完成。 Spring中常用的设计模式\r- 代理模式——Spring 中两种代理方式，若目标对象实现了若干接口，Spring 使用JDK的java.\nlang.reflect.Proxy类代理。若目标没有实现任何接口，Spring 使用 CGLIB 库生成目标类的子类。\n- 单例模式——在 Spring 的配置文件中设置 bean 默认为单例模式。\n- 模板方式模式——用来解决代码重复的问题。比如：RestTemplate、JmsTemplate、JpaTemplate。\n- 工厂模式——在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用同一个\n接口来指向新创建的对象。Spring 中使用 beanFactory 来创建对象的实例。\n简述Spring声明式事务中@Transaction中常用的两种事务传播行为？\r通过propagation来执行事务的传播行为 REQUIRED: 使用调用者的事务，如果调用者没有事务，则启动新的事务运行 REQUIRES_NEW: 将调用者的事务挂起，开启新的事务运行。\n谈谈你对spring框架的深入理解？\rSpring一款容器框架，其核心是IOC和AOP （1）IOC就是控制反转，指创建对象的控制权转移给Spring框架进行管理，并由Spring根据配置文件去创建实例和管理各个实例之间的依赖关系，对象与对象之间松散耦合，也利于功能的复用。DI依赖注入，和控制反转是同一个概念的不同角度的描述，即 应用程序在运行时依赖IoC容器来动态注入对象需要的外部依赖。 （2）最直观的表达就是，以前创建对象的主动权和时机都是由自己把控的，IOC让对象的创建不用去new了，可以由spring自动生产，使用java的反射机制，根据配置文件在运行时动态的去创建对象以及管理对象，并调用对象的方法的。 （3）AOP，一般称为面向切面，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，提高系统的可维护性。可用于权限认证、日志、事务处理。 AOP实现的关键在于 代理模式，AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。\n说一下Spring中支持的bean作用域？\rSpring框架支持如下五种不同的作用域： singleton：在Spring IOC容器中仅存在一个Bean实例，Bean以单实例的方式存在。 prototype：一个bean可以定义多个实例。 Web容器 request：每次HTTP请求都会创建一个新的Bean。该作用域仅适用于WebApplicationContext环境。 session：一个HTTP Session定义一个Bean。该作用域仅适用于WebApplicationContext环境。 globalSession：同一个全局HTTP Session定义一个Bean。该作用域同样仅适用于WebApplicationContext环境。bean默认的scope属性是\u0026quot;singleton\u0026quot;。\n解释自动装配的各种模式？（扩展）\r自动装配提供五种不同的模式供Spring容器用来自动装配beans之间的依赖注入: no：默认的方式是不进行自动装配，通过手工设置ref 属性来进行装配bean。 byName：通过参数名自动装配，Spring容器查找beans的属性，这些beans在XML配置文件中被设置为byName。之后容器试图匹配、装配和该bean的属性具有相同名字的bean。 byType：通过参数的数据类型自动自动装配，Spring容器查找beans的属性，这些beans在XML配置文件中被设置为byType。之后容器试图匹配和装配和该bean的属性类型一样的bean。如果有多个bean符合条件，则抛出错误。 constructor：这个同byType类似，不过是应用于构造函数的参数。如果在BeanFactory中不是恰好有一个bean与构造函数参数相同类型，则抛出一个严重的错误。 autodetect：如果有默认的构造方法，通过 construct的方式自动装配，否则使用 byType的方式自动装配。\n解释Spring框架中bean的生命周期？\r1.首先容器启动后，会对scope为singleton且非懒加载的bean进行实例化， 2.按照Bean定义信息配置信息，注入所有的属性， 3.如果Bean实现了BeanNameAware接口，会回调该接口的setBeanName()方法，传入该Bean的id，此时该Bean就获得了自己在配置文件中的id， 4.如果Bean实现了BeanFactoryAware接口,会回调该接口的setBeanFactory()方法，传入该Bean的BeanFactory，这样该Bean就获得了自己所在的BeanFactory， 5.如果Bean实现了ApplicationContextAware接口,会回调该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext， 6.如果有Bean实现了BeanPostProcessor接口，则会回调该接口的postProcessBeforeInitialzation()方法， 7.如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法， 8.如果Bean配置了init-method方法，则会执行init-method配置的方法， 9.如果有Bean实现了BeanPostProcessor接口，则会回调该接口的postProcessAfterInitialization()方法， 10.经过流程9之后，就可以正式使用该Bean了,对于scope为singleton的Bean,Spring的ioc容器中会缓存一份该bean的实例，而对于scope为prototype的Bean,每次被调用都会new一个新的对象，期生命周期就交给调用方管理了，不再是Spring容器进行管理了 11.容器关闭后，如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法， 12.如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法，至此，整个Bean的生命周期结束\n简述SpringMVC 的工作原理？（处理请求流程）\r（1）用户向服务器发送请求，请求被springMVC 前端控制器 DispatchServlet 捕获； （2）DispatcherServle 对请求 URL 进行解析，得到请求资源标识符（URL），然后根据该 URL 调用 HandlerMapping将请求映射到处理器 HandlerExcutionChain； （3）DispatchServlet 根据获得 Handler 选择一个合适的HandlerAdapter 适配器处理； （4）Handler 对数据处理完成以后将返回一个 ModelAndView（）对象给 DisPatchServlet; （5）Handler 返回的 ModelAndView() 只是一个逻辑视图并不是一个正式的视图， DispatcherSevlet 通过ViewResolver 试图解析器将逻辑视图转化为真正的视图View; （6）DispatcherServle 通过 model 解析出 ModelAndView()中的参数进行解析最终展现出完整的 view 并返回给客户端;\n简述SpringMVC中处理模型数据的两种方式？Handler（Model Map ModelMap ） return ModelAndView\r使用 2. ModelAndView 作为方法的返回值，将 模型数据 和 视图信息封装到ModelAndView中 3. 使用Map 或者是Model 作为方法的形参. 将模型数据添加到Map或者是Model中. SpringMVC中如何实现请求域request中传递数据\r- 使用原生API request\n- 使用Model\n- 使用Map\n- 使用ModelMap\n- 使用ModelAndView\n注意：传入的Model、ModelMap、Map类型的数的三种方式其实本质上都是 BindingAwareModelMap 类型的，而四种非原生方式底层都调用了原生的request.setAttribute(name,value)。\n简述SpringMVC中如何返回JSON数据？\r在工程最终加入jackson的jar包 2. 在请求处理方法中，将返回值改为具体返回的数据的类型， 例如 数据的集合类型 List等。 3. 在请求处理方法上使用@ResponseBody注解 SpringMVC如何快速返回jsp视图\r准备jsp页面和依赖 pom.xml依赖 jakarta.servlet.jsp.jstl jakarta.servlet.jsp.jstl-api 3.0.0 /** * 跳转到提交文件页面 /save/jump * * 如果要返回jsp页面! * 1.方法返回值改成字符串类型 * 2.返回逻辑视图名即可 * * + 逻辑视图名 + * */ @GetMapping(\u0026ldquo;jump\u0026rdquo;) public String jumpJsp(Model model){ System.out.println(\u0026ldquo;FileController.jumpJsp\u0026rdquo;); model.addAttribute(\u0026ldquo;msg\u0026rdquo;,\u0026ldquo;request data!!\u0026rdquo;); return \u0026ldquo;home\u0026rdquo;; } 转发和重定向 String @ResponseBody return “forward: /地址 redirect:/地址”\nPageHelper插件是如何使用\r拦截器：它自己就在 IOC 容器中，所以可以直接从 IOC 容器中装配组件。\n\\1. pom.xml引入依赖\n​ com.github.pagehelper\n​ pagehelper\n​ 5.1.11\n\\2. mybatis-config.xml配置分页插件\n在 MyBatis 的配置文件中添加 PageHelper 的插件：\n​ ​ ​ 其中，com.github.pagehelper.PageInterceptor 是 PageHelper 插件的名称，dialect 属性用于指定数据库类型（支持多种数据库）\nSpringMVC中如何实现Restful风格的数据传输和接收\r\\1. web.xml中添加过滤器org.springframework.web.filter.HiddenHttpMethodFilter，负责根据表单项的取值情况将POST请求转换为PUT请求或者DELETE。\n\\2. 视图中页面上使用Restful的地址提交请求（不管是Ajax还是非Ajax请求均可）。\n\\3. Controller中方法使用@GetMapping/@PostMapping/@PutMapping/@DeleteMapping指定映射路径，如果包含路径变量使用{}来表示，方法参数前使用@PathVariable注解将路径变量和参数绑定。\n简单的谈一下SpringMVC的核心API（核心组件）\r- DispatcherServlet：总控制器\n- HandlerMapping：处理器映射器，建立了请求路径和分控制器方法之间的映射\n- HandlerExecutionChain：总控制器调用HandlerMapping组件的返回值，是一个执行链，不仅有要执行的分控制器方法，还有相应的多个拦截器，组成一个执行链\n- HandlerAdapter：处理器适配器，调用Handler，不是由总控制直接调用的，而是由HandlerAdapter来调用\n- ViewResolver：逻辑视图（result）\u0026mdash;\u0026ndash;\u0026gt;物理视图（/WEB-INF/templates/result.html）\n请解释@Autowired(required =true | false)注解的工作机制及required属性的作用？\r首先会使用byType的方式进行自动装配，如果能唯一匹配，则装配成功， 如果匹配到多个兼容类型的bean, 还会尝试使用byName的方式进行唯一确定. 如果能唯一确定，则装配成功，如果不能唯一确定，则装配失败，抛出异常. 默认情况下， 使用@Autowired标注的属性必须被装配，如果装配不了，也会抛出异常. 可以使用required=false来设置不是必须要被装配.\n说下ContextLoaderListener的作用\r常见使用场景：\n- 场景1：使用了Spring但是没有使用SpringMVC的web项目（比如Dubbo服务提供者），如何加载Spring配置文件？可以使用ContextLoaderListener来加载。\n- 场景2：使用了SpringMVC但是项目规模大，有多个配置文件，除了使用DispatcherServlet一次性加载，是否有其他方法？可以使用ContextLoaderListener和DispatcherServlet分别加载。\n使用及其注意事项：\n- public class ContextLoaderListener extends ContextLoader implements ServletContextListener，该类是一个ServletContextListener，在项目启动的时候加载。注意：Servlet、Filter、Listener的加载顺序：Listener、Filter、Servlet。所以会先加载ContextLoaderListener ，再加载DispatcherServlet。\n- 使用ContextLoaderListener加载非SpringMVC配置文件创建的IoC容器是父容器，DispatcherServlet加载SpringMVC的的配置文件创建的IoC容器是子容器。子容器优先使用自己的Bean，如果没有，可以使用父容器的Bean。\n- 注意事项：同时使用了ContextLoaderListener和DispatcherServlet，如果\u0026lt;context:component-scan \u0026gt;的路径设置不合理，就会重复的创建Bean，甚至导致无法应用业务层事务的问题。\n请描述一下Spring的事务管理？\r1、声明式事务管理的定义：用在 Spring 配置文件中声明式的处理事务来代替代码式的处理事务。这样的好处是，事务管理不侵入开发的组件，具体来说，业务逻辑对象就不会意识到正在事务管理之中，事实上也应该如此，因为事务管理是属于系统层面的服务，而不是业务逻辑的一部分，如果想要改变事务管理策划的话，也只需要在定义文件中重新配置即可，这样维护起来极其方便。 基于 TransactionInterceptor 的声明式事务管理：两个次要的属性： transactionManager，用来指定一个事务治理器， 并将具体事务相关的操作请托给它； 其他一个是 Properties 类型的transactionAttributes 属性，该属性的每一个键值对中，键指定的是方法名，方法名可以行使通配符， 而值就是表现呼应方法的所运用的事务属性。 2、基于 @Transactional 的声明式事务管理：Spring 2.x 还引入了基于 Annotation 的体式格式，具体次要触及@Transactional 标注。@Transactional 可以浸染于接口、接口方法、类和类方法上。算作用于类上时，该类的一切public 方法将都具有该类型的事务属性。 编程式事物管理的定义：在代码中显式挪用 beginTransaction()、commit()、rollback()等事务治理相关的方法， 这就是编程式事务管理。Spring 对事物的编程式管理有基于底层 API 的编程式管理和基于 TransactionTemplate 的编程式事务管理两种方式。\n说一下你对spring框架中通知类型的理解？\r（1）前置通知（Before Advice）：在连接点（Join point）之前执行的通知。 （2）后置通知（After Advice）：当连接点退出的时候执行的通知（不论是正常返回还是异常退出）。 （3）环绕通知（Around Advice）：包围一个连接点的通知，这是最强大的一种通知类型。 环绕通知可以在方法调用前后完成自定义的行为。它也可以选择是否继续执行连接点或直接返回它们自己的返回值或抛出异常来结束执行。 （4）返回后通知（AfterReturning Advice）：在连接点正常完成后执行的通知（如果连接点抛出异常，则不执行） 抛出异常后通知（AfterThrowing advice）：在方法抛出异常退出时执行的通知\n请说出SpringMVC和Spring中常用的注解，并阐明其作用？\r@Controller，使用它标记的类就是一个SpringMVC Controller 对象 2. @RequestMapping，处理请求映射地址 3. @PathVariable，用于对应restful风格url中的参数 4. @RequestParam，将请求的参数绑定到方法中的参数上 5. @ResponseBody，将返回类型直接输入到http response body中 6. @RequestBody，方法参数直接被绑定到http request body中 7. @Component：泛指各种组件 8. @Service：业务层 9. @Repository：数据访问层 10.@Controller、@Service、@Repository都可以称为@Component。 @RequestMapping注解用在类上面有什么作用？\r它是一个用来处理请求地址映射的注解，可用于类或方法上。 用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。\n简述一下@RestController注解的作用\r如果需要 @ResponseBody 注解作用在类上时，我们可以直接使用 @RestController 注解，这个注解相当于@ResponseBody + @Controller注解，这样我们就不需要写两个注解了，具体如下所示： @Target({ElementType.TYPE})``@Retention(RetentionPolicy.RUNTIME)``@Documented@Controller``@ResponseBodypublic ``@interface RestController { `` @AliasFor( ``annotation = Controller.class `` ) String value() default \u0026quot;\u0026quot;;} @RestController注解的使用后，该类所有控制层方法都以JSON的形式返回。\nSpringMVC怎么样设定重定向和转发的？\r（1）转发：在返回值前面加\u0026quot;forward:\u0026quot;，譬如\u0026quot;forward:user.do?name=method4\u0026quot; （2）重定向：在返回值前面加\u0026quot;redirect:\u0026quot;，譬如\u0026quot;redirect:http://www.baidu.com\u0026quot;\n如何理解编程式事务与声明式事务？并说出他们的区别\r编程式事务和声明式事务是两种常见的事务管理方式。 编程式事务是在代码中显式地编写事务管理逻辑。开发人员需要手动在代码中控制事务的开始、提交或回滚，并处理可能出现的异常。编程式事务通常使用事务管理接口（如JDBC的Connection对象）来实现。 声明式事务是通过配置的方式来管理事务，而不需要在代码中显式地编写事务管理逻辑。开发人员只需在配置文件中声明事务的属性，如事务的传播行为、隔离级别等，由事务管理框架自动管理事务的开始、提交或回滚。 这两种事务管理方式的区别如下： 代码侵入性：编程式事务需要在代码中显式地编写事务管理逻辑，与业务逻辑代码紧密耦合，造成代码的冗余。而声明式事务通过配置方式管理事务，使得业务逻辑与事务管理逻辑解耦。 管理粒度：编程式事务可以灵活地控制事务的开始、提交或回滚，适用于复杂的事务场景。而声明式事务由事务管理框架自动管理事务，粒度较粗，适用于简单的事务场景。 可读性和可维护性：声明式事务通过配置文件来管理事务，代码清晰简洁，易于理解和维护。而编程式事务需要在代码中编写事务管理逻辑，代码复杂，可读性和可维护性较差。 综上所述，编程式事务适用于复杂的事务场景，提供了更高的灵活性和粒度控制；而声明式事务适用于简单的事务场景，使得代码更加清晰简洁。\nSpringMVC的返回值类型有哪些，具体说出一个使用场景？\r有String, ModelAndView。ModelAndView类把视图和数据都合并的一起的，但一般用String比较好。\nSQL题，有以下4张表\r请写出以下sql的查询语句\n（1）查询Score表中成绩为60或者为80的所有记录\rselect * from Score where Degree in （60，80）\n（2）查询Student表中学生不在C_001的所有记录\rselect * from Student where Class not in (‘C_001’)\n（3）查询Score表中的最底分的学生学号和课程号\rselect SNO,CNO from Score where Degree=(select MIN(Degree) from Score)\n（4）查询Score表中的最高分的学生学号和课程号\rselect SNO,CNO from Score where Degree=(select MAX(Degree) from Score)\n（5）查询成绩高于学号为“109”、课程号为“3-105”的成绩的所有记录\rselect * from student,Score where student.Sno=Score.Sno and Score.Degree\u0026gt;(select Degree from Score where Cno=‘3-105’ and Sno=‘109’)\n（6）查询Student表中不姓“王”的同学记录\rselect * from student where Sname not like (‘王%’)\n（7）以班号和年龄从大到小的顺序查询Student表中的全部记录\rselect * from student order by Class desc,Sbirthday asc\n（8）查询Student表中出生年月不为空的同学记录\rselect * from student where Sbirthday is not null\n（9）以年龄从大到小的顺序查询Student表中的全部记录\rselect * from student order by Sbirthday asc\nRedis 专题\rRedis为什么那么快？\r- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，\nHashMap的优势就是查找和操作的时间复杂度都是O(1)。\n- 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的。\n- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，\n不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗\n（Redis6.0后引入了多线程，但是为了重复利用CPU多核的优势，线程数量取决于CPU核数，\n而不是每个请求开启一个新线程）。\n- 使用多路I/O复用模型，非阻塞IO。I/O多路复用就是通过一种机制，让一个进程可以监视多个描述符，\n一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。\n常用的IO多路复用的实现有：select、poll、epoll。多路复用IO 技术最适用的是“高并发”场景。\n- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了\nVM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。\nRedis的五大数据类型，使用场景，底层原理？\rRedis有哪些持久化机制？它们分别是如何工作的？\r需要注意的是，Redis还支持持久化的混合模式，即同时使用RDB和AOF持久化机制。这样可以在某种程度上兼顾RDB和AOF的优点，并根据实际需求进行配置。 选择合适的持久化机制取决于应用的要求和场景。如果对数据完整性要求较高，可以选择AOF持久化。如果对性能和快速恢复较为重要，可以选择RDB持久化。无持久化模式适用于对数据持久性要求不高但追求最高性能和响应速度的场景。 对于AOF持久化，可以根据需求配置不同的策略，如每个写操作都同步到磁盘（fsync），或根据时间或操作数来定期同步。同步频率的选择可以根据数据的重要性和系统的容忍度来平衡性能和数据安全性。 综上所述，选择适当的持久化机制需要综合考虑应用需求、性能要求和数据安全性，并进行相应的配置和调优。\nRedis主从复制集群中配置哨兵能起到什么作用？\r通过配置哨兵的主从复制，可以实现Redis集群的高可用性和故障转移能力，提高系统的稳定性和可靠性。\nRedis 主从复制原理？(全量复制|增量复制)\r主要步骤：假设我们有一个包含一个主节点（Master）和两个从节点（Slave1和Slave2）的Redis集群。下面是Redis主从复制的原理： 1. 配置主节点（Master）：我们将其中一个节点配置为主节点，它负责接收写操作并广播数据变更。 2. 配置从节点（Slave）：将其他节点配置为从节点，它们复制主节点的数据并提供读服务。 3. 初始连接：从节点通过发送SYNC命令与主节点建立连接。 4. 快照同步：主节点执行BGSAVE命令生成RDB文件（持久化快照），然后将该文件发送给从节点。从节点接收并加载RDB文件，将主节点的数据进行初始化。 5. 命令传播：当主节点接收到写命令时，它会将命令发送给所有从节点。从节点按照相同的顺序执行这些写命令，以保持数据的一致性。 6. 增量复制：主节点将自己执行的写命令及其数据变更发送给从节点。从节点根据接收到的命令进行数据更新。 7. 主从节点通信：主节点和从节点之间通过心跳机制保持连接，并定期交换信息以检测状态和同步数据。 8. 故障恢复：如果主节点发生故障或宕机，从节点会自动选举出一个新的主节点，并进行重新同步。 通过主从复制，Redis实现了数据的备份和读写分离。主节点负责处理写操作，而从节点提供读服务，从而减轻了主节点的压力，并提高了系统的可用性和性能。\nRedis是单线程还是多线程？为什么能支持访问量和高并发?\r单线程。\n\\1) 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)\n\\2) 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗\n\\3) 使用多路I/O复用模型，非阻塞IO\n你是如何理解redis是单线程，多路I/O复用?\r在Redis中，单线程的含义是指Redis服务器在处理客户端请求时，使用单个线程逐个处理命令。这个单线程负责接收客户端连接、解析命令、执行命令和返回结果。因为只有一个线程在处理请求，所以不需要进行线程切换、上下文切换或锁竞争，避免了这些开销和潜在的并发问题。 Redis的多路I/O复用是指它利用操作系统提供的机制，同时监视和处理多个输入/输出通道（如网络套接字），以实现高并发的网络通信。 案例： 假设你是一个餐厅的服务员，你需要同时处理多个桌子上的点菜和结账请求。每个桌子都有不同的客人，他们需要你的服务。 在传统的方式中，你只能一次处理一个桌子的请求，即一次只能为一个桌子点菜或结账。 现在，为了提高效率，你采用了Redis多路I/O复用的方式来处理餐厅的请求。你站在一个中央服务台前，桌子上放置着多个点餐和结账设备。每个设备都连接到中央服务台的Redis服务器，并使用多路I/O复用技术进行管理。 当一个桌子需要点菜或结账时，服务员将其请求输入到相应的设备中，并将设备连接到Redis服务器。你可以同时处理多个桌子的请求，每个请求都在不同的设备上进行操作。 当一个桌子的请求处理完成后，设备会发送信号给Redis服务器，告知请求已经完成。Redis服务器收到信号后，将请求的结果返回给服务员，然后你可以继续处理其他桌子的请求。 通过这种多路I/O复用的方式，你能够高效地处理多个桌子的请求，而不需要一次只处理一个桌子。你可以同时处理多个桌子的点菜和结账，根据需要进行相应的操作。这样，你能够更快地为客人提供服务，提高了工作效率。\n为什么尽管redis 是单线程的，但它仍然能够实现高性能和并发的处理能力?\r这归功于以下几个因素： 1. 基于内存：Redis将数据存储在内存中，而内存的读写速度远高于磁盘和数据库的访问速度。通过避免磁盘I/O的开销，Redis能够实现非常高的吞吐量和低延迟。 2. 非阻塞I/O：Redis使用了多路I/O复用技术，如epoll、kqueue等，通过监听和处理多个网络连接，实现了非阻塞的I/O操作。这使得Redis能够同时处理多个客户端请求，支持高并发访问。 3. 单线程优化：Redis通过优化算法和数据结构，以及在内存中进行原子操作，最大程度地利用了单线程的优势。它避免了多线程带来的线程同步和资源竞争问题，简化了代码逻辑和维护成本。\n说说Redis哈希槽的概念？\rRedis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。\nRedis 淘汰机制? 满了才有淘汰!\rnoeviction 不进行数据淘汰，也是Redis的默认配置。这时，当缓存被写满时，再有写请求进来，Redis不再提供服务，直接返回错误。 2.volatile-random 缓存满了之后，在设置了过期时间的键值对中进行随机删除。 3.volatile-ttl 缓存满了之后，会针对设置了过期时间的键值对中，根据过期时间的先后顺序进行删除,越早过期的越先被删除。 4.volatile-lru 缓存满了之后，针对设置了过期时间的键值对，采用LRU算法进行淘汰，不熟悉LRU的可以看这篇文章。 5.volatile-lfu 缓存满了之后，针对设置了过期时间的键值对，采用LFU的算法进行淘汰。 6.allkeys-random 缓存满了之后，从所有键值对中随机选择并删除数据。 7.allkeys-lru 缓存写满之后，使用LRU算法在所有的数据中进行筛选删除。 8.allkeys-lfu 缓存满了之后，使用LRU算法在所有的数据中进行筛选删除。 在日常使用过程中，主要根据你的数据要求来配置相应的策略，这里我给你三点建议。 1. 我们优先使用allkeys-lru 策略。这样，我们就可以借助LRU算法去淘汰那些不常用的数据，把最近最常用的放在缓存中，从而提高应用的性能。如果你的数据有明显的冷热区分，建议你使用allkeys-lru策略。 2. 如果你的数据的访问频率相差不大，也没有冷热之分，直接使用allkeys-random 策略，随机选择淘汰的数据就行。 3. 如果你的数据有置顶要求，比如置顶新闻等。那么我们就选择volatile-lru策略，同时不给置顶数据设置过期时间，这样一来，置顶的数据永远不会被删除，而其他设置了过期时间的数据，会更加LRU算法进行淘汰 Git专题\rGit的分支管理是怎样的？ 写出相关分支命令并做出解释\rGit的分支管理是非常灵活的，每个分支可以独立开展工作，不同分支之间的内容可以合并。\n创建分支：通过命令git branch 可以创建一个新的分支，分支名可以自定义。\n切换分支：通过命令git checkout 可以切换到指定的分支，Git会自动将工作区的文件更新到指定分支的最新提交状态。\n合并分支：通过命令git merge 可以将指定分支的内容合并到当前分支，Git会尝试自动合并变化，如果有冲突则需要手动解决。\n删除分支：通过命令git branch -d 可以删除指定的分支。\n查看分支：通过命令git branch可以查看所有分支，当前分支会以特殊符号标识。\nGit中的HEAD是什么？ 谈谈你对HEAD的理解\rHEAD是Git中的一个特殊指针，用来指向当前分支的最新提交。HEAD的指向可以通过切换分支或者执行提交操作来改变。 Git切换版本，底层其实是移动的HEAD指针。\nGit中的暂存区（stage/index）是什么？\r暂存区是Git中的一个重要概念，它是用来存放待提交的文件 的区域。当我们修改了工作区的文件后，可以通过命令git add 将修改的文件添加到暂存区，然后通过命令git commit将暂存区的内容提交到当前分支。\nGit中如何撤销操作？你知道的有哪些？\r撤销修改：通过命令git checkout \u0026ndash; 可以撤销对工作区文件的修改，恢复到最近一次提交的状态。 撤销暂存：通过命令git reset HEAD 可以将暂存区的修改撤销，重新放回到工作区。 撤销提交：通过命令git revert 可以创建一个新的提交，将指定提交的修改撤销。\nGit中如何解决合并冲突？\r合并冲突是在将分支内容合并时可能遇到的问题，可以通过以下步骤解决： 执行合并操作：通过命令git merge 将指定分支的内容合并到当前分支。 例如，git merge feature将会将feature分支合并到当前分支。 Git无法自动解决冲突时，会提示合并冲突，并在冲突文件中标记出冲突的部分。 手动解决冲突：打开冲突文件，根据标记修改文件内容，解决冲突。 解决冲突后，通过命令git add 将冲突文件标记为已解决。 最后，执行命令git commit完成合并提交。\n什么是Git？ Git的工作原理是什么？\rGit是一个分布式版本控制系统，用于跟踪文件的更改并协调多人协作开发。\nGit将代码仓库视为一个存储所有文件历史记录的快照数据库，每次提交会创建一个新的快照，并记录一个指向该快照的指针。Git使用哈希算法来生成每个提交的唯一标识。Git还使用分支来支持并行开发，每个分支都是指向提交的指针。\n写出你所知道的Git的相关命令操作并做出解释（写出五个以上）\rgit init： 作用：将当前目录初始化为一个Git仓库。 解释：通过执行该命令，Git会在当前目录创建一个新的空的Git仓库，用于跟踪管理项目的版本。 git clone [url]： 作用：从远程仓库克隆代码到本地。 解释：该命令用于将远程仓库中的代码完整地复制到本地，创建一个本地的Git仓库副本，并与远程仓库保持同步。 git add [文件/目录]： 作用：将文件添加到Git的暂存区。 解释：执行该命令后，Git会将指定的文件或目录添加到暂存区，以便在后续的提交中包含它们。 git commit -m \u0026ldquo;提交信息\u0026rdquo;： 作用：提交暂存区中的文件到本地仓库。 解释：该命令用于将暂存区中的文件提交到本地仓库，同时可以附加一条提交信息，用于描述本次提交的内容。 git push： 作用：将本地仓库的代码推送到远程仓库。 解释：执行该命令后，Git会将本地仓库的代码推送到与之关联的远程仓库，以使得远程仓库与本地仓库保持同步。 git pull： 作用：从远程仓库拉取最新的代码到本地。 解释：该命令用于从与之关联的远程仓库拉取最新的代码，以使得本地仓库与远程仓库保持同步。 git branch： 作用：列出所有分支。 解释：执行该命令后，Git会返回当前仓库中存在的所有分支列表，并且会高亮显示当前所在的分支。 git checkout [分支名]： 作用：切换到指定的分支。 解释：该命令用于从当前分支切换到指定的分支，以便开始在该分支上进行开发或其他操作。 git merge [分支名]： 作用：合并指定分支到当前分支。 解释：执行该命令后，Git会将指定分支的代码合并到当前分支中，以便将两个分支的修改内容合并在一起。 git log： 作用：显示提交日志。 解释：执行该命令后，Git会返回当前分支的所有提交记录，包括每个提交的作者、日期、提交信息等详细信息。\nSpring Boot专题\rSpring Boot 特性有哪些\r快速创建独立 Spring 应用\nSSM：导包、写配置、启动运行\n- 直接嵌入Tomcat、Jetty or Undertow（无需部署 war 包）【Servlet容器】\n- - linux java tomcat mysql： war 放到 tomcat 的 webapps下\n- jar： java环境； java -jar\n- 重点：提供可选的starter，简化应用整合\n- - 场景启动器（starter）：web、json、邮件、oss（对象存储）、异步、定时任务、缓存\u0026hellip;\n- 导包一堆，控制好版本。\n- 为每一种场景准备了一个依赖； web-starter。mybatis-starter\n- 重点：按需自动配置 Spring 以及 第三方库\n- - 如果这些场景我要使用（生效）。这个场景的所有配置都会自动配置好。\n- 约定大于配置：每个场景都有很多默认配置。\n- 自定义：配置文件中修改几项就可以\n- 提供生产级特性：如 监控指标、健康检查、外部化配置等\n- - 监控指标、健康检查（k8s）、外部化配置\n- 无代码生成、无xml\n你如何理解 Spring Boot 中的 Starters？\rStarters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。如你想使用 Spring JPA 访问数据库，只要加入 spring-boot-starter-data-jpa 启动器依赖就能使用了。\nStarters包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。具体请看这篇文章《Spring Boot Starters启动器》。\nSpring Boot 自动配置原理是什么？\r1、导入starter，就会导入autoconfigure包。\n2、autoconfigure 包里面 有一个文件 META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports,里面指定的所有启动要加载的自动配置类\n3、@EnableAutoConfiguration (内部@Import注解)会自动的把上面文件里面写的所有自动配置类都导入进来。xxxAutoConfiguration 是有条件注解进行按需加载\n4、xxxAutoConfiguration给容器中导入一堆组件，组件都是从 xxxProperties中提取属性值\n5、xxxProperties又是和配置文件进行了绑定\n效果：导入starter、修改配置文件，就能修改底层行为。\nSpring Boot 的核心注解是哪个？它主要由哪几个注解组成的？\r启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：\nl @SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。\nl @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，\nn 如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。\nl @ComponentScan：Spring组件扫描。\nLinux专题\r写出Linux根目录下的6个常用目录及其作用\r/bin 二进制可执行命令。该目录下存放着普通用户的命令\n/dev 系统的设备文件，即设备的驱动程序\n/home 存放用户文件的主目录，用户数据\n/lib 存放着和系统运行相关的库文件\n/mnt 存放临时的映射文件，通常是一些用来安装其他设备的子目录\n/boot 存放启动linux的核心文件\n/media 存放着可移除的设备，比如软盘，光盘\n/proc 存放着用户与内核的交互信息\n/sbin 系统的管理命令，这里存放的是系统管理员使用的程序\n/srv 系统启动服务时可以访问的数据库目录\n/tmp 临时文件，重启后自动清空\n/var 存放系统产生的经常变化的文件\n/etc 系统所有的配置文件都在这个目录中 （添加环境变量）\n/opt (option : 自由选择)主要给源码安装软件时选择的安装目录位置\n/root 超级用户的目录\n/selinux 主要用来加固操作系统，提高系统的安全性\n/sys 管理设备文件\n/usr 最大的目录，存放着应用程序和文件\n/lost-found 这个目录平时是空的，当系统非正常关机而留下的“无家可归”的文件便会储存\n写出Linux常用命令（不少于5个）\r一、服务类命令\n（1）systemctl start 服务名 - 开启服务\n（2）systemctl stop 服务名 - 关闭服务\n（3）systemctl restart 服务名 - 重启服务\n（4）systemctl status 服务名 - 查看服务\n二、文件目录类指令\n（1）pwd - 显示当前目录的绝对路径\n（2）ls - 显示当前路径下的文件和目录\n（3）cd - 切换至指定目录\n（4）mkdir - 创建目录\n（5）rmdir - 删除目录(空目录)\n（6）touch - 创建空文件\n（7）cp - 拷贝文件或目录到指定文件或目录\n（8）rm - 删除文件或目录\n（9）mv - 移动文件与目录或重命名\n（10）cat - 查看文件内容\n（11）more - 文本过滤器\n（12）less - 分屏查看文件内容\n（13）echo - 输出内容到控制台\n（14）head - 显示文件开头部分\n（15）tail - 显示文件尾部的部分\n（16）\u0026gt; / \u0026raquo; - 输出重定向/追加\n（17）ln - 软链接\n（18）history - 查看执行过的的历史命令\n三、搜索查找类指令\n（1）find - 查找文件\n（2）locate - 定位文件路径\n（3）which - 定位指令路径\n（4）grep - 过滤查找\n四、压缩解压类指令\n（1）gzip - 压缩文件\n（2）gunzip - 解压文件\n（3）zip - 压缩文件或目录\n（4）unzip - 解压文件或目录\n（5）tar - 打包\nVMWare三种工作模式\r- bridged(桥接模式)：VMWare虚拟出来的操作系统就像是局域网中的一台独立的主机，它可以访问网内任何一台机器。需要手工为虚拟系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟系统才能和宿主机器进行通信。\n- NAT(网络地址转换模式)：让虚拟系统借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。虚拟系统无法和本局域网中的其他真实主机进行通讯。\n- host-only(主机模式)：所有的虚拟系统是可以相互通信的，但虚拟系统和真实的网络是被隔离开的。虚拟系统和宿主机器系统是可以相互通信的。如果想利用VMWare创建一个与网内其他机器相隔离的虚拟系统，进行某些特殊的网络调试工作，可选择host-only模式。\n","date":"2024-01-01T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/javaweb%E5%92%8Cssm%E9%A2%98%E5%BA%93/","title":"JavaWEB和SSM题库"},{"content":"正文测试\r而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用\r思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片\r1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://z221224.github.io/yuan/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu4699868770670889127.jpg","permalink":"https://z221224.github.io/yuan/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings\rThe following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1\rH2\rH3\rH4\rH5\rH6\rParagraph\rXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes\rThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution\rTiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution\rDon\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables\rTables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables\rItalics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks\rCode block with backticks\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces\r\u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block\r1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types\rOrdered List\rFirst item Second item Third item Unordered List\rList item Another item And another item Nested list\rFruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark\rGIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image\rThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://z221224.github.io/yuan/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"https://z221224.github.io/yuan/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt\rThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat\rVicta caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://z221224.github.io/yuan/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://z221224.github.io/yuan/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples\rInline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n$$\r\\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://z221224.github.io/yuan/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://z221224.github.io/yuan/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://z221224.github.io/yuan/p/emoji-support/","title":"Emoji Support"}]